%% LyX 2.3.0 created this file.  For more info, see http://www.lyx.org/.
%% Do not edit unless you really know what you are doing.
\RequirePackage{fix-cm}
\documentclass[12pt,italian]{amsbook}
\usepackage[T1]{fontenc}
\usepackage[latin9]{inputenc}
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2cm,bmargin=2.2cm,lmargin=2cm,rmargin=4cm,headheight=2cm,headsep=1cm,footskip=1cm}
\setlength{\parskip}{\smallskipamount}
\setlength{\parindent}{0pt}
\usepackage{babel}
\usepackage{array}
\usepackage{varioref}
\usepackage{refstyle}
\usepackage{wrapfig}
\usepackage{booktabs}
\usepackage{units}
\usepackage{textcomp}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage{amstext}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{cancel}
\makeindex
\usepackage{graphicx}
\usepackage{wasysym}
\PassOptionsToPackage{normalem}{ulem}
\usepackage{ulem}
\usepackage[unicode=true,
 bookmarks=true,bookmarksnumbered=true,bookmarksopen=true,bookmarksopenlevel=1,
 breaklinks=false,pdfborder={0 0 0},pdfborderstyle={},backref=page,colorlinks=false]
 {hyperref}
\hypersetup{pdftitle={Appunti di Fondamenti di fondamenti di Automatica},
 pdfauthor={Lorenzo Prosseda},
 pdfsubject={Corso di fondamenti di Automatica del prof. Fagiano, Politecnico di Milano 2017-2018},
 pdfkeywords={automatica}}

\makeatletter

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% LyX specific LaTeX commands.

\AtBeginDocument{\providecommand\defref[1]{\ref{def:#1}}}
\AtBeginDocument{\providecommand\exaref[1]{\ref{exa:#1}}}
\AtBeginDocument{\providecommand\chapref[1]{\ref{chap:#1}}}
\AtBeginDocument{\providecommand\tabref[1]{\ref{tab:#1}}}
\AtBeginDocument{\providecommand\subsecref[1]{\ref{subsec:#1}}}
\AtBeginDocument{\providecommand\figref[1]{\ref{fig:#1}}}
\AtBeginDocument{\providecommand\secref[1]{\ref{sec:#1}}}
\newcommand{\noun}[1]{\textsc{#1}}
%% Because html converters don't know tabularnewline
\providecommand{\tabularnewline}{\\}
\RS@ifundefined{subsecref}
  {\newref{subsec}{name = \RSsectxt}}
  {}
\RS@ifundefined{thmref}
  {\def\RSthmtxt{theorem~}\newref{thm}{name = \RSthmtxt}}
  {}
\RS@ifundefined{lemref}
  {\def\RSlemtxt{lemma~}\newref{lem}{name = \RSlemtxt}}
  {}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Textclass specific LaTeX commands.
\numberwithin{section}{chapter}
\numberwithin{equation}{section}
\numberwithin{figure}{section}
\numberwithin{table}{section}
\newenvironment{lyxlist}[1]
	{\begin{list}{}
		{\settowidth{\labelwidth}{#1}
		 \setlength{\leftmargin}{\labelwidth}
		 \addtolength{\leftmargin}{\labelsep}
		 \renewcommand{\makelabel}[1]{##1\hfil}}}
	{\end{list}}
\theoremstyle{definition}
    \ifx\thechapter\undefined
      \newtheorem{defn}{\protect\definitionname}
    \else
      \newtheorem{defn}{\protect\definitionname}[chapter]
    \fi
\theoremstyle{definition}
    \ifx\thechapter\undefined
      \newtheorem{example}{\protect\examplename}
    \else
      \newtheorem{example}{\protect\examplename}[chapter]
    \fi
\theoremstyle{remark}
    \ifx\thechapter\undefined
      \newtheorem{rem}{\protect\remarkname}
    \else
      \newtheorem{rem}{\protect\remarkname}[chapter]
    \fi
\theoremstyle{plain}
    \ifx\thechapter\undefined
	    \newtheorem{thm}{\protect\theoremname}
	  \else
      \newtheorem{thm}{\protect\theoremname}[chapter]
    \fi
\theoremstyle{plain}
    \ifx\thechapter\undefined
  \newtheorem{cor}{\protect\corollaryname}
\else
      \newtheorem{cor}{\protect\corollaryname}[chapter]
    \fi
\theoremstyle{definition}
    \ifx\thechapter\undefined
      \newtheorem{xca}{\protect\exercisename}
    \else
      \newtheorem{xca}{\protect\exercisename}[chapter]
    \fi
\theoremstyle{definition}
    \ifx\thechapter\undefined
      \newtheorem{sol}{\protect\solutionname}
    \else
      \newtheorem{sol}{\protect\solutionname}[chapter]
    \fi

\@ifundefined{date}{}{\date{}}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% User specified LaTeX commands.
\usepackage{pgfplots}
\usepackage{caption}
\captionsetup{font=scriptsize,labelfont=scriptsize}
\usepackage{geometry}
\usepackage{marginnote}
\usepackage{imakeidx}
\usepackage{amsmath}
\usepackage{wrapfig}

\renewcommand{\marginpar}[1]{\marginnote{\footnotesize #1}}
\setlength\marginparsep{0.3cm}
\setlength\marginparwidth{3cm}
\newcommand\xqed[1]{%
  \leavevmode\unskip\penalty9999 \hbox{}\nobreak\hfill
  \quad\hbox{#1}}
\newcommand\demo{\xqed{$\square$}}
\newcommand\sln[1]{\xqed{$\scriptstyle Sol.\,#1$}}
\makeindex

\makeatother

\providecommand{\corollaryname}{Corollario}
\providecommand{\definitionname}{Definizione}
\providecommand{\examplename}{Esempio}
\providecommand{\exercisename}{Esercizio}
\providecommand{\remarkname}{Osservazione}
\providecommand{\solutionname}{Soluzione}
\providecommand{\theoremname}{Teorema}

\begin{document}

\title{Appunti di Fondamenti di Automatica}

\author{Lorenzo Prosseda, a.a. 2017-2018}

\maketitle
\tableofcontents{}

\global\long\def\lm#1#2#3{\underset{{\scriptstyle #1\rightarrow#2}}{\lim}#3}

\global\long\def\serie#1#2#3{\overset{{\scriptstyle #2}}{\underset{{\scriptstyle #1}}{\sum}}#3}

\global\long\def\somme#1#2#3#4{\underset{{\scriptstyle #1}}{\overset{{\scriptstyle #2}}{\int}}#3d#4}


\chapter{Sistemi LTI a tempo continuo}

\section{Modello matematico}

\subsection{Problemi di controllo\label{subsec:Problemi-di-controllo}}

Un \emph{problema di controllo} consiste nell'imporre un \emph{funzionamento
desiderato} a un \emph{processo} assegnato: il processo è dunque l'oggetto
del problema di controllo; il funzionamento desiderato è una funzione
che mette in relazione le \emph{variabili controllat}e coi loro \emph{segnali
di riferimento} (il loro valore desiderato).

Si vuole ottenere una evoluzione del sistema nel tempo per cui le
variabili controllate abbiano un valore quanto più possibile vicino
al segnale di riferimento.

Di un processo bisogna valutare, oltre all'andamento delle variabili
controllate, anche due fonti di errore:
\begin{lyxlist}{00.00.0000}
\item [{Incertezza:}] I valori delle variabili controllate non possono
essere misurati senza \emph{incertezza}; inoltre nel processo possono
intervenire variabili non controllate dall'esterno, chiamate \emph{disturbi}.
\item [{Tempo:}] Le variabili di un problema di controllo sono funzioni
del tempo ed esso può essere \emph{continuo} o \emph{discreto}; inoltre
un componente del sistema potrebbe variare le proprie caratteristiche
nel tempo (\emph{non stazionario}).
\end{lyxlist}
Un processo è costituito in generale dai seguenti elementi:
\begin{itemize}
\item \noun{Uscita}: chiamata in generale $y\left(t\right)\in\mathbb{R}^{{\scriptscriptstyle p}}$,
è la variabile che viene misurata e vogliamo controllare; l'apice
$p$ indica la cardinalità dell'uscita (numero di uscite, sono trattate
come un vettore) ed essa è chiamata anche variabile controllata.
\item \noun{Trasduttore}: misura le variabili fisiche dell'uscita, restituendo
in retroazione una misura dell'uscita o dei disturbi del processo;
esso sarà soggetto a un errore di misura.
\item \noun{Controllore}: sistema che, interagendo col processo, ne controlla
le variabili tramite un attuatore; prende in ingresso i valori di
misura dei trasduttori e l'andamento desiderato del processo (chiamato
\emph{variabile di riferimento} $w\left(t\right)$).
\item \marginpar{{\footnotesize{}Nel corso vedremo spesso l'attuatore ``inglobato''
nel controllore}}\noun{Attuatore}: sistema che influenza il processo agendo sulla \emph{variabile
manipolabile} $u\left(t\right)\in\mathbb{R}^{{\scriptscriptstyle m}}$
anche detta ingresso del processo; l'apice $m$ indica la cardinalità
degli ingressi (come per l'uscita).
\item \noun{Disturbo}: variabili che non possono essere controllate ma possono
essere ``viste'' dal controllore in tempo reale tramite un trasduttore
dedicato; si indicano con $d\left(t\right)\in\mathbb{R}^{{\scriptscriptstyle m_{d}}}$
dove l'apice $m_{d}$ indica la cardinalità dei disturbi (come per
ingressi e uscite).
\end{itemize}
\begin{center}
\begin{minipage}[t]{1\columnwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/1_1-1 Anello controllo retroazione\string".pdf}
\par\end{center}
\begin{center}
\captionof{figure}{Anello di controllo in retroazione}\vspace{0.1cm}
\par\end{center}%
\end{minipage}
\par\end{center}

Quando $m=p$ il sistema si dice quadrato ed è una minima condizione
per ottenere il comportamento desiderato dal sistema, tuttavia non
è detto che il numero di ingressi sia sempre pari alle uscite.

In un contesto ideale sarebbe possibile calcolare (tramite un inversione
delle sue equazioni) gli ingressi del sistema per ottenere esattamente
le uscite desiderate; tuttavia a causa dei disturbi questo non è possibile
nel mondo fisico.

Un sistema si dice allora \emph{stabile} quando, accoppiando controllore
e processo, l'uscita è stabile nel tempo ed è vicina al valore desiderato
anche in presenza dei disturbi.

\subsection{Processi a tempo continuo\label{subsec:Processi-a-tempo-continuo}}

Un processo a tempo continuo presenta una una uscita ($y\left(t\right)$)
e due possibili ingressi: manipolabili ($u\left(t\right)$) e non
manipolabili ($d\left(t\right)$); un modello per questo sistema è
dato dalla Definizione \defref{modello-matematico}.
\begin{defn}
\label{def:modello-matematico}Un modello matematico è un insieme
di equazioni che descrivono il comportamento del sistema e i legami
tra ingressi e uscite.
\end{defn}
I sistemi sono classificati tramite caratteristiche dei modelli (delle
equazioni) che li rappresentano:
\begin{lyxlist}{00.00.0000}
\item [{Statico/Dinamico:}] la presenza del solo ingresso nella funzione
di uscita del sistema lo classifica come statico; si dirà invece dinamico
se presenta delle variabili di stato (vedi Esempio \exaref{maglia-rc}).
\item [{Lineare:}] tutte le equazioni del modello sono combinazioni lineari
delle variabili di stato e degli ingressi.
\item [{Proprio:}] l'ingresso figura nell'equazione di uscita; altrimenti,
se l'ingresso non compare nell'equazione di uscita (la influenza indirettamente)
il sistema si dice strettamente proprio.
\item [{Stazionario:}] la variabile tempo non modifica esplicitamente le
variabili del sistema (per esempio una variabile che cambia comportamento
nel tempo, come un componente che si usura).
\item [{SISO/MIMO:}] sistema con una sola uscita e un solo ingresso o più
uscite e più ingressi.
\end{lyxlist}
\pagebreak{}

A seguire due esempi riguardanti un sistema statico e uno dinamico:
\begin{example}
\label{exa:resistore}\marginpar{{\footnotesize{}Per sistemi a }\emph{\footnotesize{}tempo continuo}{\footnotesize{},
trattati in questo capitolo, la variabile tempo è sempre reale ($t\in\mathbb{R}$),
ovvero tra due istanti di tempo ne esiste sempre un'altro}}Sia dato un resistore di valore $R$ di resistenza, ai cui capi è
applicata una tensione $v\left(t\right)$ dove $t\in\mathbb{R}$;
nel resistore scorrerà una corrente $i\left(t\right)$ dipendente
dalla tensione applicata. Il modello del processo è il seguente:
\[
i\left(t\right)=\dfrac{v\left(t\right)}{R}
\]
Dalla precedente equazione si deduce che, scegliendo di voler misurare
la corrente nel resistore, l'uscita sarà $y\left(t\right)=i\left(t\right)$
mentre l'ingresso sarà $u\left(t\right)=v\left(t\right)$; inoltre
notando che una perturbazione dell'ingresso si ripercuote istantaneamente
sull'uscita ($y\left(t\right)$ dipende direttamente da $u\left(t\right)$)
si può classificare il sistema come statico.

Il sistema ha un solo ingresso e una sola uscita, quindi è quadrato
e SISO (single input, single output).\demo
\end{example}
%
\begin{example}
\label{exa:maglia-rc}Sia data una serie costituita da un resistore
di valore $R$ di resistenza e un condensatore di capacità $C$; ai
capi del circuito è applicata una tensione $v\left(t\right)$, che
causa una tensione $v_{\text{c}}\left(t\right)$ ai capi del condensatore
e una corrente $i\left(t\right)$ nella serie. Sia $v_{\text{c}}\left(t\right)$
la variabile da misurare.

Adottando l'equilibrio delle tensioni possiamo scrivere che la somma
delle tensioni su resistore e condensatore è pari alla tensione forzata
sulla serie:
\[
R\cdot i\left(t\right)+v_{\text{c}}\left(t\right)=v\left(t\right)
\]
Nel caso del condensatore, la tensione ai suoi capi è proporzionale
alla carica sulle sue armature e alla capacità come $v_{\text{c}}\left(t\right)=q\left(t\right)/C$,
da cui si ottiene derivando
\[
\dot{v}_{\text{c}}\left(t\right)=\dfrac{1}{C}\cdot\overset{{\scriptscriptstyle \text{corrente}}}{\overbrace{\dfrac{\partial q\left(t\right)}{\partial t}}}=\dfrac{i\left(t\right)}{C}
\]
La corrente nella serie sarà la stessa per il condensatore e il resistore,
e può essere ricavata dalla legge di Ohm come tensione sul resistore
($v\left(t\right)-v_{\text{c}}\left(t\right)$) divisa la sua resistenza
\[
i\left(t\right)=-\dfrac{1}{R}v_{\text{c}}\left(t\right)+\dfrac{1}{R}v\left(t\right)
\]
Sostituendo $i\left(t\right)$ nell'espressione di $\dot{v}_{\text{c}}\left(t\right)$
si ottiene la seguente
\[
\dot{v}_{\text{c}}\left(t\right)=-\dfrac{1}{RC}v_{\text{c}}\left(t\right)+\dfrac{1}{RC}v\left(t\right)
\]
Scegliendo di voler misurare la tensione ai capi del condensatore
si ha che $y\left(t\right)=v_{\text{c}}\left(t\right)$, l'ingresso
sarà la tensione forzata sulla serie $u\left(t\right)=v\left(t\right)$.
Rispetto all'Esempio \exaref{resistore}, pur conoscendo la tensione
$v\left(t\right)$ ai capi della serie non è possibile ottenere la
tensione $v_{\text{c}}\left(t\right)$ ai capi della capacità (sarebbe
necessario integrare l'equazione differenziale $\dot{v}_{\text{c}}\left(t\right)$,
in cui compaiono delle costanti che rappresentano le \emph{condizioni
iniziali} del sistema, ignote nel contesto di questo esercizio). La
presenza di una grandezza simile in uscita classifica questo sistema
come dinamico.\demo
\end{example}
\begin{defn}
Si chiamano \emph{variabili di stato} quelle la cui conoscenza all'istante
iniziale è necessaria per determinare l'andamento del sistema a seguito
di un ingresso; esse sono indicate come $x\left(t\right)\in\mathbb{R}^{{\scriptscriptstyle n}}$
con apice $n$ la cardinalità del sistema.

Per $n>0$ il sistema si dice dinamico, altrimenti statico.
\end{defn}
Le variabili di stato in pratica indeboliscono il legame tra ingresso
e uscita; il loro numero determina l'\emph{ordine} del sistema (quello
dell'Esercizio \exaref{maglia-rc} è del primo ordine); i sistemi
fisici in generale hanno infinite variabili di stato.

Una formulazione generale per le equazioni del modello matematico
per processi a tempo continuo è la seguente:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Equazioni di un processo a tempo continuo}{\footnotesize{}\index{Processo a tempo continuo, modello@{\footnotesize{}Processo a tempo continuo, modello}}}}
\begin{equation}
\begin{cases}
\dot{x}\left(t\right)=f\left(x\left(t\right),u\left(t\right),t\right) & \text{Equazione di stato}\\
y\left(t\right)=g\left(x\left(t\right),u\left(t\right),t\right) & \text{Equazione di uscita}
\end{cases}\label{eq:Equazioni-processo-tempo-continuo}
\end{equation}
Tornando ai precedenti esempi, i sistemi che descrivono possono essere
classificati nel modo seguente:

\begin{table}[!h]
\begin{centering}
\begin{tabular}{>{\centering}p{0.18\textwidth}>{\centering}m{0.22\textwidth}>{\centering}m{0.58\textwidth}}
 & Esempio \ref{exa:resistore} & Esempio \ref{exa:maglia-rc}\tabularnewline
Equazioni di stato & $\overset{\begin{cases}
y\left(t\right)=\dfrac{1}{R}u\left(t\right)\end{cases}}{{\scriptstyle \text{per }v\left(t\right)=u\left(t\right)}}$ & \bigskip

$\begin{cases}
y\left(t\right)=x\left(t\right) & {\scriptstyle \text{per }v_{\text{c}}\left(t\right)=x\left(t\right)}\\
\dot{x}\left(t\right)=-\dfrac{1}{RC}x\left(t\right)+\dfrac{1}{RC}u\left(t\right) & {\scriptstyle \text{per }v\left(t\right)=u\left(t\right)}
\end{cases}$

\bigskip\tabularnewline
Caratteristiche & Proprio, statico, stazionario, lineare & \bigskip

Strettamente proprio, dinamico del I ordine, stazionario, lineare\tabularnewline
\end{tabular}
\par\end{centering}
\bigskip

\caption{Classificazione di due sistemi, esempi \ref{exa:resistore} e \ref{exa:maglia-rc}}
\end{table}

Nel prossimo esempio si effettuerà una classificazione completa del
sistema meccanico di un ammortizzatore MacPherson:
\begin{example}
Sia dato un ammortizzatore inserito in una molla: possiamo considerare
il sistema (sospensione) come una massa sospesa $m$ (il veicolo)
collegata a una molla di coefficiente $k$ (in cui è inclusa anche
la rigidità dello pneumatico) e un ammortizzatore con coefficiente
di attrito viscoso $\beta$. La sospensione in questione è attiva,
ovvero è possibile applicare in modo controllato una forza $\vec{F}\left(t\right)$
alla massa $m$ (vedi Figura \ref{fig:Esempio-sospensione}).

\begin{table}[!h]
\begin{tabular}{>{\centering}m{0.26\textwidth}>{\centering}m{0.37\textwidth}>{\centering}m{0.37\textwidth}}
\includegraphics[scale=2]{\string"Illustrazioni/1_2-1 Esempio sospensione MacPherson\string".pdf}

\captionof{figure}{}\label{fig:Esempio-sospensione} & \includegraphics[scale=0.8]{\string"Illustrazioni/1_2-2 Andamento attrito viscoso\string".pdf}

\captionof{figure}{}\label{fig:Andamento-attrito-viscoso} & \includegraphics[scale=0.8]{\string"Illustrazioni/1_2-3 Andamento costante elastica\string".pdf}

\captionof{figure}{}\label{fig:Andamento-costante-elastica}\tabularnewline
\end{tabular}
\end{table}

In condizioni statiche la posizione della massa rispetto al suolo
è data da $p_{k}$ (posizione di riposo della molla); la variabile
$\overline{p}_{m}=p_{m}\left(t\right)-p_{k}$ è la posizione della
massa rispetto alla posizione di riposo $p_{k}$.

L'ammortizzatore è dotato di fondo corsa, un limite meccanico all'estensione
della molla: il coefficiente $\beta$ di attrito viscoso dipenderà
allora dalla posizione $\overline{p}_{m}$ della massa (che è anche
l'elongazione della molla); possiamo scrivere
\[
\beta\left(\overline{p}_{m}\right):\begin{cases}
\beta_{0} & \text{se }\overline{p}_{m}\in\left[-p_{m},p_{m}\right]\\
\dfrac{\beta_{0}\varepsilon}{\varepsilon-\left|\overline{p}_{m}\right|+\left|p_{k}\right|} & \text{se }\overline{p}_{m}\in\left(-p_{m}-\varepsilon,-p_{m}\right)\cup\left(p_{m},p_{m}+\varepsilon\right)
\end{cases}
\]
dove i valori di fondo corsa sono indicati da $\varepsilon$, e $\beta_{0}$
è il valore di attrito viscoso in condizioni statiche: l'espressione
ha un coefficiente di attrito viscoso prossimo a $\beta_{0}$ finché
non si raggiunge uno dei due asintoti verticali ($-p_{m}-\varepsilon$
e $p_{m}+\varepsilon$) dove $\beta$ tende a diventare infinitamente
grande (vedi Figura \ref{fig:Andamento-attrito-viscoso}).

Per quanto riguarda il coefficiente della molla (rigidità della sospensione)
esso può variare nel tempo, a causa dell'usura: modellizziamo tale
valore con l'espressione
\[
k\left(t\right)=k_{0}-\left(1-e^{-\lambda t}\right)\Delta k
\]
con $k_{0}$ il valore iniziale della molla appena costruita e $\lambda$
un parametro costante: l'espressione decresce esponenzialmente per
$t\rightarrow\infty$ da $k_{0}$ a $k_{0}-\Delta k$ (vedi Figura
\ref{fig:Andamento-costante-elastica}).

Il modello per questo sistema si può scrivere usando le equazioni
di Newton, equilibrando la traslazione verticale della massa:
\[
\overset{{\scriptscriptstyle \text{forza della massa}}}{\overbrace{m\ddot{\overline{p}}_{m}\left(t\right)}}+\underset{{\scriptscriptstyle \text{forza dell'attrito viscoso}}}{\underbrace{\beta\left(\overline{p}_{m}\left(t\right)\right)\dot{\overline{p}}_{m}\left(t\right)}}+\overset{{\scriptscriptstyle \text{forza della molla}}}{\overbrace{k\left(t\right)\overline{p}_{m}\left(t\right)}}=\underset{{\scriptscriptstyle \text{forza sospensione}}}{\underbrace{F\left(t\right)-mg}}
\]
\marginpar{{\footnotesize{}Per indicare le derivate di $\overline{p}_{m}$ è
stata usata la notazione puntata: ad ogni punto sulla variabile corrisponde
un grado di derivazione; quindi $\ddot{\overline{p}}_{m}\left(t\right)$
è l'accelerazione e $\dot{\overline{p}}_{m}\left(t\right)$ la velocità}}

Per scrivere la precedente nella forma generale bisogna individuare
le variabili di stato ($\overline{p}_{m}$ e $\dot{\overline{p}}_{m}$
pari a $x_{1}$ e $x_{2}$), gli ingressi ($F\left(t\right)$ pari
a $u\left(t\right)$) e i disturbi ($-mg$ nell'espressione della
forza sulla sospensione, pari a $d\left(t\right)$); la precedente
diventa
\[
m\dot{x}_{2}\left(t\right)+\beta\left(x_{1}\left(t\right)\right)x_{2}\left(t\right)+k\left(t\right)x_{1}\left(t\right)=u\left(t\right)-d\left(t\right)
\]
dove posizione ($x_{1}$) e velocità ($x_{2}$) formano il vettore
di variabili di stato; bisogna includere nel modello l'equazione che
mette in relazione le due variabili di stato ($\dot{x}_{1}\left(t\right)=x_{2}\left(t\right)$)
e due funzioni di stato; se vogliamo misurare la posizione della massa
imponiamo $x_{1}\left(t\right)$ in uscita:
\[
\begin{array}{l}
f_{1}\left(x\left(t\right),u\left(t\right),t\right)=x_{2}\left(t\right)\\
f_{2}\left(x\left(t\right),u\left(t\right),t\right)=\dfrac{-\beta\left(x_{1}\left(t\right)\right)}{m}x_{2}\left(t\right)-\dfrac{k\left(t\right)}{m}x_{1}\left(t\right)+\dfrac{u\left(t\right)}{m}-\dfrac{d\left(t\right)}{m}\\
g\left(x\left(t\right),u\left(t\right),t\right)=x_{1}\left(t\right)
\end{array}
\]
Si osserva che il sistema è dinamico del secondo ordine (2 variabili
di stato), non è lineare (la seconda equazione di stato non è lineare),
è tempo-variante (non stazionario, il coefficiente della molla $k\left(t\right)$
cambia nel tempo), è SISO (ha un ingresso e una uscita), è strettamente
proprio (l'ingresso non figura nell'equazione di uscita).\demo
\end{example}
Nel prossimo esempio misuriamo il moto di un autoveicolo, tramite
i principi della dinamica\begin{wrapfigure}{o}{0.3\textwidth}%
\begin{centering}
\includegraphics[scale=1.6]{\string"Illustrazioni/1_2-4 Modello veicolo in movimento\string".pdf}
\par\end{centering}
\caption{Modello per autoveicolo in movimento}
\end{wrapfigure}%

\begin{example}
\emph{Sia dato un autoveicolo in movimento tramite la forza di trazione
del motore $F\left(t\right)$ attraverso le ruote, a cui si oppongono
la massa $m$, la forza di inerzia $m\dot{v}\left(t\right)$ e la
resistenza aerodinamica $\beta mv^{2}\left(t\right)$; $\checkmark$scrivere
un modello che abbia come ingresso la forza di trazione e come uscita
la velocità.}

L'equazione del sistema sarà l'equilibrio della forza di trazione
con quelle che vi si oppongono:
\[
m\dot{v}\left(t\right)+\beta mv^{2}\left(t\right)=F\left(t\right)
\]
Per scrivere la precedente in modo standard consideriamo che (dalla
richiesta dell'esercizio) l'uscita vale $y\left(t\right)=v\left(t\right)$
e l'ingresso vale $u\left(t\right)=F\left(t\right)$; inoltre è presente
la derivata della velocità nell'equazione del sistema: si tratta di
una variabile di stato ($x\left(t\right)=v\left(t\right)$).

Dopo queste considerazioni l'equazione diventa
\[
\begin{array}{c}
m\dot{x}\left(t\right)+\beta mx^{2}\left(t\right)=u\left(t\right){\scriptstyle \text{ da cui segue}}\\
\dot{x}\left(t\right)=-\beta x^{2}\left(t\right)+\dfrac{u\left(t\right)}{m};\quad y\left(t\right)=x\left(t\right)
\end{array}
\]
Si tratta di un sistema dinamico del primo ordine (una variabile di
stato), stazionario (nessuna equazione dipende dal tempo), non lineare
(compare un termine al quadrato nell'equazione di stato), strettamente
proprio (non compare l'ingresso nell'equazione di uscita), SISO (un
ingresso e una uscita).

Se ora immaginiamo di voler misurare anche la posizione del veicolo,
dobbiamo introdurre un nuovo stato coerente con quello presente che
riguardi la grandezza spazio $p\left(t\right)$. Sapendo che $v\left(t\right)=\dot{p}\left(t\right)$
e ponendo dunque $x_{1}\left(t\right)=p\left(t\right)$ e $x_{2}\left(t\right)=v\left(t\right)$
si ottiene
\[
\left\{ \begin{array}{l}
\dot{x}_{1}\left(t\right)=x_{2}\left(t\right)\\
\dot{x}_{2}\left(t\right)=-\beta x_{2}^{2}\left(t\right)+\dfrac{u\left(t\right)}{m}\\
y\left(t\right)=x_{2}\left(t\right)
\end{array}\right.{\scriptstyle \text{(nuovo modello per il sistema)}}
\]
Rispetto al modello precedente è cambiato l'ordine (secondo) mentre
le altre caratteristiche sono immutate.\demo
\end{example}
Nel prossimo esempio un sistema dinamico di ordine \noun{IV:}\begin{wrapfigure}{o}{0.45\textwidth}%
\begin{centering}
\includegraphics[scale=1.5]{\string"Illustrazioni/1_2-5 Sistema due masse sospensioni\string".pdf}
\par\end{centering}
\caption{Sistema di due masse con sospensioni}
\end{wrapfigure}%

\begin{example}
\label{exa:Due-masse-ammortizzate}\emph{Sia dato un sistema costituito
da due masse $m_{1}$ e $m_{2}$ ciascuna avente una propria molla
di costante $k_{1}$ e $k_{2}$ e un proprio ammortizzatore di coefficiente
di attrito $\beta_{1}$ e $\beta_{2}$; le due masse sono collegate
in serie a un vincolo - rispettivamente $m_{1}$ è collegata al vincolo
e $m_{2}$ è collegata a $m_{1}$ - e la loro posizione rispetto a
quella di riposo è data da $p_{1}\left(t\right)$ e $p_{2}\left(t\right)$;
si possa esercitare una forza su ciascuna massa in modo longitudinale
rispetto al sistema (rispettivamente $F_{1}\left(t\right)$ e $F_{2}\left(t\right)$).
$\checkmark$Si scriva un modello per misurare la posizione nel tempo
delle due masse.}

Usando l'equilibrio delle forze (per una massa alla volta) possiamo
scrivere un'equazione tra forza d'inerzia, forza dell'ammortizzatore,
forza elastica e forze esercitate dall'altra massa in seguito al suo
moto relativo, tutto eguagliato alla forza sulla massa considerata\marginpar{{\footnotesize{}In questo esempio viene introdotta in modo diretto
la notazione vettoriale per le equazioni del sistema}}
\[
\begin{array}{c}
m_{1}\ddot{p}_{1}\left(t\right)+\beta_{1}\dot{p}_{1}\left(t\right)+k_{1}p_{1}\left(t\right)+\beta_{2}\left(\dot{p}_{1}\left(t\right)-\dot{p}_{2}\left(t\right)\right)+k_{2}\left(p_{1}\left(t\right)-p_{2}\left(t\right)\right)=F_{1}\left(t\right)\\
m_{2}\ddot{p}_{2}\left(t\right)+\beta_{2}\left(\dot{p}_{2}\left(t\right)-\dot{p}_{1}\left(t\right)\right)+k_{2}\left(p_{2}\left(t\right)+p_{1}\left(t\right)\right)=F_{2}\left(t\right)
\end{array}
\]
Possiamo scrivere il modello nella sua forma standard usando le seguenti
considerazioni (sono presentate direttamente le forme matriciali):
\[
u\left(t\right)\,:\,\begin{bmatrix}u_{1}\left(t\right)\\
u_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}F_{1}\left(t\right)\\
F_{2}\left(t\right)
\end{bmatrix};\qquad y\left(t\right)\,:\,\begin{bmatrix}y_{1}\left(t\right)\\
y_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}p_{1}\left(t\right)\\
p_{2}\left(t\right)
\end{bmatrix}
\]
Ingressi e uscite si ricavano dalla richiesta dell'esercizio, mentre
gli stati sono determinati dai termini differenziali: dato che sono
due per ciascuna equazione, si avranno 4 stati; inoltre sarà necessario
rispettare la scrittura $\dot{x}\left(t\right)=f\left(x,u,t\right)$
per ottenere le equazioni standard del sistema:
\[
x\left(t\right)\,:\,\begin{bmatrix}\dot{x}_{1}\left(t\right)\\
\dot{x}_{2}\left(t\right)\\
\dot{x}_{3}\left(t\right)\\
\dot{x}_{4}\left(t\right)
\end{bmatrix}=\begin{bmatrix}p_{1}\left(t\right)\\
\dot{p}_{1}\left(t\right)\\
p_{2}\left(t\right)\\
\dot{p}_{2}\left(t\right)
\end{bmatrix}
\]
Ora possiamo scrivere le equazioni standard sostituendo nelle equazioni
del sistema:
\begin{equation}
\begin{bmatrix}\dot{x}_{1}\left(t\right)\\
\dot{x}_{2}\left(t\right)\\
\dot{x}_{3}\left(t\right)\\
\dot{x}_{4}\left(t\right)
\end{bmatrix}=\begin{bmatrix}x_{2}\left(t\right)\\
\nicefrac{1}{m_{1}}\left({\scriptstyle -\beta_{1}x_{2}\left(t\right)-k_{1}x_{1}\left(t\right)-\beta_{2}\left(x_{2}\left(t\right)-x_{4}\left(t\right)\right)-k_{2}\left(x_{1}\left(t\right)-x_{3}\left(t\right)\right)+u\left(t\right)}\right)\\
x_{4}\left(t\right)\\
\nicefrac{1}{m_{2}}\left(-\beta_{2}\left(x_{4}\left(t\right)-x_{2}\left(t\right)\right)-k_{2}\left(x_{3}\left(t\right)-x_{1}\left(t\right)\right)+u_{2}\left(t\right)\right)
\end{bmatrix}\label{eq:Vettore-equazioni-di-stato}
\end{equation}
\[
\begin{bmatrix}y_{1}\left(t\right)\\
y_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}x_{1}\left(t\right)\\
x_{3}\left(t\right)
\end{bmatrix}
\]
Si tratta di un sistema dinamico del quarto ordine, lineare (le equazioni
di stato e di uscita non hanno termini quadratici), stazionario, MIMO
(due ingressi e due uscite), strettamente proprio (nell'equazione
di uscita non compare l'ingresso).\demo
\end{example}

\subsection{Modello standard per processi LTI}

Per i sistemi lineari stazionari (tempo-invarianti), chiamati LTI,
la forma matriciale standard del modello è la seguente:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Modello matriciale standard per sistemi LTI}{\footnotesize{}\index{LTI, modello matriciale standard@{\footnotesize{}LTI, modello matriciale standard}}}}
\begin{equation}
\begin{bmatrix}\dot{x}\left(t\right)=A\cdot x\left(t\right)+B\cdot u\left(t\right)\\
y\left(t\right)=C\cdot x\left(t\right)+D\cdot u\left(t\right)
\end{bmatrix}\label{eq:Forma-standard-matrice-LTI}
\end{equation}

I coefficienti $A,\,B,\,C,\,D$ sono matrici di coefficienti ricavati
dalle equazioni in forma matriciale ``canonica'': per esempio osservando
le equazioni (\ref{eq:Vettore-equazioni-di-stato}) dell'Esempio \ref{exa:Due-masse-ammortizzate},
si ha che le quattro matrici varranno rispettivamente:
\[
\begin{array}{cc}
A=\begin{bmatrix}0 & 1 & 0 & 0\\
\dfrac{-k_{1}-k_{2}}{m_{1}} & \dfrac{-\beta_{1}-\beta_{2}}{m_{1}} & \dfrac{+k_{2}}{m_{1}} & \dfrac{+\beta_{2}}{m_{1}}\\
0 & 0 & 0 & 1\\
\dfrac{k_{2}}{m_{2}} & \dfrac{\beta_{2}}{m_{2}} & \dfrac{-k_{2}}{m_{2}} & \dfrac{-\beta_{2}}{m_{2}}
\end{bmatrix} & B=\begin{bmatrix}0 & 0\\
\nicefrac{1}{m_{1}} & 0\\
0 & 0\\
0 & \nicefrac{1}{m_{2}}
\end{bmatrix}\\
C=\begin{bmatrix}1 & 0 & 0 & 0\\
0 & 0 & 1 & 0
\end{bmatrix} & D=\begin{bmatrix}0 & 0\\
0 & 0
\end{bmatrix}
\end{array}
\]
dove la matrice $C$ ha sulle righe le uscite e sulle colonne gli
stati (la prima uscita è pari al primo stato e la seconda pari al
terzo stato); la matrice $D$ ha sulle righe le uscite e sulle colonne
gli ingressi (ed essendo il sistema nell'esempio strettamente proprio,
sarà una matrice nulla); la matrice $B$ ha sulle righe gli stati
e sulle colonne gli ingressi; la matrice $A$ ha sulle righe e sulle
colonne gli stati.

Si noti che un sistema rimane lineare anche se tempo-variante: infatti
se uno dei coefficienti matriciali cambia nel tempo, il modello (\ref{eq:Forma-standard-matrice-LTI})
rimane una combinazione lineare.

In generale, posto che $u\in\mathbb{R}^{m},\,x\in\mathbb{R}^{n},\,y\in\mathbb{R}^{p}$,
i coefficienti matriciali saranno rispettivamente di dimensione:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Dimensioni dei coefficienti standard per sistemi
LTI}{\footnotesize{}\index{LTI, dimensioni dei coefficiente standard@{\footnotesize{}LTI, dimensioni dei coefficiente standard}}}}[-0.25cm]
\begin{equation}
A\in\mathbb{R}^{n\times n},\,B\in\mathbb{R}^{n\times m},\,C\in\mathbb{R}^{p\times n},\,D\in\mathbb{R}^{p\times m}\label{eq:Dimensioni-coeff-matrici-standard}
\end{equation}
Ricapitolando, i coefficienti matriciali sono costituiti come $A=\#_{\text{stati}}\times\#_{\text{stati}},\,B=\#_{\text{stati}}\times\#_{\text{ingressi}},\,C=\#_{\text{uscite}}\times\#_{\text{stati}},\,D=\#_{\text{uscite}}\times\#_{\text{ingressi}}$
dove $\#_{i}$ è la cardinalità della funzione $i$ al pedice nelle
equazioni (\ref{eq:Equazioni-processo-tempo-continuo}).

Un sistema particolare (della categoria LTI) che ha il modello (\ref{eq:Forma-standard-matrice-LTI})
è il \emph{sistema a ritardo di tempo}: i ritardi sono presenti in
ogni sistema di controllo e rappresentano dei limiti alle prestazioni
del sistema; per modellizzare un ritardo pari a $\tau$ secondi si
scrive l'uscita influenzata come $y\left(t\right)=u\left(t-\tau\right)$.

Il sistema con questa uscita rimane lineare e ha una traslazione di
$y\left(t\right)$ lungo l'asse del tempo; per verificare che un sistema
sia lineare non ostante la presenta di disturbi si può studiare usando
la \emph{sovrapposizione degli effetti}: se l'ingresso e l'uscita
sono combinazioni lineari di due segnali allora il sistema è lineare,
ovvero deve valere\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Sovrapposizione degli effetti per LTI}{\footnotesize{}\index{LTI, sovrapposizione degli effetti@{\footnotesize{}LTI, sovrapposizione degli effetti}}}}[0.25cm]
\begin{equation}
\begin{array}{c}
u_{{\scriptscriptstyle \text{TOT}}}\left(t\right)=\alpha_{1}u_{1}\left(t\right)+\alpha_{2}u_{2}\left(t\right)\\
y_{{\scriptscriptstyle \text{TOT}}}\left(t\right)=\alpha_{1}u_{1}\left(t-\tau\right)+\alpha_{2}u_{2}\left(t-\tau\right)
\end{array}\label{eq:Sovrapposizione-effetti-sistema-lineare}
\end{equation}
Vale che $u_{i}\left(t-\tau\right)=y_{i}\left(t\right)$ ovvero l'uscita
è pari all'ingresso sfasato del ritardo, da cui $y_{{\scriptscriptstyle \text{TOT}}}\left(t\right)=\alpha_{1}y_{1}\left(t\right)+\alpha_{2}y_{2}\left(t\right)$.

\section{Comportamento del sistema}

\subsection{Movimenti ed equilibrio}

Dato un sistema lineare ad un certo istante iniziale $t_{0}$ a cui
corrisponde lo stato (condizione) iniziale $x\left(t_{0}\right)=x_{0}$
e un segnale $u\left(t\right)$ per $t\in\left(t_{0},\,\infty\right)$,
in generale si può dire che:
\begin{defn}
Il \emph{movimento} di un sistema LTI dinamico sono le funzioni $x\left(t\right)$
e $y\left(t\right)$ (rispettivamente dello stato e dell'uscita),
a fronte di condizioni iniziali $x\left(t_{0}\right)$ e ingresso
$u\left(t\right)$ per $t>t_{0}$.
\end{defn}
I movimenti di un sistema non lineare non sono calcolabili in forma
chiusa ed è necessario applicare metodi di calcolo numerico. Una classe
particolare di movimenti sono gli equilibri:
\begin{defn}
\label{def:Equilibrio-LTI}Gli \emph{equilibri} di un sistema dinamico
sono una classe di movimenti per cui il valore dell'ingresso, dello
stato e dell'uscita sono costanti nel tempo; in termini di equazioni
(\ref{eq:Equazioni-processo-tempo-continuo}) si deve avere $\dot{x}\left(t\right)=0$
per ottenere un andamento costante.

Un equilibrio è dunque una coppia di valori $\left(\overline{u},\,\overline{x}\right)$
tali che le equazioni di stato siano tutte nulle ($f\left(\overline{u},\,\overline{x},\,t\right)=0$)
e l'uscita di equilibrio vale $g\left(\overline{u},\,\overline{x},\,t\right)=\overline{y}$.
\end{defn}
Uno dei requisiti principali dei sistemi di controllo è la garanzia
di stabilità; questo concetto è legato in modo analitico ai movimenti
del sistema: si parla infatti di stabilità dei movimenti di un sistema
(e non del sistema).
\begin{defn}
\label{def:Stabilit=0000E0}Il movimento dello stato ottenuto a partire
da condizioni iniziali $x\left(t_{0}\right)$ e applicando l'ingresso
$u\left(t\geq t_{0}\right)$ si dice \emph{stabile} se, comunque preso
un $\varepsilon$ piccolo a piacere positivo esiste un $\delta$ piccolo
a piacere positivo tale che, per tutti i valori di $\tilde{x}_{0}$
(perturbazioni dei valori iniziali) che soddisfano $\left\Vert \tilde{x}_{0}-x_{0}\right\Vert \leq\delta$
(condizione iniziale perturbata sufficientemente vicina a quella iniziale
nominale) risulti $\left\Vert \tilde{x}\left(t\right)-x\left(t\right)\right\Vert \leq\varepsilon$,
dove $\tilde{x}\left(t\right)$ è il movimento generato dal sistema
con condizione iniziale $\tilde{x}_{0}$ (valga $\tilde{x}\left(t_{0}\right)=\tilde{x}_{0}$)
e lo stesso ingresso, con $t>t_{0}$.

Scrivendo la formula logica si ha che la definizione equivale a\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Stabilità di un sistema LTI}{\footnotesize{}\index{LTI, stabilità@{\footnotesize{}LTI, stabilità}}}}[0.2cm]
\begin{equation}
\forall\varepsilon>0\,\exists\delta>0\left(\forall\tilde{x}_{0}\left(\left\Vert \tilde{x}_{0}-x_{0}\right\Vert \leq\delta\right)\Rightarrow\forall t>t_{0}\left(\left\Vert \tilde{x}\left(t\right)-x\left(t\right)\right\Vert \leq\varepsilon\right)\right)\label{eq:Stabilit=0000E0-sistema-LTI}
\end{equation}
\end{defn}
La definizione afferma che per ogni $t>t_{0}$ il segnale perturbato
$x\left(t\right)$ rimane confinato intorno al movimento nominale
per una $\tilde{x}_{0}$ entro un intorno della condizione iniziale
nominale.

Dalla Definizione \ref{def:Stabilit=0000E0} segue la
\begin{defn}
Un movimento si dice \emph{instabile} se non vale la (\ref{eq:Stabilit=0000E0-sistema-LTI}).
\end{defn}
Se anche in presenza di una perturbazione si osserva una convergenza
del movimento a quello nominale si parla di
\begin{defn}
\label{def:Stabilit=0000E0-asintotica}Un movimento si dice \emph{asintoticamente
stabile} se soddisfa la Definizione \ref{def:Stabilit=0000E0} e vale
\[
\lm t{\infty}{\left\Vert \tilde{x}\left(t\right)-x\left(t\right)\right\Vert =0}
\]
ovvero la perturbazione si smorza nel tempo.
\end{defn}
Nei capitoli successivi si vedrà che nel caso di sistemi lineari dinamici
tempo-invarianti la stabilità è una proprietà strutturale, ovvero
se il sistema ha un movimento stabile allora tutti i suoi movimenti
sono stabili (quindi per i sistemi LTI si può anche parlare di stabilità
del sistema).

Il prossimo esempio presenta il concetto di equilibrio dei movimenti
e di sovrapposizione degli effetti in modo analitico:
\begin{example}
\emph{Sia dato un circuito costituito da una serie di un resistore
di resistenza $R$ e un condensatore di capacità $C$; è possibile
forzare una tensione $v\left(t\right)$ ai capi della serie e si vuole
misurare la tensione $v_{c}\left(t\right)$ ai capi del condensatore.
$\checkmark$Studiare la condizione di equilibrio e i movimenti del
sistema.}

In analogia con l'Esempio \ref{exa:maglia-rc}, il modello per questo
sistema, posto $v_{c}\left(t\right)=x\left(t\right)$, è $\dot{x}\left(t\right)=-\nicefrac{1}{RC}\cdot x\left(t\right)+\nicefrac{1}{RC}\cdot u\left(t\right);\;y\left(t\right)=x\left(t\right)$.
Applichiamo al circuito una tensione costante $u\left(t\right)=\overline{u}$
e controlliamo se si presenta un movimento di equilibrio: dalla Definizione
\ref{def:Equilibrio-LTI} segue che dobbiamo cercare $\overline{x}$
tale che $-\nicefrac{1}{RC}\cdot\overline{x}+\nicefrac{1}{RC}\cdot\overline{u}=0$;
questo si verifica per $\overline{x}=\overline{u}$. Tutte le coppie
$\left(\overline{x},\,\overline{u}\right)$ tali che $\overline{x}=\overline{u}$
sono equilibri.

Per capire di che tipo di equilibrio si tratti (stabile, instabile,
asintoticamente stabile) si usa di nuovo la Definizione \ref{def:Equilibrio-LTI},
assumendo che prendendo un movimento di equilibrio la condizione iniziale
sia l'equilibrio stesso: partiamo dunque da $\overline{x}=x\left(t_{0}\right)$
e applichiamo il segnale costante $\overline{u}=u\left(t>t_{0}\right)$
(pari al valore di equilibrio); siccome il sistema è tempo-invariante
possiamo considerare il tempo iniziale $t_{0}=0$.

Studiamo in queste condizioni il comportamento di un movimento del
sistema a fronte di una perturbazione: ponendo $\tilde{x}\left(t_{0}\right)=\overline{x}+\delta$
scriviamo l'equazione del movimento quando $u\left(t\right)=\overline{u}$
come
\[
\tilde{x}\left(t\right)=\tilde{x}_{0}e^{-\nicefrac{1}{RC}t}+\left(1-e^{-\nicefrac{1}{RC}t}\right)\overline{u}
\]
Si tratta dell'equazione analitica del movimento dello stato in forma
chiusa; notando che compaiono degli esponenziali con esponente sempre
minore di zero (il tempo $t$ e i valori di $R$ e $C$ sono positivi)
possiamo affermare che la precedente tende per $t\rightarrow\infty$
a $\overline{u}$, che è il valore del movimento nominale: il movimento
converge a quello nominale in modo asintotico, in particolare (dalla
Definizione \ref{def:Stabilit=0000E0})
\[
\left\Vert x\left(t\right)-\tilde{x}\left(t\right)\right\Vert =\left\Vert \overline{x}-\tilde{x}_{0}e^{-\nicefrac{1}{RC}t}-(1-e^{-\nicefrac{1}{RC}t})\overline{u}\right\Vert 
\]
\[
\overset{{\scriptscriptstyle \overline{x}\rightarrow\overline{u}}}{=}\left\Vert \cancel{\overline{u}}-\tilde{x}_{0}e^{-\nicefrac{1}{RC}t}-\cancel{\overline{u}}+e^{-\nicefrac{1}{RC}t}\overline{u}\right\Vert =\bigl\Vert\overset{{\scriptscriptstyle \varhexstar}}{(\delta-\overline{x})}e^{-\nicefrac{1}{RC}t}+e^{-\nicefrac{1}{RC}t}\overline{u}\bigr\Vert
\]
\[
\overset{{\scriptscriptstyle \overline{u}\rightarrow\overline{x}}}{=}\left\Vert \delta e^{-\nicefrac{1}{RC}t}+\left(\overline{x}-\overline{x}\right)e^{-\nicefrac{1}{RC}t}\right\Vert =\left\Vert \delta e^{-\nicefrac{1}{RC}t}\right\Vert 
\]
Nel passaggio $\varhexstar$ si è usata la considerazione iniziale
per cui $\tilde{x}\left(t_{0}\right)=\overline{x}+\delta=\tilde{x}_{0}$;
si ottiene un'esponenziale decrescente che soddisfa la Definizione
\ref{def:Stabilit=0000E0-asintotica}, dunque per questo sistema qualsiasi
condizione di equilibrio ha stabilità asintotica.\demo
\end{example}

\subsection{Formula di Lagrange}

Vogliamo calcolare i movimenti di un sistema lineare: consideriamo
prima l'equazione di stato (il movimento dell'uscita si ottiene facilmente
dal movimento dello stato):
\[
\dot{x}\left(\tau\right)=Ax\left(\tau\right)+Bu\left(\tau\right)
\]
dove si assume che $x\left(\tau=t_{0}\right)$ e $u\left(\tau>t_{0}\right)$.
Moltiplicando entrambi i membri per l'esponenziale di matrice $e^{A\left(t-\tau\right)}$
si ottiene\marginpar{{\footnotesize{}Si ricordi che i coefficienti scritti in maiuscolo
sono matrici, per le quali valgono specifiche proprietà (consultare
\chapref{Richiami-di-Geometria})}}
\[
e^{A\left(t-\tau\right)}\dot{x}\left(\tau\right)-Ae^{A\left(t-\tau\right)}x\left(\tau\right)=e^{A\left(t-\tau\right)}Bu\left(\tau\right)
\]
\[
e^{A\left(t-\tau\right)}\dot{x}\left(\tau\right)-Ae^{A\left(t-\tau\right)}x\left(\tau\right)=\dfrac{\partial\left(e^{A\left(t-\tau\right)}x\left(\tau\right)\right)}{\partial\tau}
\]
La seconda uguaglianza mette in risalto che al primo membro è presente
una derivata di un prodotto: sostituendo una delle due precedenti
equazioni nell'altra e integrando entrambi i membri scriviamo
\[
\somme{t_{0}}t{\dfrac{d}{d\tau}e^{A\left(t-\tau\right)}x\left(\tau\right)}{\tau}=\somme{t_{0}}t{e^{A\left(t-\tau\right)}Bu\left(\tau\right)}{\tau}
\]
Il primo membro può essere ricavato direttamente come $\left[e^{A\left(t-\tau\right)}x\left(\tau\right)\right]_{t_{0}}^{t}=x\left(t\right)-e^{A\left(t-t_{0}\right)}x\left(t_{0}\right)$;
il secondo membro non può essere manipolato nella sua forma generale:
la scrittura risultante è la formula di Lagrange:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Formula di Lagrange}{\footnotesize{}\index{Lagrange, formula@{\footnotesize{}Lagrange, formula}}}}[0.6cm]
\begin{equation}
x\left(t\right)=e^{A\left(t-t_{0}\right)}x\left(t_{0}\right)+\somme{t_{0}}t{e^{A\left(t-\tau\right)}Bu\left(\tau\right)}{\tau}\label{eq:Formula-di-Lagrange}
\end{equation}
La (\ref{eq:Formula-di-Lagrange}) è un integrale di convoluzione
che permette di ottenere l'espressione del movimento dello stato di
un sistema LTI; essa è la somma di due contributi: un primo contributo
chiamato \emph{movimento libero} (dipendente dalla matrice $A$ e
dalle condizioni iniziali), e un secondo contributo chiamato \emph{movimento
forzato} (dipendente dall'effetto dell'ingresso sul sistema).

Verifichiamo ora la proprietà della sovrapposizione degli effetti
nei sistemi LTI sui movimenti del sistema:
\begin{rem}
\marginpar{{\footnotesize{}D'ora in avanti si userà la sigla PSE per riferirsi
al principio di sovrapposizione degli effetti}}Il PSE afferma che, presa una coppia di condizioni iniziali e una
di ingressi, il movimento dello stato e dell'uscita del sistema si
ottiene come combinazione lineare dei movimenti degli ingressi e degli
stati; poniamo per semplicità $t_{0}=0$ e scriviamo in generale le
coppie ingresso-stati usando la (\ref{eq:Formula-di-Lagrange}):
\[
\begin{cases}
x^{\prime}\left(t\right)=e^{At}x_{0}'+\somme 0t{e^{A\left(t-\tau\right)}Bu^{\prime}\left(\tau\right)}{\tau} & \text{per }\left(x_{0}^{\prime},\,u^{\prime}\left(t\right)\right)\\
x^{\prime\prime}\left(t\right)=e^{At}x_{0}''+\somme 0t{e^{A\left(t-\tau\right)}Bu^{\prime\prime}\left(\tau\right)}{\tau} & \text{per }\left(x_{0}^{\prime\prime},\,u^{\prime\prime}\left(t\right)\right)
\end{cases}
\]
a questo punto si prende una terza coppia $\left(x_{0}^{\prime\prime\prime},\,u^{\prime\prime\prime}\left(t\right)\right)$
come combinazione lineare dei movimenti delle due precedenti:
\[
\begin{array}{c}
x_{0}^{\prime\prime\prime}=\alpha_{1}x_{0}^{\prime}+\alpha_{2}x_{0}^{\prime\prime}\\
u^{\prime\prime\prime}\left(t\right)=\alpha_{1}u^{\prime}\left(t\right)+\alpha_{2}u^{\prime\prime}\left(t\right)
\end{array}
\]
dove i coefficienti $\alpha_{1}$ e $\alpha_{2}$ sono scalari; dalle
due precedenti il movimento dello stato sarà (raccogliendo dalla (\ref{eq:Formula-di-Lagrange}))
\[
\boxed{x^{\prime\prime\prime}\left(t\right)=\alpha_{1}x^{\prime}\left(t\right)+\alpha_{2}x^{\prime\prime}\left(t\right)}
\]
\end{rem}
La (\ref{eq:Formula-di-Lagrange}) permette anche per calcolare l'espressione
del movimento di uscita; nel contesto di questa osservazione vale
\begin{equation}
y\left(t\right)=Ce^{At}x_{0}+C\somme 0t{e^{A\left(t-\tau\right)}Bu\left(\tau\right)}{\tau}+Du\left(t\right)\label{eq:Movimento-uscita-Lagrange}
\end{equation}
Possiamo dunque calcolare i movimenti dell'uscita rispetto ai movimenti
dello stato applicando la precedente e raccogliendo come per il movimento
dello stato:
\[
\boxed{y^{\prime\prime\prime}\left(t\right)=\alpha_{1}y^{\prime}\left(t\right)+\alpha_{2}y^{\prime\prime}\left(t\right)}
\]


\subsection{Movimento libero e forzato}

Prendiamo un sistema di ordine uno con $a$ e $b$ scalari: avremo
il movimento dello stato $\dot{x}\left(t\right)=ax\left(t\right)+bu\left(t\right)$;
consideriamo il movimento libero ponendo $u\left(t\right)=0$ e supponiamo
nota la condizione iniziale $x\left(t_{0}\right)=x_{0}$, applicando
la (\ref{eq:Formula-di-Lagrange}) scriveremo\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Movimento libero}{\footnotesize{}\index{Movimento libero@{\footnotesize{}Movimento libero}}}}[0.2cm]
\begin{equation}
x\left(t\right)=e^{at}x_{0}\label{eq:Movimento-libero}
\end{equation}
che è la componente del movimento libero. Questa funzione dipende
dal valore di $a$ nel seguente modo
\begin{itemize}
\item per $a>0$ si ha un andamento esponenziale crescente;
\item per $a<0$ si ha un andamento esponenziale decrescente;
\item per $a=0$ si ha un andamento costante.
\end{itemize}
Considerando il caso $a=0$, ci chiediamo quanto velocemente il movimento
libero converga a zero, ovvero quando $x\left(t\right)=\varepsilon x_{0}$
con $\varepsilon\in\left(0,1\right)$ molto piccolo.

Sostituendo si ha $e^{at_{\varepsilon}}x_{0}=x_{0}\varepsilon\rightarrow e^{at_{\varepsilon}}=\varepsilon\rightarrow t\varepsilon=\dfrac{1}{\left|a\right|}\left|\ln\left(\varepsilon\right)\right|$
e ponendo $T=\dfrac{1}{\left|a\right|}$ (chiamata \emph{costante
di tempo}) scriviamo infine
\[
t_{\varepsilon}=T\left|\ln\left(\varepsilon\right)\right|
\]
Il valore $T$ ci dice quanto velocemente il movimento libero (per
moto \uline{convergente}) converge. Per esempio per $\varepsilon=5\%$
vale $t_{\varepsilon}\simeq3T$.

\marginpar{Nell'automatica si utilizzano gli \emph{ingressi canonici} di un sistema,
segnali interessanti dal punto di vista delle prestazioni del sistema
e del calcolo del suo comportamento; useremo nel seguito lo scalino
($\text{sca}\left(t\right)$)}Analizziamo adesso il movimento forzato, ponendo l'ingresso al valore
$u\left(t\right)=\overline{u}\cdot\text{sca}\left(t\right)$ dove
l'ingresso canonico $\text{sca}\left(t\right):\begin{cases}
1 & \text{per }t\geq0\\
0 & \text{per }t<0
\end{cases}$ viene moltiplicato per il valore costante $\overline{u}$. Annulliamo
le altre condizioni iniziali per studiare solo la parte forzata, ponendo
$t_{0}=0,\,\overline{u}>0,\,x_{0}=0$. Sono ammissibili due procedimenti:
\begin{enumerate}
\item \textsc{Formula di Lagrange}:\smallskip{}
\\
Dall'integrale di convoluzione al secondo addendo di (\ref{eq:Formula-di-Lagrange})
otteniamo (portando le costanti fuori dall'integrale)
\[
x\left(t\right)=\somme 0t{e^{a\left(t-\tau\right)}b\overline{u}\text{sca}\left(\tau\right)}{\tau}=e^{at}b\overline{u}\somme 0t{e^{-a\tau}\text{sca}\left(\tau\right)}{\tau}
\]
Tra gli estremi di integrazione $\text{sca}\left(\tau\right)$ vale
$1$\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Movimento forzato}{\footnotesize{}\index{Movimento forzato@{\footnotesize{}Movimento forzato}}}}[0.65cm]
\begin{equation}
=e^{at}b\overline{u}\somme 0t{e^{-a\tau}}{\tau}=-\dfrac{1}{a}e^{at}b\overline{u}\left[e^{-a\tau}\right]_{\tau=0}^{\tau=t}=\boxed{-\dfrac{b}{a}\overline{u}\left(1-e^{at}\right)}\label{eq:Movimento-forzato}
\end{equation}
Al variare dello scalare $a$ nell'esponenziale si hanno i seguenti
andamenti (supponiamo $b\geq0$):\\
\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item per $a>0$ si ha un andamento esponenziale crescente, tendente a $+\infty$;
\item per $a<0$ si ha un andamento esponenziale decrescente, tendente a
$\dfrac{b}{\left|a\right|}\overline{u}$;
\item per $a=0$ si ha un andamento lineare, tendente a $b\overline{u}$;
per ottenerlo bisogna fare un passo indietro rispetto alla (\ref{eq:Formula-di-Lagrange}):
se $a$ si annulla infatti vale che $\dot{x}\left(t\right)=b\overline{u}$
che è un segnale costante, dunque la primitiva $x\left(t\right)$
ha andamento di una retta divergente.
\end{itemize}
%
\end{minipage}\\
\item \noun{Sovrapposizione degli effetti}:\smallskip{}
\\
Calcoliamo per prima cosa la condizione di equilibrio del sistema
($\dot{x}\left(t\right)=0$) a fronte di un ingresso costante $\overline{u}$
\begin{equation}
\dot{x}\left(t\right)=a\overline{x}+b\overline{u}=0\rightarrow\boxed{\overline{x}=-\dfrac{b}{a}\overline{u}}\label{eq:Condizioni-iniziali-equilibrio-movimento-forzato}
\end{equation}
Interessiamoci al movimento forzato con ingresso a scalino e condizioni
iniziali nulle; possiamo scomporre questo ingresso come una somma
di contributi: condizione iniziale $\overline{x}$ e $u\left(t\right)=\text{sca}\left(t\right)$,
e condizione iniziale $x_{0}-\overline{x}$.\\
Per il primo contributo, essendo il sistema in equilibrio per ipotesi,
il movimento vale $x\left(t\right)=\overline{x}$. Per il secondo
contributo considero
\[
\begin{cases}
x_{0}^{\prime}=\overline{x}, & u^{\prime}\left(t\right)=\overline{u}\cdot\text{sca}\left(t\right)\\
x_{0}^{\prime\prime}=-\overline{x}, & u^{\prime\prime}\left(t\right)=0
\end{cases}
\]
La somma di tali condizioni iniziali e ingressi fornisce il movimento
cercato senza usare l'integrale di convoluzione:
\[
\begin{cases}
x^{\prime}\left(t\right)=\overline{x} & (1)\\
x^{\prime\prime}\left(t\right)=-e^{at}\overline{x}\overset{{\scriptscriptstyle *}}{=}\dfrac{b}{a}e^{at}\overline{u} & (2)
\end{cases}
\]
dove la $\left(1\right)$ rappresenta il movimento a partire da condizioni
iniziali di equilibrio con ingresso di equilibrio, mentre $\left(2\right)$
con ingresso nullo e condizione iniziale $-\overline{x}$ è la risposta
libera del sistema (nell'uguaglianza $*$ si è sostituita la (\ref{eq:Condizioni-iniziali-equilibrio-movimento-forzato})
a $\overline{x}$).\\
Il movimento cercato sarà la somma dei due contributi appena calcolati
(dalla (\ref{eq:Sovrapposizione-effetti-sistema-lineare}) usiamo
$x_{0}=x_{0}^{\prime}+x_{0}^{\prime\prime}$):
\[
x\left(t\right)=-\dfrac{b}{a}\overline{u}\left(1-e^{at}\right)
\]
Otteniamo infine lo stesso risultato dell'integrale di convoluzione.
\end{enumerate}
\begin{rem}
Ricapitolando, abbiamo scelto una condizione iniziale e un ingresso
per facilitare i calcoli: volendo studiare la condizione iniziale
nulla $x_{0}=0$, prendiamo una prima condizione iniziale $x_{0}^{\prime}=\overline{x}$
perché in sua presenza il movimento sarà costante pari a $\overline{x}$;
siccome la condizione di interesse è quella nulla, prendiamo un secondo
movimento con condizione iniziale opposta al primo ($x_{0}^{\prime\prime}-\overline{x}$)
tale che la somma dei due si annulli. Infine abbiamo preso due ingressi
tali che $u^{\prime}\left(t\right)+u^{\prime\prime}\left(t\right)=u\left(t\right)$.
\end{rem}
Proviamo nuovamente a calcolare nel caso $a<0$ il tempo che il movimento
forzato impiega a raggiungere un valore stazionario (asintotico) di
stato:
\[
x\left(t_{\varepsilon}\right)=\overline{x}\left(1-\varepsilon\right)=-\dfrac{b}{a}\overline{u}\left(1-\varepsilon\right)=-\dfrac{b}{a}\overline{u}\left(1-e^{at_{\varepsilon}}\right)
\]
ottenuta dalle (\ref{eq:Condizioni-iniziali-equilibrio-movimento-forzato})
per il secondo membro e (\ref{eq:Movimento-forzato}) per il terzo.
Dall'equazione precedente si ricava
\[
t_{\varepsilon}=\dfrac{1}{\left|a\right|}\left|\ln\left(\varepsilon\right)\right|
\]
che è la stessa condizione del (\ref{eq:Movimento-libero}); essa
implica la presenza di una costante di tempo $T=1/\left|a\right|$
per movimenti convergenti ($a<0$).

\section{Rappresentazione equivalente}

Rispetto al precedente paragrafo, dobbiamo generalizzare i conti fatti
per ottenere i movimenti a coefficienti matriciali (soprattutto per
quanto riguarda la matrice $A$); per affrontare questa generalizzazione
introduciamo il seguente concetto di \emph{rappresentazione equivalente},
in sistemi LTI.

Riprendendo l'Esempio \ref{exa:Due-masse-ammortizzate}, si era scelto
come vettore dello stato posizione e velocità delle due masse; nulla
ci vieta di scegliere diversamente lo stato. Prendendo distanza e
velocità relative tra le due masse otteniamo:
\[
x\left(t\right)=\begin{bmatrix}p_{1}\left(t\right)\\
\dot{p}_{1}\left(t\right)\\
p_{2}\left(t\right)\\
\dot{p}_{2}\left(t\right)
\end{bmatrix}\rightarrow\hat{x}\left(t\right)=\begin{bmatrix}p_{1}\left(t\right)\\
p_{1}\left(t\right)-p_{2}\left(t\right)\\
\dot{p}_{1}\left(t\right)\\
\dot{p}_{1}\left(t\right)-\dot{p}_{2}\left(t\right)
\end{bmatrix}
\]
Si noti che è ammissibile qualsiasi scelta che sia una combinazione
lineare degli stati di partenza; in questo specifico caso lo stato
equivalente può essere espresso come il prodotto di una matrice di
trasformazione per il vettore degli stati:
\[
\hat{x}\left(t\right)=T\cdot x\left(t\right)\rightarrow\overset{{\scriptstyle \hat{x}\left(t\right)}}{\overbrace{\begin{bmatrix}p_{1}\left(t\right)\\
p_{1}\left(t\right)-p_{2}\left(t\right)\\
\dot{p}_{1}\left(t\right)\\
\dot{p}_{1}\left(t\right)-\dot{p}_{2}\left(t\right)
\end{bmatrix}}}=\overset{{\scriptstyle T}}{\overbrace{\begin{bmatrix}1 & 0 & 0 & 0\\
1 & 0 & -1 & 0\\
0 & 1 & 0 & 0\\
0 & 1 & 0 & -1
\end{bmatrix}}}\cdot\overset{{\scriptstyle x\left(t\right)}}{\overbrace{\begin{bmatrix}p_{1}\left(t\right)\\
\dot{p}_{1}\left(t\right)\\
p_{2}\left(t\right)\\
\dot{p}_{2}\left(t\right)
\end{bmatrix}}}
\]
Perché l'equivalenza sia valida deve verificarsi che $T$ sia una
matrice invertibile (nel contesto di questo esempio $\det\left(T\right)=-1$
quindi è invertibile).

Ci chiediamo ora come si possano ottenere le rispettive equazioni
della dinamica del sistema: dalla precedente, esplicitando lo stato
e supponendo $T$ invertibile si può riscrivere che $x\left(t\right)=T^{-1}\cdot\hat{x}\left(t\right)$.

Partiamo da (\ref{eq:Forma-standard-matrice-LTI}) e adottiamo le
considerazioni appena fatte: 
\[
\dot{x}\left(t\right)=Ax\left(t\right)+Bu\left(t\right)\rightarrow T^{-1}\dot{\hat{x}}\left(t\right)=A\cdot T^{-1}\hat{x}\left(t\right)+Bu\left(t\right)
\]
\[
\rightarrow\dot{\hat{x}}\left(t\right)=T\cdot A\cdot T^{-1}\hat{x}\left(t\right)+T\cdot Bu\left(t\right)
\]

L'equazione di uscita sarà di conseguenza
\[
y\left(t\right)=C\cdot x\left(t\right)+D\cdot u\left(t\right)\rightarrow y\left(t\right)=C\cdot T^{-1}\hat{x}\left(t\right)+Du\left(t\right)
\]
Il sistema che si ottiene è LTI della stessa forma di quello originale
(\ref{eq:Forma-standard-matrice-LTI}) ma con i coefficienti matriciali
(la cosiddetta rappresentazione del modello) equivalenti che ridefiniscono
le equazioni nel modo seguente:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Modello equivalente per sistemi LTI}{\footnotesize{}\index{LTI, modello equivalente@{\footnotesize{}LTI, modello equivalente}}}}[1.3cm]
\[
\hat{A}=T\cdot A\cdot T^{-1},\,\hat{B}=T\cdot B,\,\hat{C}=C\cdot T^{-1},\,\hat{D}=D
\]
\begin{equation}
\begin{cases}
\dot{\hat{x}}\left(t\right)=\hat{A}\cdot\hat{x}\left(t\right)+\hat{B}\cdot u\left(t\right)\\
y\left(t\right)=\hat{C}\cdot\hat{x}\left(t\right)+\hat{D}\cdot u\left(t\right)
\end{cases}\label{eq:Forma-equivalente-matrice-LTI}
\end{equation}

\begin{rem}
Per il PSE uno stato è combinazione lineare dello stato precedente
e questo vale per tutti i movimenti; fissando condizione iniziale
e ingresso si ottiene un movimento la cui rappresentazione equivalente
è la combinazione lineare dei movimenti originali secondo la matrice
$T$ di trasformazione.\marginpar{Nelle prossime sezioni vedremo che tutte le proprietà di un sistema
LTI dipendono dagli autovalori di $A$, chiamati \emph{modi} del sistema.}

Dall'Osservazione \ref{oss:Esponenziali-matrici-simili} possiamo
risolvere il calcolo dei movimenti di un generico sistema con matrice
$A$ quadrata, di cui basta cercare la rappresentazione equivalente
più comoda per risolvere le equazioni: se $A$ fosse diagonalizzabile,
potremmo adottare una rappresentazione equivalente nella quale $\hat{A}$
è diagonale (quindi composta dai soli autovalori sulla diagonale mentre
gli altri elementi sono nulli); questo facilita l'uso della (\ref{eq:Formula-di-Lagrange})
poiché l'esponenziale di una matrice diagonale si ricava facilmente.

Si nota che qualsiasi movimento dello stato di un sistema LTI è combinazione
lineare di un numero piccolo di movimenti possibili, tanti quanti
gli autovalori della matrice $A$ della rappresentazione.
\end{rem}

\section{Movimenti generati dai modi}

\subsection{Modi e autovalori}

Prendiamo in esame il caso in cui la matrice $A$ da (\ref{eq:Forma-standard-matrice-LTI})
sia diagonalizzabile (autovalori tutti distinti, vedi Osservazione
\ref{oss:Condizione-sufficiente-diagonalizzabilit=0000E0}): gli autovettori
della matrice saranno soluzione di $\left(\lambda_{i}I-A\right)v_{i}=0$,
generando una matrice di autospazi per una matrice diagonale di autovalori
come
\[
A=\overset{{\scriptstyle T_{{\scriptscriptstyle \text{D}}}}}{\overbrace{\left[v_{1},\,v_{2},\,\ldots v_{n}\right]}}\cdot\overset{{\scriptstyle A_{{\scriptscriptstyle \text{D}}}}}{\overbrace{\text{diag}\left\{ \lambda_{1},\,\lambda_{2},\,\ldots\lambda_{n}\right\} }}\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}
\]
dove $T_{{\scriptscriptstyle \text{D}}}$ è la trasformazione che
diagonalizza $A$ in $A_{{\scriptscriptstyle \text{D}}}$(matrice
diagonale con autovalori di $A$); possiamo riscrivere la relazione
tra la matrice e la sua diagonale nei modi seguenti:
\[
T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}=A\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}\rightarrow A=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot T_{{\scriptscriptstyle \text{D}}}\rightarrow A_{{\scriptscriptstyle \text{D}}}=T_{{\scriptscriptstyle \text{D}}}\cdot A\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}
\]
Se scegliamo un nuovo stato $\hat{x}\left(t\right)=T_{{\scriptscriptstyle \text{D}}}\cdot x\left(t\right)$
ottenuto tramite la matrice di diagonalizzazione, ottengo l'equazione
del modello:
\[
\begin{cases}
\dot{\hat{x}}\left(t\right)=A_{{\scriptscriptstyle \text{D}}}\cdot x\left(t\right)+T_{{\scriptscriptstyle \text{D}}}\cdot Bu\left(t\right)\\
y\left(t\right)=C\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot\hat{x}\left(t\right)+D\cdot u\left(t\right)
\end{cases}
\]
Notiamo che il nuovo sistema ha per matrice di stato una matrice diagonale
($A_{{\scriptscriptstyle \text{D}}}$); ponendo la condizione iniziale
$\hat{x}_{0}=T_{{\scriptscriptstyle \text{D}}}\cdot x_{0}$, il movimento
libero (poniamo ingresso $u\left(t\right)=0$) del sistema si ottiene
dalla (\ref{eq:Movimento-libero}):
\[
\hat{x}\left(t\right)=e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}\hat{x}_{0}
\]
dove l'esponenziale di matrice diagonale vale $e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}=\text{diag}\left\{ e^{\lambda_{1}t},\,e^{\lambda_{2}t},\,\ldots e^{\lambda_{n}t}\right\} $,
dove gli autovalori sulla diagonale sono chiamati \emph{modi} del
sistema. 
\begin{rem}
Questa è una generalizzazione del caso scalare studiato nella precedente
sezione: la matrice $A$ era composta da un singolo elemento e avevamo
ottenuto movimenti della forma $e^{at}$.

Nel caso vettoriale con matrice $A$ diagonalizzabile, troviamo una
matrice di trasformazione $T_{{\scriptscriptstyle \text{D}}}$ che
produce un sistema equivalente il cui stato è combinazione degli stati
originali, col vantaggio che la sua matrice di stato ($A_{{\scriptscriptstyle \text{D}}}$)
è diagonale; a questo punto analizzando il movimento libero con la
(\ref{eq:Formula-di-Lagrange}) si ottiene \uline{necessariamente}
la combinazione lineare dei modi (espressioni della stessa forma $e^{\lambda_{i}t}$)
del nuovo sistema.
\end{rem}
Infine, calcoliamo il movimento libero dello stato del sistema originale,
tramite la trasformazione inversa
\[
x\left(t\right)=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot\hat{x}\left(t\right)
\]

Possiamo affermare che in sistemi LTI qualsiasi movimento libero del
sistema è una combinazione dei suoi modi, che sono al più $n$. Se
la matrice di stato ha coefficienti reali, si ottengono autovalori
reali oppure complessi coniugati; i casi possibili sono elencati di
seguito (viene sottinteso che per $\lambda_{i}$ complessi si abbia
una coppia di autovalori complessi coniugati):\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Andamenti asintotici dei modi di sistemi LTI}{\footnotesize{}\index{LTI, andamenti asintotici dei modi@{\footnotesize{}LTI, andamenti asintotici dei modi}}\label{eq:Andamento-asintotico-modi-LTI}}}[1.6cm]
\begin{itemize}
\item $\lambda_{i}\in\mathbb{\mathbb{R}}$
\begin{itemize}
\item $\lambda_{i}<0$: modo convergenti;
\item $\lambda_{i}=0$: modo costanti;
\item $\lambda_{i}>0$: modo divergenti.
\end{itemize}
\item $\lambda_{i}\in\mathbb{C}$
\begin{itemize}
\item $\Re\left(\lambda_{i}\right)>0$: modo oscillante divergente;
\item $\Re\left(\lambda_{i}\right)=0$: modo oscillante limitato;
\item $\Re\left(\lambda_{i}\right)<0$: modo oscillante convergente.
\end{itemize}
\end{itemize}
\bigskip{}

In particolare, per il caso di autovalori complessi coniugati, avremo
$\lambda_{i,1}=\sigma_{i}+j\omega_{i},\,\lambda_{i,2}=\sigma_{i}-j\omega_{i}$,
si dimostra che anche gli autovettori associati sono complessi coniugati
e gli esponenziali $e^{\lambda_{i}t}$ saranno moltiplicati per coefficienti
complessi coniugati; otterremo dei termini del tipo:
\[
\left(a_{i}+jb_{i}\right)e^{\left(\sigma_{i}+j\omega_{i}\right)t}+\left(a_{i}-jb_{i}\right)e^{\left(\sigma_{i}-j\omega_{i}\right)t}
\]
Se chiamiamo il modulo del coefficiente complesso $m_{p}=\left|a_{i}\pm jb_{i}\right|$
e la sua fase $\phi_{p}=\text{arg}\left(a_{i}\pm jb_{i}\right)$,
possiamo riscrivere la precedente come:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Modo oscillante}{\footnotesize{}\index{Modo oscillante@{\footnotesize{}Modo oscillante}}}}[1.5cm]
\[
m_{p}e^{j\phi_{p}}\cdot e^{\left(\sigma_{i}+j\omega_{i}\right)t}+m_{p}e^{-j\phi_{p}}\cdot e^{\left(\sigma_{i}-jw_{i}\right)t}
\]
\begin{equation}
=m_{p}e^{\sigma_{i}t}\cdot\left(e^{j\left(\omega_{i}t+\phi_{p}\right)}+e^{-j\left(\omega_{i}t-\phi_{p}\right)}\right)=\boxed{m_{p}e^{\sigma_{i}t}\cdot2\cos\left(\omega_{i}t+\phi_{p}\right)}\label{eq:Modo-oscillante}
\end{equation}
dove nella seconda uguaglianza è stata utilizzata la (\ref{eq:Formula-di-Eulero})
ottenendo $e^{\left(\omega_{i}t\pm\phi_{p}\right)}=\cos\left(\omega_{i}t\pm\phi_{p}\right)+j\sin\left(\omega_{i}t\pm\phi_{p}\right)$.
Chiamiamo modo oscillante l'espressione (\ref{eq:Modo-oscillante}),
anche se in modo improprio dato che si tratta della combinazione lineare
di due modi (la coppia di complessi coniugati); esso presenta un andamento
reale in funzione del tempo.\smallskip{}
\begin{wrapfigure}{o}{0.4\textwidth}%
\begin{centering}
\includegraphics[scale=0.9]{\string"Illustrazioni/1_8-1 Circuito RL\string".pdf}
\par\end{centering}
\caption{Circuito RLC con generatore controllato in ingresso}
\end{wrapfigure}%

\begin{example}
\label{exa:Circuito-serie_RLC}\emph{Sia dato un circuito formato
da una maglia con la serie di resistore di valore $R$, condensatore
di valore $C$ e induttore di valore $L$, chiusi su un generatore
indipendente di tensione $u\left(t\right)$, che è l'ingresso del
sistema. Nella serie scorre una corrente $i\left(t\right)$ e su condensatore
e induttore ci sarà rispettivamente una tensione $v_{c}\left(t\right)$
e $v_{{\scriptscriptstyle L}}\left(t\right)$; $\checkmark$si scriva
un modello per questo sistema che abbia come uscita la tensione sul
condensatore $v_{c}\left(t\right)$ e $\checkmark$si analizzi il
movimento libero del sistema (senza ingresso) al variare dei parametri
costruttivi ($R,\,L,\,C$).}

Per i due componenti dinamici (condensatore e induttore) si hanno
dalla Fisica le seguenti relazioni:
\[
\dfrac{\partial}{\partial t}v_{c}\left(t\right)=\dfrac{i\left(t\right)}{C}
\]
\[
\dfrac{\partial}{\partial t}i\left(t\right)=\dfrac{v_{{\scriptscriptstyle L}}\left(t\right)}{L}=\dfrac{1}{L}\left(u\left(t\right)-Ri\left(t\right)-v_{c}\left(t\right)\right)
\]
Abbiamo sostituito la tensione sull'induttore nella seconda relazione
col bilancio delle tensioni sulla maglia, scrivendo $v_{{\scriptscriptstyle L}}\left(t\right)$
in funzione di $v_{c}\left(t\right)$, con $Ri\left(t\right)$ la
tensione sul resistore.

Scegliamo le variabili di stato per portare le equazioni in forma
standard: abbiamo la derivata della tensione sul condensatore nella
prima e la derivata della corrente nella seconda, quindi prendiamo:
\[
x\left(t\right)=\begin{bmatrix}x_{1}\left(t\right)\\
x_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}i\left(t\right)\\
v_{c}\left(t\right)
\end{bmatrix}
\]
da cui segue la seguente scrittura per l'equazione di stato (\ref{eq:Forma-standard-matrice-LTI}):
\[
\dot{x}\left(t\right)=\overset{{\scriptstyle A}}{\overbrace{\begin{bmatrix}-R/L & -1/L\\
1/C & 0
\end{bmatrix}}}\cdot x\left(t\right)+\overset{{\scriptstyle B}}{\overbrace{\begin{bmatrix}1/L\\
0
\end{bmatrix}}}u\left(t\right)
\]

Scegliamo come condizioni iniziali una certa corrente nel circuito
e una certa tensione ai capi della capacità al tempo $t=0=t_{0}$;
imponiamo inoltre l'equazione di uscita per ottenere $v_{c}\left(t\right)$:
\[
x_{0}=\begin{bmatrix}x_{0,1}\\
x_{0,2}
\end{bmatrix}=\begin{bmatrix}i\left(t_{0}\right)\\
v_{c}\left(t_{0}\right)
\end{bmatrix},\quad y\left(t\right)=\begin{bmatrix}0 & 1\end{bmatrix}\cdot x\left(t\right)
\]

Cerchiamo prima di tutto gli autovalori della matrice di stato $A$:
\[
\begin{vmatrix}\lambda+R/L & 1/L\\
-1/C & \lambda
\end{vmatrix}=0\rightarrow\lambda^{2}+\dfrac{R}{L}\lambda+\dfrac{1}{LC}=0\rightarrow\lambda_{1,2}=-\dfrac{R}{2L}\pm\sqrt{\dfrac{R^{2}C-4L}{4L^{2}C}}
\]
Dovremo studiare i casi distinti in cui gli autovalori saranno reali
e i casi in cui saranno complessi coniugati, in dipendenza dal numeratore
della frazione sotto radice. Dovendo cercare il movimento libero calcoleremo
la funzione $e^{A\cdot t}x_{0}$, dalla (\ref{eq:Movimento-libero}).\bigskip{}

\noun{Autovalori reali e distinti} ($R^{2}C>4L$):

In questo caso vale $\lambda_{1},\,\lambda_{2}\in\mathbb{R}\land\lambda_{1}\neq\lambda_{2}$
dunque avendo autovalori distinti la matrice $A$ è diagonalizzabile;
gli autovettori associati a tali autovalori sono:
\[
v_{1}=\begin{bmatrix}1\\
L\lambda_{2}
\end{bmatrix},\,v_{2}=\begin{bmatrix}1\\
L\lambda_{1}
\end{bmatrix}
\]
da cui otteniamo l'inversa della matrice di trasformazione e possiamo
ricavare direttamente $T_{{\scriptscriptstyle \text{D}}}$:
\[
T_{{\scriptscriptstyle \text{D}}}^{-1}=\begin{bmatrix}1 & 1\\
L\lambda_{2} & L\lambda_{1}
\end{bmatrix}\rightarrow T_{{\scriptscriptstyle \text{D}}}=\dfrac{1}{\lambda_{1}-\lambda_{2}}\begin{bmatrix}\lambda_{1} & -1/L\\
-\lambda_{2} & 1/L
\end{bmatrix}
\]
La matrice di stato sarà dunque simile a una matrice diagonale $A_{{\scriptscriptstyle \text{D}}}$
con gli stessi autovalori:\marginpar{D'ora in avanti si presti molta attenzione al pedice $_{D}$ alle
matrici: le relazioni che seguono sfruttano le proprietà di similitudine
e diagonalizzabilità de \chapref{Richiami-di-Geometria}}
\[
A=\overset{{\scriptstyle T_{{\scriptscriptstyle \text{D}}}^{-1}}}{\overbrace{\begin{bmatrix}1 & 1\\
L\lambda_{2} & L\lambda_{1}
\end{bmatrix}}}\cdot\underset{{\scriptstyle {\scriptstyle A_{{\scriptscriptstyle \text{D}}}}}}{\underbrace{\begin{bmatrix}\lambda_{1} & 0\\
0 & \lambda_{2}
\end{bmatrix}}}\cdot\overset{{\scriptstyle T_{{\scriptscriptstyle \text{D}}}}}{\overbrace{\dfrac{1}{\lambda_{1}-\lambda_{2}}\begin{bmatrix}\lambda_{1} & -1/L\\
-\lambda_{2} & 1/L
\end{bmatrix}}}
\]
L'esponenziale di questa matrice diagonale vale quanto quello della
sua diagonalizzata $A_{{\scriptscriptstyle \text{D}}}$ trasformata
da $T_{{\scriptscriptstyle \text{D}}}$:
\[
e^{A\cdot t}=T_{{\scriptscriptstyle \text{D}}}^{-1}\overset{{\scriptstyle e^{A_{{\scriptscriptstyle \text{D}}}t}}}{\overbrace{\begin{bmatrix}e^{\lambda_{1}t} & 0\\
0 & e^{\lambda_{2}t}
\end{bmatrix}}}\cdot T_{{\scriptscriptstyle \text{D}}}
\]
La risposta libera del sistema $x\left(t\right)=e^{A\cdot t}x_{0}$
si riscrive dalle precedenti come:
\[
x\left(t\right)=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot e^{A_{{\scriptscriptstyle \text{D}}}t}\cdot T_{{\scriptscriptstyle \text{D}}}\cdot x_{0}
\]
\[
=\dfrac{1}{\lambda_{1}-\lambda_{2}}\begin{bmatrix}\left(\lambda_{1}x_{0,1}-\nicefrac{1}{L}x_{0,2}\right)e^{\lambda_{1}t}+\left(\lambda_{2}x_{0,1}+\nicefrac{1}{L}x_{0,2}\right)e^{\lambda_{2}t}\\
\left(\lambda_{1}x_{0,1}-\nicefrac{1}{L}x_{0,2}\right)L\lambda_{2}e^{\lambda_{1}t}+\left(-\lambda_{2}x_{0,1}+\nicefrac{1}{L}x_{0,2}\right)L\lambda_{1}e^{\lambda_{2}t}
\end{bmatrix}
\]
La precedente ha due componenti siccome lo stato ha due componenti.
I suoi coefficienti sono una combinazione lineare dei coefficienti
dello stato iniziale e degli elementi della matrice di trasformazione.
Il movimento avrà un andamento sempre convergente: dall'espressione
degli autovalori ricavata inizialmente si ricava
\[
\lambda_{1,2}=-\dfrac{R}{2L}\left(1\pm\sqrt{1-\dfrac{4L}{R^{2}C}}\right)<0
\]
essendoci posti nel caso $R^{2}C>4L$ , quindi gli autovalori reali
distinti saranno sempre negativi e ogni possibile modo derivante avrà
andamento convergente.

Le costanti di tempo di ciascun modo sono $T_{i}=\dfrac{1}{\left|\lambda_{i}\right|}$.\bigskip{}

\noun{Autovalori complessi coniugati} ($R^{2}C<4L$):

I due autovalori saranno pari a $\lambda_{1,2}=\sigma\pm j\omega\in\mathbb{C}\land\lambda_{1}\neq\lambda_{2}$;
essendo sempre distinti la matrice di stato sarà comunque diagonalizzabile.
Gli autovettori di $A$ e le relative matrici di trasformazione sono
uguali a quelle ottenute nel caso precedente; in particolare vale
\[
\sigma=-\dfrac{R}{2L},\quad\omega=\sqrt{\dfrac{\left|R^{2}C-4L\right|}{4L^{2}C}}
\]
Anche in questo caso è corretta l'espressione per $x\left(t\right)=e^{A\cdot t}x_{0}$
ottenuta nel caso precedente; per facilitare la scrittura del primo
stato, definiamo i seguenti:
\[
m_{p}=\left|\dfrac{x_{0,1}}{2}-\dfrac{j}{2\omega}\left(\sigma x_{0,1}-\dfrac{1}{L}x_{0,2}\right)\right|,\quad\phi_{p}=\text{arg}\left(\dfrac{x_{0,1}}{2}-\dfrac{j}{2\omega}\left(\sigma x_{0,1}-\dfrac{1}{L}x_{0,2}\right)\right)
\]
Dopo aver messo in coordinate polari i coefficienti tramite le due
precedenti, si ottiene:
\[
x_{1}\left(t\right)=m_{p}e^{\sigma t}\cdot2\cos\left(\omega t+\phi_{p}\right)
\]
Viene riconfermato il risultato (\ref{eq:Modo-oscillante}).

\marginpar{Un circuito oscillante analogico, come un risonatore puro, ha applicazioni
nel campo dell'elettronica delle telecomunicazioni}L'andamento è decrescente, determinato dall'esponente $\sigma=-R/2L<0$,
dato che le grandezze di resistenza e induttanza sono sempre positive
in un sistema reale; la pulsazione $\omega$ risulta invece inversamente
proporzionale ai valori di resistenza e induttanza: se avessimo un
circuito di resistenza $R=0$ si avrebbe $\omega=\sqrt{1/LC}$, che
caratterizza il circuito come risonatore puro.\bigskip{}

\noun{Autovalori coincidenti} ($R^{2}C=4L$):

I due autovalori saranno pari a $\lambda_{1,2}\in\mathbb{R}\land\lambda_{1}=\lambda_{2}=-R/2L$
(si annulla la radice nell'espressione degli autovalori) e in generale,
la matrice di stato potrebbe non essere diagonalizzabile: controlliamo
che la molteplicità algebrica dell'autovalore $\lambda$ (pari a 2
in questo caso) e quella geometrica coincidano:
\[
g_{1}=n-\text{rango}\left(-\dfrac{R}{2L}I-A\right)=2-\text{rango}\left(\begin{bmatrix}-\dfrac{R}{2L}+\dfrac{R}{L} & \dfrac{1}{L}\\
-\dfrac{1}{C} & -\dfrac{R}{2L}
\end{bmatrix}\right)
\]
\[
=2-\text{rango}\left(\begin{bmatrix}-\dfrac{R}{2L} & \dfrac{1}{L}\\
-\dfrac{R^{2}}{4L} & -\dfrac{R}{2L}
\end{bmatrix}\right)=2-1=1
\]
dove nella seconda abbiamo sostituito $C=4L/R^{2}$ dalla condizione
studiata e il rango è 1 poiché la seconda riga è combinazione lineare
della prima per $-R/2$. Essendo $g_{1}<n_{1}$ la matrice di stato
non è diagonalizzabile; tuttavia può essere scritta in forma (\ref{eq:Forma-di-Jordan}):
la matrice $A_{{\scriptscriptstyle \text{J}}}$ ottenuta sarà in relazione
con $A$ nel modo seguente:
\begin{equation}
A=T_{{\scriptscriptstyle \text{J}}}^{-1}\cdot A_{{\scriptscriptstyle \text{J}}}\cdot T_{{\scriptscriptstyle \text{J}}}\label{eq:Trasformazione-Jordan-Normale}
\end{equation}
La matrice in forma di Jordan avrà sulla diagonale i due autovalori
coincidenti e un 1 in posizione $a_{1,\,2}$ mentre la matrice di
trasformazione si ottiene calcolando (\ref{eq:Autovettori-generalizzati}):
\[
A_{{\scriptscriptstyle \text{J}}}=\begin{bmatrix}\lambda_{1} & 1\\
0 & \lambda_{1}
\end{bmatrix},\quad T_{{\scriptscriptstyle \text{J}}}^{-1}=\begin{bmatrix}1 & 1\\
\lambda_{1}L & L\left(\lambda_{1}-1\right)
\end{bmatrix}\rightarrow T_{{\scriptscriptstyle \text{J}}}=\dfrac{1}{L}\begin{bmatrix}L\left(\lambda_{1}-1\right) & 1\\
-\lambda_{1}L & 1
\end{bmatrix}
\]
Possiamo a questo punto ottenere il movimento libero con (\ref{eq:Movimento-libero})
applicato al sistema in forma di Jordan, a cui applichiamo la trasformazione
(\ref{eq:Trasformazione-Jordan-Normale}):
\begin{equation}
x\left(t\right)=T_{{\scriptscriptstyle \text{J}}}^{-1}\cdot e^{A_{{\scriptscriptstyle \text{J}}}t}\cdot T_{{\scriptscriptstyle \text{J}}}\cdot x_{0}=e^{At}x_{0}\label{eq:Risposta-libera-autovalori-coincidenti}
\end{equation}
dove si ha che $e^{A_{{\scriptscriptstyle \text{J}}}t}=\begin{bmatrix}e^{\lambda_{1}t} & te^{\lambda_{1}t}\\
0 & e^{\lambda_{1}t}
\end{bmatrix}$.
\end{example}
\begin{rem}
Svolgendo il prodotto (\ref{eq:Risposta-libera-autovalori-coincidenti})
otteniamo una risposta libera come combinazione lineare dei modi ottenuti
nel caso di autovalori reali distinti, con dei nuovi modi esponenziali
(tanti quanti gli autovalori con $g_{i}<n_{i}$).
\end{rem}
Nel caso di una matrice non diagonalizzabile, gli autovalori con molteplicità
algebrica $n_{i}>1$ che si ottengono dalla forma di Jordan determinano
i seguenti andamenti dei modi:\label{eq:Andamento-modi-autovalori-multipli}
\begin{itemize}
\item $\lambda_{i}\in\mathbb{R}$ (modi del tipo $te^{\lambda_{i}t}$):\smallskip{}

\begin{itemize}
\item $\lambda_{i}>0$: modo divergente;
\item $\lambda_{i}=0$: modo limitato;
\item $\lambda_{i}<0$: modo convergente.
\end{itemize}
\item $\lambda_{i}\in\mathbb{C}$ (autovalori complessi coniugati, modi
del tipo\\
$te^{\sigma t}\left(\cos\left(\omega t+\phi\right)+j\sin\left(\omega t+\phi\right)\right)$):\smallskip{}

\begin{itemize}
\item $\Re\left(\lambda_{i}\right)>0$: modo divergente (esponenziale);
\item $\Re\left(\lambda_{i}\right)=0$: modo divergente (lineare);
\item $\Re\left(\lambda_{i}\right)<0$: modo convergente.
\end{itemize}
\end{itemize}
\demo\bigskip{}
\begin{figure}[!h]
\begin{centering}
$F\left(t\right)\rightarrow\boxed{1/m}\overset{\ddot{p}\left(t\right)}{\rightarrow}\boxed{\somme 0t{\ddot{p}\left(t\right)}t+p_{0}}\overset{\dot{p}\left(t\right)}{\rightarrow}\boxed{\somme 0t{\dot{p}\left(t\right)}t+p_{0}}\rightarrow p\left(t\right)$
\par\end{centering}
\caption{Schema a blocchi del doppio integratore in questo sistema}
\label{fig:Schema-doppio-integratore}
\end{figure}

\begin{example}
\marginpar{Il sistema nell'esempio con due autovalori coincidenti nulli appartiene
alla categoria dei \emph{doppi integratori}}\label{exa:Doppio-integratore-carrello}\emph{Consideriamo un carrello
di massa $m$ che si muova lungo una superficie priva di attrito con
una traiettoria rettilinea; la sua posizione è data da $p\left(t\right)$
mentre ad esso è applicata una forza esterna $F\left(t\right)$. $\checkmark$Scrivere
un modello per questo sistema in cui si misuri la posizione e $\checkmark$stabilirne
l'andamento dei modi.}

Si ricava facilmente l'equazione della dinamica del sistema:
\[
m\cdot a\left(t\right)=F\left(t\right)
\]
L'ingresso del sistema sarà la forza ($u\left(t\right)=F\left(t\right)$)
e l'uscita da misurare la posizione ($y\left(t\right)=p\left(t\right)$);
come stati scegliamo la posizione ($p\left(t\right)$) e la velocità
($\dot{p}\left(t\right)$) in modo da poter scrivere in funzione di
essi l'accelerazione ($\ddot{p}\left(t\right)$):
\[
x\left(t\right)=\begin{bmatrix}x_{1}\left(t\right)\\
x_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}p\left(t\right)\\
\dot{p}\left(t\right)
\end{bmatrix}
\]
Dalla (\ref{eq:Forma-standard-matrice-LTI}) le equazioni di stato
saranno scritte come:
\[
\dot{x}\left(t\right)=\overset{{\scriptstyle A}}{\overbrace{\begin{bmatrix}0 & 1\\
0 & 0
\end{bmatrix}}}\cdot\overset{{\scriptstyle x\left(t\right)}}{\overbrace{\begin{bmatrix}p\left(t\right)\\
\dot{p}\left(t\right)
\end{bmatrix}}}+\overset{{\scriptstyle B}}{\overbrace{\begin{bmatrix}0\\
1/m
\end{bmatrix}}}\cdot\overset{{\scriptstyle u\left(t\right)}}{\overbrace{F\left(t\right)}}
\]
Il sistema di questo esempio si chiama appunto doppio integratore
poiché presenta due integrazioni in serie dell'ingresso (mostrate
in Figura \ref{fig:Schema-doppio-integratore}); cerchiamo gli autovalori
della matrice di stato per calcolare i movimenti del sistema: essendo
una matrice triangolare, gli autovalori sono i coefficienti sulla
diagonale principale, ovvero vale:
\[
\lambda_{1}=\lambda_{2}=0
\]
Si osserva inoltre che $A$ è già in forma (\ref{eq:Forma-di-Jordan});
posto $x\left(t_{0}\right)=x_{0}$, il movimento libero (\ref{eq:Movimento-libero})
di questo sistema sarà pari a
\[
x\left(t\right)=e^{A\cdot t}x_{0}=\begin{bmatrix}e^{0t} & te^{0t}\\
0 & e^{0t}
\end{bmatrix}\cdot\begin{bmatrix}x_{0,1}\\
x_{0,2}
\end{bmatrix}=\begin{bmatrix}x_{0,1}+tx_{0,2}\\
x_{0,2}
\end{bmatrix}
\]
dove l'esponenziale si calcola in modo diretto per la matrice di stato
di ordine 2 in forma di Jordan.

Il movimento ottenuto rappresenta il fatto che in un sistema di questo
tipo, in assenza di forze in ingresso e di disturbi come l'attrito
(siamo nel caso dell'esempio) la velocità rimarrà costante nel tempo
mentre la posizione (integrale della velocità) aumenterà in modo lineare.\smallskip{}

Calcoliamo invece il movimento forzato applicando in ingresso uno
scalino (forza costante) come $u\left(t\right)=\overline{u}\cdot\text{sca}\left(t\right)$;
la (\ref{eq:Movimento-forzato}) assume il seguente valore:
\[
x\left(t\right)=\somme 0t{e^{A\left(t-\tau\right)}Bu\left(\tau\right)}{\tau}=\somme 0t{\begin{bmatrix}1 & t-\tau\\
0 & 1
\end{bmatrix}\cdot\begin{bmatrix}0\\
\nicefrac{1}{m}
\end{bmatrix}\cdot\overline{u}\cdot\text{sca}\left(\tau\right)}{\tau}
\]
\[
=\somme 0t{\begin{bmatrix}\dfrac{t-\tau}{m}\overline{u}\cdot\text{sca}\left(\tau\right)\\
\dfrac{1}{m}\overline{u}\cdot\text{sca}\left(\tau\right)
\end{bmatrix}}{\tau}=\begin{bmatrix}\dfrac{\overline{u}}{2m}\left[-\left(t-\tau\right)^{2}\right]_{0}^{t}\\
\dfrac{1}{m}\overline{u}\left[\tau\right]_{0}^{t}
\end{bmatrix}=\begin{bmatrix}\dfrac{\overline{u}}{2m}t^{2}\\
\dfrac{1}{m}\overline{u}t
\end{bmatrix}
\]
I coefficienti risultanti dal movimento forzato sono una riscrittura
delle equazioni della dinamica, rispettivamente $a_{1,1}:\,v\left(t\right)=a\left(t\right)t,\,a_{2,1}:\,p\left(t\right)=\dfrac{1}{2}a\left(t\right)t^{2}$
ponendo $a\left(t\right)=\overline{u}/m$. Notiamo inoltre che il
movimento forzato della posizione sarà un esponenziale mentre quello
della velocità è lineare, entrambi divergenti.\demo
\end{example}

\subsection{Modo dominante}

Prendiamo in esame i sistemi con autovalori reali negativi: essi generano
modi convergenti; la costante di tempo associata a ciascun autovalore
dipende inversamente da esso come $T_{i}=1/\left|\lambda_{i}\right|$
(esiste solo per modi convergenti).

Se invece abbiamo autovalori complessi coniugati nella forma (\ref{eq:Modo-oscillante})
possiamo vedere la costante di tempo come il tempo impiegato dall'ampiezza
dell'oscillazione a scendere sotto una certa soglia: concettualmente
si parla dell'esponente $\sigma$ nel modo oscillante, e la costante
di tempo può essere definita come $T=1/\left|\sigma\right|$.

In generale, in un sistema di ordine $n$ ci saranno al più $n$ autovalori
con associate le rispettive costanti di tempo; la risposta complessiva
del sistema (la combinazione lineare dei modi) sarà influenzata dal
modo più ``lento'' (quello con costante di tempo maggiore): tale
modo si chiama \emph{modo dominante}, il quale avrà analiticamente
l'autovalore associato con parte reale più piccola degli altri.

\section{Equilibrio di sistemi LTI}

Per portare in equilibrio un sistema LTI a tempo continuo bisogna
avere una coppia di condizioni iniziali e ingressi costanti $\left(\overline{x},\,\overline{u}\right)$
tali che il movimento di stato rimanga costante, ovvero $\dot{x}\left(t\right)\,:\,A\cdot\overline{x}+B\cdot\overline{u}=0$,
e l'equazione di uscita segue da (\ref{eq:Forma-standard-matrice-LTI})
risultando in $\overline{y}=C\cdot\overline{x}+D\cdot\overline{u}$;
questa equazione ammette una e una sola soluzione quando $A$ è invertibile:
\begin{itemize}
\item Se $A$ è priva di autovalori nulli allora essa è invertibile, e a
fronte di qualsiasi ingresso costante troviamo sempre uno e un solo
stato di equilibrio; dall'equazione di stato si ottiene $\overline{x}=A^{-1}\cdot B\cdot\overline{u}$.
\item Se $A$ non è invertibile almeno un autovalore è nullo e bisogna risolvere
$A\cdot\overline{x}=-B\cdot\overline{u}$.
\end{itemize}
Dalle precedenti considerazioni scriviamo le equazioni di equilibrio
del sistema rispetto ai valori iniziali e alle uscite di equilibrio,
ammettendo che $A$ sia invertibile:
\[
\begin{cases}
\overline{x}=A^{-1}\cdot B\cdot\overline{u}\\
\overline{y}=\left(-C\cdot A^{-1}\cdot B+D\right)\overline{u}
\end{cases}
\]

\begin{example}
Dall'Esempio \ref{exa:Doppio-integratore-carrello} otteniamo la seguente
equazione del sistema (notando che $A$ non è invertibile in questo
caso):
\[
\begin{bmatrix}0 & 1\\
0 & 0
\end{bmatrix}\cdot\begin{bmatrix}\overline{x}_{1}\\
\overline{x}_{2}
\end{bmatrix}=-\begin{bmatrix}0\\
\nicefrac{1}{m}
\end{bmatrix}\cdot\overline{u}
\]
L'equazione ammette soluzione solo per ingresso nullo $\overline{u}=0$,
mentre la prima equazione impone la velocità $\overline{x}_{2}=0$;
a questo punto la posizione $\overline{x}_{1}=\alpha,\,\alpha\in\mathbb{R}$
può assumere qualunque valore reale.\demo
\end{example}

\section{Risposta all'impulso}

L'ingresso canonico chiamato impulso è definito come $\text{imp}\left(t\right)=\left\{ 1\,\text{per }t=0;\;0\,\text{per }t\neq0\right\} $
e il suo integrale vale:
\[
\somme{-\infty}{\infty}{\text{imp}\left(t\right)}t=1
\]
Nella realtà non è possibile avere un ingresso istantaneo: per modellizzare
l'impulso si forza nel sistema un ingresso molto ampio per un breve
periodo di tempo a partire da $t=0$.

Noto il movimento generato dall'impulso di un sistema LTI, è possibile
calcolare il movimento forzato derivante da qualsiasi altro ingresso
in condizioni iniziali nulle.

In generale il movimento forzato dello stato sarà ottenuto da (\ref{eq:Formula-di-Lagrange})
come:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Risposta all'impulso}{\footnotesize{}\index{impulso, risposta al@{\footnotesize{}impulso, risposta al}}}}[2cm]
\[
x_{{\scriptscriptstyle \text{F}}}\left(t\right)=\somme 0t{e^{A\left(t-\tau\right)}B\cdot\text{imp}\left(\tau\right)}{\tau}=e^{A\cdot t}\cdot B\somme 0t{\text{imp}\left(\tau\right)}{\tau}
\]
\begin{equation}
=e^{A\cdot t}\cdot B\label{eq:Risposta-all'-impulso}
\end{equation}
Si ottiene questo risultato osservando che l'impulso vale 1 solo per
$\tau=0$ e per qualunque valore di $\tau\neq0$ il prodotto con l'impulso
che si annulla annulla tutto l'integrale; nota la (\ref{eq:Risposta-all'-impulso})
possiamo calcolare in generale il movimento forzato del sistema come
integrale di convoluzione di (\ref{eq:Movimento-forzato}) in cui
l'argomento contiene il termine (\ref{eq:Risposta-all'-impulso})
per l'ingresso forzato in esame.

Un sistema si dirà stabile se la risposta all'impulso genera modi
convergenti: osservando la risposta all'impulso (\ref{eq:Risposta-all'-impulso})
come la risposta libera (\ref{eq:Movimento-libero}) con condizioni
iniziai pari a $B$, si vorranno ottenere combinazioni lineari di
modi convergenti per garantire la stabilità del sistema.

\section{Stabilità del sistema}

\subsection{Condizioni di stabilità in sistemi a tempo continuo}

Prendiamo un sistema LTI a tempo continuo e poniamoci in una condizione
di equilibrio: il movimento dello stato si ottiene dalla (\ref{eq:Formula-di-Lagrange});
perturbiamo ora la condizione iniziale applicando lo stesso ingresso
di equilibrio e chiamiamo $\tilde{x}_{0}=x\left(t_{0}\right)+\delta$
dove $\delta$ è una perturbazione iniziale.

Scriviamo il movimento perturbato come:
\[
\tilde{x}\left(t\right)=e^{A\cdot t}\tilde{x}_{0}+\somme 0t{e^{A\left(t-\tau\right)}B\cdot u\left(\tau\right)}{\tau}
\]
La distanza della perturbazione da $x\left(t\right)$ sarà definita
da $\delta x\left(t\right)=\tilde{x}\left(t\right)-x\left(t\right)$,
dove possiamo raccogliere l'esponenziale di matrice e notando che
si annulla il termine dovuto all'ingresso (abbiamo ipotizzato una
condizione di equilibrio) avremo:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Andamento della perturbazione}{\footnotesize{}\index{LTI, andamento della perturbazione@{\footnotesize{}LTI, andamento della perturbazione}}}}[0.2cm]
\begin{equation}
e^{A\cdot t}\left(\tilde{x}-x_{0}\right)=e^{A\cdot t}\delta\label{eq:Perturbazione-sistema-LTI}
\end{equation}
Si ottiene questo risultato a prescindere dalle condizioni iniziali.
\begin{rem}
In un sistema LTI a tempo continuo, presa qualsiasi coppia di movimento
e movimento perturbato, la distanza tra i due movimenti è data sempre
dalla (\ref{eq:Perturbazione-sistema-LTI}); da questo deriva il seguente
Teorema \ref{thm:Stabilit=0000E0-del-sistema}.
\end{rem}
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Teorema sulla stabilità del sistema}{\footnotesize{}\index{stabilità del sistema, Teorema@{\footnotesize{}stabilità del sistema, Teorema}}}}[-0.2cm]\label{thm:Stabilit=0000E0-del-sistema}In un sistema LTI
un movimento (incluso quello di equilibrio) è stabile, asintoticamente
stabile o instabile se e solo se sono rispettivamente stabili, asintoticamente
stabili o instabili tutti i movimenti del sistema.
\end{thm}
\begin{rem}
Si nota che l'equazione (\ref{eq:Perturbazione-sistema-LTI}) è l'espressione
di un movimento libero (\ref{eq:Movimento-libero}), dunque è una
combinazione lineare dei modi del sistema: si deduce che l'espressione
(\ref{eq:Perturbazione-sistema-LTI}) sarà limitata, convergente o
divergente a seconda dell'andamento di questi modi. Possiamo quindi
controllare l'andamento di (\ref{eq:Perturbazione-sistema-LTI}) per
conoscere l'andamento di tutto il sistema, per il Teorema \ref{thm:Stabilit=0000E0-del-sistema}.
\end{rem}
Possiamo usare le condizioni (\ref{eq:Andamento-asintotico-modi-LTI})
assieme alla precedente osservazione per ottenere le seguenti considerazioni:
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Teorema dell'asintotica stabilità}{\footnotesize{}\label{thm:Teorema-dell'asintotica-stabilit=0000E0}\index{asintotica stabilità, Teorema@{\footnotesize{}asintotica stabilità, Teorema}}}}[-0.2cm]Un sistema LTI della forma (\ref{eq:Forma-standard-matrice-LTI})
si dice asintoticamente stabile se e solo se \uline{tutti} gli
autovalori della sua matrice di stato ($A$) hanno parte reale negativa
(ovvero quando (\ref{eq:Perturbazione-sistema-LTI}) converge a zero).
\end{thm}
%
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Teorema dell'instabilità}{\footnotesize{}\label{thm:Teorema-dell'instabilit=0000E0}\index{instabilità, Teorema@{\footnotesize{}instabilità, Teorema}}}}[-0.2cm]Un sistema LTI della forma (\ref{eq:Forma-standard-matrice-LTI})
si dice instabile se e solo se \uline{almeno uno} degli autovalori
della sua matrice di stato ($A$) ha parte reale positiva.
\end{thm}
Per autovalori con parte reale nulla, bisogna controllare la diagonalizzabilità
della matrice di stato ($n_{i}=g_{i}$): se questo si verifica si
ottengono solo modi limitati; se la molteplicità geometrica è inferiore
a quella algebrica, allora tutti i modi divergeranno (vedi le condizioni
\vpageref{eq:Andamento-modi-autovalori-multipli}). Enunciamo il seguente
\begin{thm}
In un sistema LTI, per autovalori della matrice di stato tali che
$\Re\left(\lambda_{i}\right)=0$, se vale $n_{i}=g_{i}$ si ha un
sistema stabile (modi limitati); nel caso in cui $g_{i}<n_{i}$ allora
il sistema è instabile.
\end{thm}
Riprendiamo due esempi fatti in precedenza per mostrare un'applicazione
dei teoremi appena enunciati:

Dall'Esempio \ref{exa:Circuito-serie_RLC} si ottenevano due autovalori
nella forma $\lambda_{1,2}=-\dfrac{R}{2L}\pm\sqrt{\dfrac{R^{2}C-4L}{4L^{2}C}}$;
per $R\neq0$ si ottengono sempre autovalori con parte reale negativa:
il sistema risulterà asintoticamente stabile; per $R=0$ si ottengono
autovalori complessi coniugati (immaginari puri): il sistema risulterà
semplicemente stabile.

Dall'Esempio \ref{exa:Doppio-integratore-carrello} si ottenevano
autovalori nulli con molteplicità algebrica maggiore della geometrica:
dalla matrice di stato in forma di Jordan si ottiene che il sistema
è instabile.

Elenchiamo ora alcune proprietà dei sistemi LTI asintoticamente stabili:
\begin{enumerate}
\item Un movimento per $t\rightarrow\infty$ non dipende dalle condizioni
iniziali $x\left(t_{0}\right)$;
\item La risposta (movimento) a un impulso tende ad annullarsi per $t\rightarrow\infty$;
\item La risposta (movimento) a qualsiasi ingresso limitato nel tempo tende
ad annullarsi per $t\rightarrow\infty$;
\item Gli stati e le uscite di equilibrio, con ingresso costante nel tempo
($\overline{u}$), sono unici e pari a $\overline{x}$ e $\overline{y}$;
\item \marginpar{La proprietà di stabilità esterna è abbreviata come BIBO: bounded
input, bounded output}Il sistema gode della proprietà di \emph{stabilità esterna}: a fronte
di ingressi limitati nel tempo, anche le uscite saranno limitate nel
tempo.
\end{enumerate}

\subsection{Segno degli autovalori\label{subsec:Segno-degli-autovalori}}

Sappiamo che gli autovalori della matrice di stato sono i valori per
cui vale la Definizione \ref{def:Autovalore} e risolvono (\ref{eq:Polinomio-caratteristico});
chiamiamo tale polinomio $\phi\left(\lambda\right)=0$, che in generale
ha grado pari all'ordine della matrice da cui deriva (nel nostro caso
ha grado pari all'ordine di $A$).

Possiamo scrivere tale polinomio come
\begin{equation}
\phi\left(\lambda\right)=\phi_{0}\lambda^{n}+\phi_{1}\lambda^{n-1}+\ldots+\phi_{n}\label{eq:Polinomio-caratteristico-Routh}
\end{equation}
Studiamo il segno della parte reale delle soluzioni di tale polinomio,
osservando i suoi coefficienti; enunciamo su questa base il seguente:
\begin{thm}
\label{thm:Criterio-segni-concordi-autovalori}Se il sistema della
forma (\ref{eq:Forma-standard-matrice-LTI}) è asintoticamente stabile,
allora i coefficienti del suo polinomio caratteristico $\phi_{i},\,i\in0\ldots n$
hanno tutti lo stesso segno.
\end{thm}
\begin{cor}
In un sistema di ordine $n\leq2$, la condizione del Teorema (\ref{thm:Criterio-segni-concordi-autovalori})
diventa necessaria e sufficiente.
\end{cor}
Nel caso di un sistema di ordine maggiore di 2 con segno concorde
per tutti gli autovalori della matrice di stato, il sistema potrebbe
essere stabile ma bisogna verificarlo col criterio proposto nella
sezione successiva.

\subsection{Criterio di Routh}

Enunciamo un criterio che fornisce una condizione necessaria e sufficiente
per stabilire la stabilità asintotica di un sistema; questo criterio
si basa sulla seguente \emph{tabella di Routh}, costruita a partire
dal polinomio caratteristico nella forma (\ref{eq:Polinomio-caratteristico-Routh}):
\begin{equation}
\begin{array}{cccccc}
\phi_{0} & \phi_{2} & \phi_{4} & \cdots & \phi_{n-1} & 0\\
\phi_{1} & \phi_{3} & \phi_{5} & \cdots & \phi_{n} & 0\\
\vdots & \vdots & \vdots & \ddots & 0 & \vdots\\
h_{1} & h_{2} & h_{3} & \vdots & \vdots & \vdots\\
k_{1} & k_{2} & k_{3} & \vdots & \vdots & \vdots\\
\ell_{1} & \ell_{2} & \ell_{3} & 0 & 0 & 0
\end{array}\label{eq:Tabella-di-Routh}
\end{equation}
Questa tabella si compila grazie al seguente \emph{algoritmo di Routh}
che dalle due righe precedenti ($h_{i},\,k_{i}$) ottiene la successiva
($\ell_{i}$):
\begin{equation}
\ell_{i}=-\dfrac{1}{k_{1}}\cdot\det\left(\begin{bmatrix}h_{1} & h_{i+1}\\
k_{1} & k_{i+1}
\end{bmatrix}\right)=h_{i+1}-\dfrac{h_{1}k_{i+1}}{k_{1}}\label{eq:Algoritmo-di-Routh}
\end{equation}
Si osserva che in generale la tabella è triangolare, e inoltre l'algoritmo
non si può applicare per il caso $k_{1}=0$ per almeno una riga (in
tal caso si dice che la (\ref{eq:Tabella-di-Routh}) non è ben definita).
L'algoritmo termina quando si otterrebbe uno zero nella prima posizione
della riga più in basso.
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Criterio di Routh}{\footnotesize{}\index{Routh, criterio@{\footnotesize{}Routh, criterio}}}}\label{thm:Criterio-di-Routh}Un sistema LTI della forma (\ref{eq:Forma-standard-matrice-LTI})
è asintoticamente stabile se e solo se la tabella di Routh (\ref{eq:Tabella-di-Routh})
del polinomio caratteristico della matrice di stato ($A$) del sistema
è ben definita, e tutti gli elementi sulla prima colonna della tabella
hanno segno concorde.
\end{thm}
\begin{cor}
Il numero di variazioni di segno degli elementi sulla prima colonna
della tabella (\ref{eq:Tabella-di-Routh}) è pari al numero di autovalori
con parte reale positiva (i quali generano modi instabili).\bigskip{}
\end{cor}
\begin{example}
\emph{Sia dato il seguente polinomio caratteristico della matrice
di stato di un sistema LTI di ordine 5
\[
\phi\left(\lambda\right)=\lambda^{5}+15\lambda^{4}+85\lambda^{3}+225\lambda^{2}+274\lambda+120
\]
$\checkmark$Verificare la stabilità dei movimenti del sistema.}

Il Teorema \ref{thm:Criterio-segni-concordi-autovalori} fornisce
un indizio sulla possibile stabilità del sistema: usiamo il Teorema
\ref{thm:Criterio-di-Routh} per sfruttarne la condizione sufficiente;
grazie all'algoritmo (\ref{eq:Algoritmo-di-Routh}) compiliamo la
seguente tabella:

\begin{minipage}[t]{1\textwidth}%
\begin{center}
\begin{tabular}{cccc}
1 & 85 & 274 & 0\tabularnewline[\doublerulesep]
15 & 225 & 120 & 0\tabularnewline[\doublerulesep]
$85-\dfrac{1\cdot225}{15}$ & $274-\dfrac{1\cdot120}{15}$ & $0-\dfrac{1\cdot0}{15}$ & 0\tabularnewline[\doublerulesep]
$225-\dfrac{15\cdot266}{70}$ & $120-\dfrac{15\cdot0}{70}$ & $0-\dfrac{15\cdot0}{70}$ & 0\tabularnewline[\doublerulesep]
$266-\dfrac{70\cdot120}{168}$ & $0-\dfrac{70\cdot0}{168}$ & $0-\dfrac{70\cdot0}{168}$ & 0\tabularnewline[\doublerulesep]
$120-\dfrac{168\cdot0}{216}$ & $0-\dfrac{168\cdot0}{216}$ & $0-\dfrac{168\cdot0}{216}$ & 0\tabularnewline[\doublerulesep]
\end{tabular}$=$%
\begin{tabular}{cccc}
1 & 85 & 274 & 0\tabularnewline[\doublerulesep]
15 & 225 & 120 & 0\tabularnewline[\doublerulesep]
70 & 266 & 0 & 0\tabularnewline[\doublerulesep]
168 & 120 & 0 & 0\tabularnewline[\doublerulesep]
216 & 0 & 0 & 0\tabularnewline[\doublerulesep]
120 & 0 & 0 & 0\tabularnewline[\doublerulesep]
\end{tabular}
\par\end{center}%
\end{minipage}

Il sistema risulta asintoticamente stabile per il Teorema \ref{thm:Criterio-di-Routh}
poiché tutti gli elementi della prima colonna hanno segno concorde.\demo
\end{example}
%
\begin{example}
\emph{Sia dato un sistema LTI con parametri incerti, ovvero gli autovalori
sono variabili; è possibile calcolare il polinomio caratteristico
rispetto a tali parametri: $\checkmark$si valuti dunque la stabilità
del sistema col seguente polinomio caratteristico di stato}
\[
\phi\left(\lambda\right)=\lambda^{3}+\left(2+\beta\right)\lambda^{2}+\left(1+2\beta\right)\lambda+\alpha+\beta
\]

Grazie al Teorema \ref{thm:Criterio-di-Routh} possiamo compilare
una tabella di Routh e ottenere su di essa le condizioni perché gli
autovalori incerti abbiano segno concorde.

\begin{minipage}[t]{1\textwidth}%
\begin{center}
\begin{tabular}{ccc}
1 & $1+2\beta$ & 0\tabularnewline[\doublerulesep]
$2+\beta$ & $\alpha+\beta$ & 0\tabularnewline[\doublerulesep]
\cline{1-2} 
$\left(1+2\beta\right)-\dfrac{1\cdot\left(\alpha+\beta\right)}{2+\beta}$ & $0-\dfrac{1\cdot0}{2+\beta}$ & 0\tabularnewline[\doublerulesep]
$\left(\alpha+\beta\right)-\dfrac{\left(2+\beta\right)\cdot0}{\dfrac{2\left(\beta+1\right)^{2}-\alpha}{\beta+2}}$ & $0-\dfrac{\left(2+\beta\right)\cdot0}{\dfrac{2\left(\beta+1\right)^{2}-\alpha}{\beta+2}}$ & 0\tabularnewline[\doublerulesep]
\end{tabular}$=\quad$%
\begin{tabular}{ccc}
1 & $1+2\beta$ & 0\tabularnewline[\doublerulesep]
$2+\beta$ & $\alpha+\beta$ & 0\tabularnewline[\doublerulesep]
\cline{1-2} 
$\dfrac{2\left(\beta+1\right)^{2}-\alpha}{\beta+2}$ & 0 & 0\tabularnewline[\doublerulesep]
$\alpha+\beta$ & 0 & 0\tabularnewline[\doublerulesep]
\end{tabular}
\par\end{center}%
\end{minipage}

Imponiamo che tutti i coefficienti della prima colonna siano maggiori
di zero (è presente un 1, che è costante e positivo, esso influenza
il segno della colonna):
\[
\begin{cases}
2+\beta>0\\
2\left(\beta+1\right)^{2}-\alpha>0\\
\alpha+\beta>0
\end{cases}
\]
Le coppie $\left(\alpha,\,\beta\right)$ che soddisfano tutte queste
condizioni generano movimenti asintoticamente stabili per il sistema.
Quelle che non le soddisfano generano movimenti instabili.\demo
\end{example}

\section{Sistemi non lineari tempo-invarianti}

\subsection{Linearizzazione}

Un sistema si definisce \emph{non lineare} quando una delle equazioni
(\ref{eq:Forma-standard-matrice-LTI}) non è una combinazione degli
stati con gli ingressi; il calcolo dei movimenti per questo tipo di
sistemi, a partire da condizioni iniziali ben definite e un certo
ingresso non è risolvibile in forma chiusa (l'equazione differenziale
dello stato avrà almeno una costante indeterminata).

I movimenti di equilibrio di questi sistemi sono tuttavia ottenibili
direttamente usando la Definizione \ref{def:Equilibrio-LTI}; per
sistemi non lineari si cercano nella pratica degli equilibri di interesse
attorno ai quali i movimenti sono stabili. Grazie a una trasformazione
chiamata linearizzazione, ovvero tramite uno sviluppo di Taylor al
primo ordine (lineare) delle matrici (\ref{eq:Dimensioni-coeff-matrici-standard})
nel punto di equilibrio, si studia la stabilità dei movimenti del
sistema.

Si effettua dunque la seguente approssimazione: sia dato un sistema
nella forma (\ref{eq:Forma-standard-matrice-LTI}), e una sua condizione
di equilibrio $\left(\overline{x},\,\overline{u}\right)$; lo sviluppo
di Taylor troncato al primo ordine delle equazioni di stato e di uscita
vale:
\[
\dot{x}\left(t\right)=f\left(\overline{x},\,\overline{u},\,t\right)+\left.\dfrac{\partial f}{\partial x}\right|_{\overline{x},\overline{u}}\cdot\left(x\left(t\right)-\overline{x}\right)+\left.\dfrac{\partial f}{\partial u}\right|_{\overline{x},\overline{u}}\cdot\left(u\left(t\right)-\overline{u}\right)
\]
\[
y\left(t\right)=g\left(\overline{x},\,\overline{u},\,t\right)+\left.\dfrac{\partial g}{\partial x}\right|_{\overline{x},\overline{u}}\cdot\left(x\left(t\right)-\overline{x}\right)+\left.\dfrac{\partial g}{\partial u}\right|_{\overline{x},\overline{u}}\cdot\left(u\left(t\right)-\overline{u}\right)
\]
Se definiamo le quantità $\delta x\left(t\right)=x\left(t\right)-\overline{x}$
e $\delta u\left(t\right)=u\left(t\right)-\overline{u}$ per le equazioni
di stato, e la quantità $\delta y\left(t\right)=y\left(t\right)-\overline{y}$
per l'equazione di uscita, le precedenti diventano\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Forma linearizzata tempo-invariante}{\footnotesize{}\index{Linearizzazione@{\footnotesize{}Linearizzazione}}}}[1.3cm]
\begin{equation}
\begin{array}{c}
\delta\dot{x}\left(t\right)=\dot{x}\left(t\right)-\dot{\overline{x}}=\overset{{\scriptstyle A}}{\overbrace{\left.\dfrac{\partial f}{\partial x}\right|_{\overline{x},\overline{u}}}}\cdot\delta x\left(t\right)+\overset{{\scriptstyle B}}{\overbrace{\left.\dfrac{\partial f}{\partial u}\right|_{\overline{x},\overline{u}}}}\cdot\delta u\left(t\right)\\
\delta y\left(t\right)=y\left(t\right)-\overline{y}=\overset{{\scriptstyle C}}{\overbrace{\left.\dfrac{\partial g}{\partial x}\right|_{\overline{x},\overline{u}}}}\cdot\delta x\left(t\right)+\overset{{\scriptstyle D}}{\overbrace{\left.\dfrac{\partial g}{\partial u}\right|_{\overline{x},\overline{u}}}}\cdot\delta u\left(t\right)
\end{array}\label{eq:Forma-linearizzata-sistema-LTI}
\end{equation}
Ritroviamo le equazioni della forma standard (\ref{eq:Forma-standard-matrice-LTI});
l'approssimazione fatta vale in un intorno appropriato dell'equilibrio.
Come per i sistemi lineari, valgono i risultati sulla stabilità asintotica
e sul segno degli autovalori della matrice di stato $A$. In particolare
enunciamo i seguenti teoremi:
\begin{thm}
Lo stato di equilibrio $\overline{x}$ relativo all'ingresso $\overline{u}$
per un sistema non lineare della forma (\ref{eq:Forma-standard-matrice-LTI}),
si dice asintoticamente stabile se tutti gli autovalori della matrice
di stato $A$ del sistema (\ref{eq:Forma-linearizzata-sistema-LTI})
hanno parte reale negativa.
\end{thm}
%
\begin{thm}
Lo stato di equilibrio $\overline{x}$ relativo all'ingresso $\overline{u}$
per un sistema non lineare della forma (\ref{eq:Forma-standard-matrice-LTI}),
si dice instabile se almeno uno degli autovalori della matrice di
stato $A$ del sistema (\ref{eq:Forma-linearizzata-sistema-LTI})
ha parte reale negativa.
\end{thm}
Si nota che entrambi i teoremi sono i corrispettivi dei \ref{thm:Teorema-dell'asintotica-stabilit=0000E0}
e \ref{thm:Teorema-dell'instabilit=0000E0}, ma per i sistemi non
lineari le condizioni poste sono solo sufficienti; nel caso di autovalori
nulli non è possibile, a partire da un equilibrio di un sistema linearizzato,
determinare la sua stabilità.

\subsection{Metodo grafico per sistemi non lineari}

Tale metodo è applicabile solo per sistemi di ordine molto piccolo,
nel nostro caso di ordine 1; questo metodo è una alternativa alla
linearizzazione che però coinvolge il disegno della funzione di stato
su un grafico costruito in un certo modo.

Consideriamo $\dot{x}\left(t\right)=f\left(t\right)$ costante con
$x\in\mathbb{R}$; rappresentiamo sul riferimento $\left(\dot{x}\left(t\right),\,x\left(t\right)\right)$
l'andamento della derivata della funzione di stato, e osserviamo che:
\begin{itemize}
\item I punti in cui la funzione $f\left(t\right)$ (la derivata dello stato)
si annulla rappresentano gli equilibri dello stato;
\item La stabilità degli equilibri individuati è determinata dal segno della
funzione $f\left(t\right)$:
\begin{itemize}
\item se la funzione decresce a destra e cresce a sinistra (riporta lo stato
sul valore di equilibrio) l'equilibrio è asintoticamente stabile;
\item se la funzione cresce o decresce sia a destra che a sinistra, l'equilibrio
è stabile semplicemente;
\item se la funzione cresce a destra e decresce a sinistra (allontana lo
stato dal valore di equilibrio) l'equilibrio è instabile.
\end{itemize}
\end{itemize}
\begin{figure}[!h]
\begin{centering}
\includegraphics{\string"Illustrazioni/1_8-1 Metodo grafico stabilità sistemi non lineari\string".pdf}
\par\end{centering}
\centering{}\caption{\label{fig:Funzione-di-stato-metodo-grafico}Funzione di stato analizzata
col metodo grafico}
\end{figure}

\begin{example}
\emph{Sia dato il grafico in figura che indica l'andamento dell'equazione
di stato in funzione dello stato, in un sistema di ordine 1: $\checkmark$determinare
la stabilità degli eventuali equilibri.}

Notiamo che la funzione di stato (una cosinusoide) si annulla in tre
punti, che chiameremo in ordine 1, 2 e 3; osservando il segno della
funzione (se si trova al di sopra o al di sotto dell'asse orizzontale)
giungiamo alle seguenti conclusioni:
\end{example}
\begin{enumerate}
\item equilibrio instabile;
\item equilibrio asintoticamente stabile;
\item equilibrio instabile.\demo
\end{enumerate}

\chapter{Sistemi dinamici a tempo discreto}

\section{Modello matematico nel tempo discreto}

\subsection{Processi a tempo discreto}

Le considerazioni già fatte per i sistemi lineari a tempo continuo
valgono ancora, con degli accorgimenti, per i sistemi a tempo discreto.
Questi ultimi presentano la variabile temporale definita in istanti
atomici ($k\in\mathbb{Z}$), e la dinamica del sistema evolve per
successione di istanti.

La riscrittura del modello matriciale standard per i sistemi a tempo
discreto è la seguente:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Equazioni di un processo a tempo discreto}{\footnotesize{}\index{tempo discreto, equazioni di processo@{\footnotesize{}tempo discreto, equazioni di processo}}}}[0.2cm]
\begin{equation}
\begin{cases}
x\left(k+1\right)=f\left(x\left(k\right),\,u\left(k\right),\,k\right) & \text{Equazione di stato}\\
y\left(k\right)=g\left(x\left(k\right),\,u\left(k\right),\,k\right) & \text{Equazione di uscita}
\end{cases}\label{eq:Modello-standard-sistemi-tempo-discreto}
\end{equation}
In generale lo stato ha $n$ dimensioni e l'ingresso $m$ dimensioni,
mentre l'uscita $p$ dimensioni, come secondo (\ref{eq:Dimensioni-coeff-matrici-standard}).

Definiamo i movimenti generati da questa categoria di sistemi, a fronte
di condizione iniziale $x_{0}=x\left(k_{0}\right)$ e l'andamento
dell'ingresso $u\left(k\right)$ per $k\geq0$, iterando l'equazione
(\ref{eq:Modello-standard-sistemi-tempo-discreto}) fino al $k-$esimo
istante di interesse; l'istante di tempo discreto può riferirsi sia
a eventi periodici (ogni minuto, primo di ogni mese) oppure a eventi
che non dipendono dallo scorrere del tempo (auto che entra in un parcheggio,
temperatura che supera un certo valore)
\begin{example}
Definiamo le seguenti variabili:

Le scorte in un magazzino a inizio mese successivo (con $k$ indice
del mese attuale) come 
\[
s\left(k+1\right)=a\cdot s\left(k\right)+q\left(k\right)-v\left(k\right)
\]
con $a$ indice di deperimento, $q\left(k\right)$ la quantità prodotta,
$v\left(k\right)$ la quantità venduta; l'andamento delle vendite
può essere visto come
\[
\alpha\left(k\right)-\beta\left(k\right)\cdot p\left(k\right)
\]
con $\alpha\left(k\right)$ la domanda, $\beta\left(k\right)$ il
comportamento degli acquirenti, $p\left(k\right)$ il prezzo ($\alpha,\,\beta>0$);
la politica di prezzo è definito da
\[
p\left(k+1\right)=p\left(k\right)+\gamma\left(k\right)\cdot\left(s_{0}\left(k\right)-s\left(k\right)\right)+\delta\left(k\right)\cdot v\left(t\right)
\]
con $\gamma\left(k\right)$ le scorte in magazzino, $s_{0}$ il valore
di riferimento per la quantità da tenere in magazzino, $\delta\left(k\right)$
variabile decisionale dell'azienda rispetto alle vendite; vogliamo
misurare il profitto mensile definito come
\[
g\left(k\right)=p\left(k\right)\cdot v\left(k\right)-\zeta\left(k\right)\cdot q\left(k\right)
\]
con $\zeta\left(k\right)$ il costo di produzione.

Adoperiamo come stati le variabili di cui è nota l'espressione all'\emph{istante
successivo} ($k+1$) e come ingressi i seguenti, assegnati:
\[
x\left(k\right)=\begin{bmatrix}x_{1}\left(k\right)\\
x_{2}\left(k\right)
\end{bmatrix}=\begin{bmatrix}s\left(k\right)\\
p\left(k\right)
\end{bmatrix};\;u\left(k\right)=\begin{bmatrix}u_{1}\left(k\right)\\
u_{2}\left(k\right)\\
u_{3}\left(k\right)
\end{bmatrix}=\begin{bmatrix}q\left(k\right)\\
\alpha\left(k\right)\\
s_{0}\left(k\right)
\end{bmatrix}
\]
per quanto riguarda $a,\,\beta\left(k\right),\,\gamma\left(k\right),\,\delta\left(k\right),\,\zeta\left(k\right)$
essi sono \uline{parametri}; infine poniamo l'uscita $y\left(k\right)=g\left(k\right)$.

Il modello del sistema con queste premesse sarà il seguente:
\[
\begin{array}{c}
x\left(k+1\right)=ax_{1}\left(k\right)+u_{1}\left(k\right)-u_{2}\left(k\right)+\beta\left(k\right)x_{2}\left(k\right)\\
x_{2}\left(k+1\right)=x_{2}\left(k\right)+\gamma\left(k\right)u_{3}\left(k\right)-\gamma\left(k\right)x_{1}\left(k\right)+\delta\left(k\right)u_{2}\left(k\right)-\delta\left(k\right)\beta\left(k\right)x_{2}\left(k\right)\\
y\left(k\right)=x_{2}\left(k\right)u_{2}\left(k\right)-x_{2}^{2}\left(k\right)\beta\left(k\right)-\zeta\left(k\right)u_{1}\left(k\right)
\end{array}
\]
Da questo modello osserviamo che (come per i sistemi a tempo continuo,
analizzando le equazioni in forma standard) il sistema è classificabile
come: dinamico (possiede almeno uno stato) del secondo ordine (due
stati in totale), ha più ingressi e una uscita (MISO), tempo-variante
(i \uline{parametri} delle equazioni dipendono da $k$), non lineare
(l'equazione di uscita presenta uno stato al quadrato e un prodotto
con uno stato), proprio (almeno un ingresso nell'equazione di uscita).\demo
\end{example}
\begin{minipage}[c]{0.6\textwidth}%
Nel prossimo esempio viene proposta la discretizzazione di un sistema
a tempo continuo, procedimento che riguarda l'acquisizione di dati
dal mondo fisico; introduciamo prima il concetto di interazione tra
un sistema a tempo continuo e uno a tempo discreto.

\marginpar{I sistemi che coinvolgono l'interazione tra una componente analogica
(tempo continuo) e una digitale (tempo discreto) sono chiamati cyber-physical
system (CPS)}Prendiamo un sistema dinamico a tempo continuo $s$ (vedi figura \ref{fig:Modello-sistema-discretizzazione}),
dotato di un ingresso $u\left(t\right)$ e una uscita $y\left(t\right)$;%
\end{minipage}%
\begin{minipage}[c]{0.4\textwidth}%
\begin{center}
\includegraphics[scale=0.66]{\string"Illustrazioni/2_1-1 Modello di sistema con discretizzazione\string".pdf}
\par\end{center}
\captionof{figure}{Modello di sistema con discretizzazione}

\label{fig:Modello-sistema-discretizzazione}%
\end{minipage}

essa è acquisita a intervalli di tempo regolari da un dispositivo
chiamato scheda di acquisizione dati (DAQ), che riporta l'uscita $y\left(k\right)$
a un controllore digitale $c$ che stabilisce un valore di ingresso
discreto $u\left(k\right)$, che infine viene convertito in un valore
a tempo continuo $u\left(t\right)$ da un componente chiamato \emph{filtro
di mantenimento}.\bigskip{}

\emph{}%
\begin{minipage}[c]{0.6\textwidth}%
\begin{example}
\label{exa:Circuito-RL-elettrovalvola}\emph{Sia dato un circuito
formato da una maglia con induttore e resistore in serie, e sia controllabile
il generatore di tensione in ingresso; $\checkmark$scrivere un modello
che abbia la corrente nella maglia come uscita.}
\end{example}
Chiamiamo la corrente che scorre nella maglia $i\left(t\right)$:
la tensione sul resistore vale $Ri\left(t\right)$ e quella sull'induttore
$v_{{\scriptscriptstyle L}}\left(t\right)=\partial i\left(t\right)/\partial t$;
con un bilancio di tensioni rispetto al generatore controllabile,
vale $u\left(t\right)=Ri\left(t\right)+v_{{\scriptscriptstyle L}}\left(t\right)$.
Poniamo $y\left(t\right)=i\left(i\right)$, come richiesto dall'esempio
e scriviamo:%
\end{minipage}\emph{}%
\begin{minipage}[c]{0.4\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/2_1-2 Modello di circuito per elettrovalvola\string".pdf}
\par\end{center}
\captionof{figure}{Modello di circuito per elettrovalvola}%
\end{minipage}
\[
\dot{x}\left(t\right)=-\dfrac{R}{L}x\left(t\right)+\dfrac{1}{L}u\left(t\right)
\]
ponendo lo stato $x\left(t\right)=i\left(t\right)$ (compare la derivata
della corrente in $v_{{\scriptscriptstyle L}}\left(t\right)$). Nel
passaggio dal mondo analogico a quello digitale discreto c'è l'operazione
di \emph{campionamento}, ovvero l'acquisizione di un segnale a intervalli
regolari: questi intervalli di tempo sono chiamati \emph{passo} di
campionamento ($T_{s}$).

Facciamo un'approssimazione a tempo discreto del sistema, considerando
per ogni passo di campionamento lo stato del sistema in quell'istante,
in cui iniettiamo un ingresso costante fino all'istante successivo;
potremo così risolvere il movimento del sistema (per esempio integrando
per un passo di campionamento con la (\ref{eq:Formula-di-Lagrange})).
Partendo da $x\left(k\right)$, calcoliamo il movimento del sistema
dall'istante successivo $k+1$ come:
\[
x\left(k+1\right)=e^{-\nicefrac{R}{L}T_{s}}x\left(k_{0}\right)+\somme 0{T_{s}}{e^{-\nicefrac{R}{L}\left(T_{s}-\tau\right)}\dfrac{1}{L}u\left(k\right)}{\tau}
\]
\[
=\underset{{\scriptstyle a}}{\underbrace{e^{-\nicefrac{R}{L}T_{s}}}}x\left(k\right)+\underset{{\scriptstyle b}}{\underbrace{\dfrac{1-e^{-\nicefrac{R}{L}T_{s}}}{R}}}u\left(k\right)
\]
Si nota che, essendo il sistema tempo invariante, gli estremi di integrazione
possono essere traslati in $0-T_{s}$ invece di avere $kT_{s}-\left(k+1\right)T_{s}$
(la distanza tra istanti successivi è costante) e il valore di ingresso
$u\left(k\right)$ sarà mantenuto costante tra due istanti successivi.
Inoltre essendo il sistema scalare abbiamo già l'autovalore $a=-R/L$.
Per quanto riguarda l'equazione di uscita, essa rimane invariata come
$y\left(k\right)=x\left(k\right)$, infatti nella discretizzazione
si approssima solo l'operazione di derivazione nelle equazioni di
stato.\demo

Il metodo appena visto nell'Esempio \ref{exa:Circuito-RL-elettrovalvola}
ha dei vantaggi per i sistemi a tempo continuo asintoticamente stabili:
con coefficienti scalari, il sistema deve avere $a<0\land a\in\mathbb{R}$;
nel caso dell'Esempio \ref{exa:Circuito-RL-elettrovalvola} abbiamo
un coefficiente $a$ reale negativo. Se ora iteriamo l'equazione di
stato a tempo discreto, otteniamo:
\[
x\left(k+1\right)=ax\left(k\right)\implies x\left(0\right)=1,\,x\left(1\right)=a,\,x\left(2\right)=a^{2},\,\ldots
\]
Per avere la convergenza a 0 del movimento così definito deve valere
$\left|a\right|<1$; questo approccio garantisce che se abbiamo un
sistema a tempo continuo asintoticamente stabile ($a<0$), anche nel
tempo discreto il nostro sistema sarà stabile ($\left|a\right|<1$
sicuramente) e i movimenti convergeranno; questo non vale per qualsiasi
metodo di discretizzazione.

Un metodo alternativo consiste nell'usare la formula (\ref{eq:Formula-di-Eulero})
approssimando la derivata nel tempo continuo come una differenza finita:
\[
\dot{x}\left(t\right)=\dfrac{\partial x\left(t\right)}{\partial d}\simeq\dfrac{x\left(k+1\right)-x\left(k\right)}{T_{s}}
\]
Questa approssimazione è valida nella misura in cui il passo di campionamento
ha dimensione adeguata rispetto alla velocità del sistema.

Sostituendo questa equazione in quella a tempo continuo del sistema
possiamo ottenere un modello discretizzato; riprendendo l'Esempio
\ref{exa:Circuito-RL-elettrovalvola}, otteniamo le stesse equazioni
di stato e uscita ma i coefficienti avranno forme differenti:
\[
a=1-\dfrac{R}{L}T_{s},\;b=\dfrac{1}{L}T_{s}
\]
In questo caso scegliendo un $T_{s}$ troppo elevato si rischia di
avere un valore di $a$ per cui l'andamento simulato del sistema è
diverso da quello reale.

\subsection{Forma dei movimenti}

Per sistemi lineari a tempo discreto la forma standard è analoga a
(\ref{eq:Forma-standard-matrice-LTI}):\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Modello matriciale per sistemi LTI a tempo
discreto}{\footnotesize{}\index{LTI, modello matriciale discreto@{\footnotesize{}LTI, modello matriciale discreto}}}}
\begin{equation}
\begin{bmatrix}x\left(k+1\right)=A\cdot x\left(k\right)+B\cdot u\left(k\right)\\
y\left(k\right)=C\cdot x\left(k\right)+D\cdot u\left(k\right)
\end{bmatrix}\label{eq:Forma-standard-matrice-LTI-discreto}
\end{equation}
Come condizione iniziale per le successive considerazioni possiamo
imporre $k_{0}=0$ (condizione iniziale $x_{0}=x\left(t_{0}\right)$),
essendo il sistema stazionario; in generale a un certo istante conosciamo
il valore dello stato e possiamo calcolare i movimenti a fronte di
un certo ingresso. Una forma chiusa per il calcolo del movimento di
stato e uscita è offerta dalla riscrittura della (\ref{eq:Formula-di-Lagrange});
essa si ricava applicando ricorsivamente l'equazione di stato, dalla
quale si ottiene poi l'equazione di uscita:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Formula di Lagrange a tempo discreto}{\footnotesize{}\index{Lagrange, formula discretizzata@{\footnotesize{}Lagrange, formula discretizzata}}}}[0.5cm]
\begin{equation}
x\left(k\right)=A^{k}\cdot x_{0}+\serie{i=0}{k-1}{A^{k-i-1}\cdot B\cdot u\left(i\right)}\label{eq:Formula-di-Lagrange-discreta}
\end{equation}
L'integrale di convoluzione nel tempo discreto diventa la sommatoria
appena mostrata; questo risultato intuitivo si ottiene con l'iterazione
dell'equazione di stato; prendendo il caso di $k=1$, otteniamo da
(\ref{eq:Forma-standard-matrice-LTI-discreto}):
\[
x\left(2\right)=A\cdot x\left(1\right)+B\cdot u\left(1\right)=A\cdot\left(A\cdot x\left(0\right)+B\cdot u\left(0\right)\right)+B\cdot u\left(0\right)
\]
da cui la sommatoria nella formula di Lagrange discretizzata. 

Distinguiamo dalla (\ref{eq:Formula-di-Lagrange-discreta}) i movimenti
libero e forzato:
\begin{itemize}
\item movimento libero $x_{{\scriptscriptstyle \text{L}}}\left(k\right)=A^{k}\cdot x_{0}$:
è indipendente dagli ingressi e legato alle condizioni iniziali;
\item movimento forzato $x_{{\scriptscriptstyle \text{F}}}\left(k\right)=\serie{i=0}{k-1}{A^{k-i-1}\cdot B\cdot u\left(i\right)}$:
è legato agli ingressi.
\end{itemize}

\subsection{Sovrapposizione degli effetti}

Le equazioni per i sistemi a tempo discreto rimangono lineari, dunque
vale la sovrapposizione degli effetti come nel tempo continuo: se
abbiamo due condizioni iniziali $x^{\prime}\left(0\right)$ e $x^{\prime\prime}\left(0\right)$,
e due andamenti $x^{\prime}\left(k\right)$ e $x^{\prime\prime}\left(k\right)$,
posto che l'ingresso $u^{\prime\prime\prime}\left(k\right)=\alpha u^{\prime}\left(k\right)+\beta u^{\prime\prime}\left(k\right)$
possiamo vedere il movimento dello stato a partire dalle coppie stato-ingresso
come combinazione lineare dei movimenti ottenuti separatamente dalle
condizioni iniziali e dagli ingressi separatamente:
\[
\begin{array}{c}
x^{\prime}\left(k\right)=f\left(x^{\prime}\left(0\right),\,u^{\prime}\left(k\right)\right)\\
+\\
x^{\prime\prime}\left(k\right)=f\left(x^{\prime\prime}\left(0\right),\,u^{\prime\prime}\left(k\right)\right)
\end{array}=\;\begin{cases}
x^{\prime\prime\prime}\left(k\right)=\alpha x^{\prime}\left(k\right)+\beta x^{\prime\prime}\left(k\right)\\
y^{\prime\prime\prime}\left(k\right)=\alpha y^{\prime}\left(k\right)+\beta y^{\prime\prime}\left(k\right)
\end{cases}
\]
dove $f\left(x\left(0\right),\,u\left(k\right)\right)$ rappresenta
la (\ref{eq:Formula-di-Lagrange-discreta}) con condizione iniziale
$x\left(0\right)$e ingresso $u\left(k\right)$.

Si può facilmente verificare questa proprietà per sostituzione; l'equazione
di uscita in forma chiusa, dalla (\ref{eq:Formula-di-Lagrange-discreta}),
vale allora:
\begin{equation}
y\left(k\right)=C\cdot A^{k}\cdot x_{0}+C\cdot\serie{i=0}{k-1}{A^{k-i-1}\cdot B\cdot u\left(i\right)}+D\cdot u\left(k\right)\label{eq:Movimento-uscita-Lagrange-discreto}
\end{equation}


\section{Comportamento nel tempo discreto}

\subsection{Equilibrio}

Un movimento di un sistema a tempo discreto si ottiene iterando l'equazione
di stato fino all'istante di interesse. Una coppia di ingressi $\overline{x}$
e uscite $\overline{u}$ è un equilibrio se $\overline{x}=f\left(\overline{x},\,\overline{u},\,k\right)$;
l'equazione di stato infatti restituisce lo stato all'istante successivo
e se questo è uguale allo stato attuale, si ha un andamento costante
dello stato nel tempo. L'uscita di equilibrio è funzione della coppia
$\overline{x},\,\overline{u}$; in breve:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Condizione di equilibrio nel tempo discreto}{\footnotesize{}\index{tempo discreto, equilibrio@{\footnotesize{}tempo discreto, equilibrio}}}}[0.2cm]
\begin{equation}
\begin{array}{c}
\overline{x}=f\left(\overline{x},\,\overline{u}\right)\\
\overline{y}=g\left(\overline{x},\,\overline{u}\right)
\end{array}\label{eq:Condizioni-equilibrio-tempo-discreto}
\end{equation}
Nel caso di un sistema a coefficienti scalari dovrà valere $\overline{x}=a\overline{x}+b\overline{u}$,
da cui $\overline{x}=\dfrac{b}{1-a}\overline{u}$; esse sono tutte
le coppie ingresso-stato di equilibrio per il sistema in esame. Il
modello del sistema nella forma (\ref{eq:Modello-standard-sistemi-tempo-discreto}),
nelle condizioni di equilibrio (\ref{eq:Condizioni-equilibrio-tempo-discreto}),
si scriverà come
\[
\begin{cases}
\overline{x}=A\cdot\overline{x}+B\cdot\overline{u}\\
\overline{y}=C\cdot\overline{x}+D\cdot\overline{u}
\end{cases}
\]
Lo stato di equilibrio esiste solo se l'equazione di stato per l'equilibrio
ammette una e una sola soluzione; questo si verifica quando $\det\left(I-A\right)\neq0$,
e in tal caso possiamo scrivere $\overline{x}=\left(I-A\right)^{-1}\cdot B\cdot\overline{u}$
per l'equilibrio dello stato e $\overline{y}=\left(C\cdot\left(I-A\right)^{-1}\cdot B+D\right)\overline{u}$
per l'equilibrio di uscita, dove la matrice a cui l'uscita è moltiplicata
è detta matrice dei \emph{guadagni statici} (è una relazione statica
tra ingressi costanti e uscite costanti).

Se $\left(I-A\right)$ non fosse invertibile si potrebbero avere nessuna
o infinite soluzioni (non nulle), sempre che per un $\overline{u}$
si riesca a trovare $\overline{x}$ di equilibrio; la coppia ingresso-uscita
di equilibrio nulla risolve comunque il sistema.

\subsection{Stabilità}

Nei sistemi a tempo discreto possiamo enunciare le seguenti proprietà
e definizioni, analoghe a quelle dei sistemi a tempo continuo (non
siamo necessariamente nell'ambito dei sistemi lineari):
\begin{defn}
\label{def:Stabilit=0000E0-tempo-discreto}Un movimento $x\left(k\right)$
per $k\geq k_{0}$, generato da un sistema dinamico a partire da $x\left(k_{0}\right)=x_{0}$
e con ingresso $u\left(k\right)$, si dice \emph{stabile} se per ogni
$\varepsilon>0$ esiste un $\delta>0$ tale che, per ogni condizione
iniziale perturbata $\tilde{x}\left(k_{0}\right)=\tilde{x}_{0}$ che
sia distante dalla condizione iniziale nominale $x_{0}$ di una quantità
in norma minore di $\delta$, risulta che la distanza tra la traiettoria
nominale $x\left(k\right)$ e quella perturbata $\tilde{x}\left(k\right)$
rimanga limitata in un intorno minore o uguale a $\varepsilon$ per
qualunque $k\geq k_{0}$; chiamiamo $\tilde{x}\left(k\right)$ il
movimento generato dal sistema a fronte del medesimo ingresso $u\left(k\geq k_{0}\right)$
e condizioni iniziali $\tilde{x}_{0}$. In termini di formula logica
deve valere
\begin{equation}
\forall\varepsilon>0\,\exists\delta>0\,\left(\forall\tilde{x}_{0}\left(\left\Vert \tilde{x}_{0}-x_{0}\right\Vert \leq\delta\Rightarrow\forall k\geq k_{0}\left(\left\Vert \tilde{x}\left(k\right)-x\left(k\right)\right\Vert \leq\varepsilon\right)\right)\right)\label{eq:Stabilit=0000E0-tempo-discreto}
\end{equation}
\end{defn}
%
\begin{defn}
Un movimento $x\left(k\right)$ generato da un sistema a tempo discreto
è \emph{instabile} se non soddisfa la Definizione \ref{def:Stabilit=0000E0-tempo-discreto}.
\end{defn}
%
\begin{defn}
Un movimento generato da un sistema a tempo discreto si dice \emph{asintoticamente
stabile} se soddisfa la Definizione \ref{def:Stabilit=0000E0-tempo-discreto}
e vale inoltre
\[
\lm k{\infty}{\left\Vert x\left(k\right)-\tilde{x}\left(k\right)\right\Vert =0}
\]
\end{defn}

\section{Rappresentazione equivalente discreta}

Presa una matrice di trasformazione $T$ invertibile, definiamo uno
stato equivalente $\hat{x}\left(k\right)$ come combinazione lineare
dello stato originale $x\left(k\right)$; vale la seguente relazione
tra stato originale ed equivalente:
\[
x\left(k\right)=T^{-1}\cdot\hat{x}\left(k\right)\,\leftrightarrows\,\hat{x}\left(k\right)=T\cdot x\left(k\right)
\]
Possiamo parlare di rappresentazioni equivalenti di sistemi LTI a
tempo discreto, in particolare se il sistema di partenza è della forma
(\ref{eq:Forma-standard-matrice-LTI-discreto}), con questa trasformazione
otteniamo la rappresentazione equivalente:
\begin{equation}
\begin{array}{c}
\hat{x}\left(k+1\right)=T\cdot A\cdot T^{-1}\cdot\hat{x}\left(k\right)+T\cdot B\cdot u\left(k\right)\\
y\left(k\right)=C\cdot T^{-1}\cdot\hat{x}\left(k\right)+D\cdot u\left(k\right)
\end{array}\label{eq:Rappresentazione-equivalente-discreta}
\end{equation}


\section{Movimenti nel tempo discreto}

\subsection{Modi e autovalori}

Il movimento libero nel tempo discreto di un sistema LTI è definito
$x_{{\scriptscriptstyle \text{L}}}\left(k\right)=A^{k}\cdot x_{0}$
dalla (\ref{eq:Formula-di-Lagrange-discreta}); come nel caso del
tempo continuo, sfruttiamo la rappresentazione equivalente (\ref{eq:Rappresentazione-equivalente-discreta})
più comoda per calcolare il movimento libero.

Se la matrice di stato è diagonalizzabile esisterà una matrice di
trasformazione $T_{{\scriptscriptstyle \text{D}}}$ che rende $A$
simile ad $A_{{\scriptscriptstyle \text{D}}}$, quest'ultima una matrice
diagonale con gli stessi autovalori $z_{i}$ di $A$; tale matrice
di trasformazione verifica le seguenti equazioni:
\[
A_{{\scriptscriptstyle \text{D}}}=T_{{\scriptscriptstyle \text{D}}}\cdot A\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}\,\leftrightarrows\,A=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot T_{{\scriptscriptstyle \text{D}}}
\]
Iteriamo la precedente equazione per calcolare $A^{k}$ dalla matrice
diagonale simile, ottenendo:
\[
A^{k}=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot\cancel{T_{{\scriptscriptstyle \text{D}}}}\cdot\cancel{T_{{\scriptscriptstyle \text{D}}}^{-1}}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot T_{{\scriptscriptstyle \text{D}}}\ldots=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}^{k}\cdot T_{{\scriptscriptstyle \text{D}}}
\]
dove la potenza di matrice diagonale $A_{{\scriptscriptstyle \text{D}}}^{k}$
è una matrice diagonale con elementi sulla diagonale elevati a $k$:
$A_{{\scriptscriptstyle \text{D}}}^{k}=\begin{bmatrix}z_{1}^{k} & 0 & 0\\
0 & \ddots & 0\\
0 & 0 & z_{n}^{k}
\end{bmatrix}$.

Ritornando all'equazione del movimento libero, possiamo ora riscriverla
come $x_{{\scriptscriptstyle \text{L}}}\left(k\right)=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}^{k}\cdot T_{{\scriptscriptstyle \text{D}}}\cdot x_{0}$;
questo movimento libero generico sarà una combinazione lineare dipendente
dal valore iniziale degli stati e dalla matrice di trasformazione,
e avrà una scrittura del tipo $\alpha_{1}z_{1}^{k}+\alpha_{2}z_{2}^{k}+\ldots+\alpha_{n}z_{n}^{k}$.
Al contrario dei movimenti esponenziali, generati dai sistemi a tempo
continuo, nel tempo discreto i movimenti assumono forma polinomiale.

Gli autovalori (della matrice di stato $A$) $z_{i}$ con $i\in\left[1,\,n\right]$
si dicono \emph{modi} del sistema a tempo discreto.

\subsection{Segno degli autovalori}

Nel caso di autovalori reali, dobbiamo distinguere i seguenti casi:
\begin{itemize}
\item $z_{i}\in\mathbb{R},\,z_{i}>0$:
\begin{itemize}
\item $z_{i}=1$: vale $z_{i}^{k}=\text{costante}\,\forall k\in\mathbb{Z}$;
\item $z_{i}>1$: vale $z_{i}^{k}=\text{polinomio divergente}$;
\item $z_{i}<1$: vale $z_{i}^{k}=\text{polinomio convergente}$.
\end{itemize}
\item $z_{i}\in\mathbb{R},\,z_{i}<0$:
\begin{itemize}
\item $\left|z_{i}\right|=1$: vale $z_{i}^{k}=\text{limitato tra }\left[-1,\,1\right]$;
\item $\left|z_{i}\right|>1$: vale $z_{i}^{k}=\text{divergente a segni alterni}$;
\item $\left|z_{i}\right|<1$: vale $z_{i}^{k}=\text{convergente a segni alterni}$.
\end{itemize}
\end{itemize}
\marginpar{Con l'apice $^{*}$ si indica il coniugato di un numero complesso,
ovvero il corrispettivo con la parte immaginaria di segno opposto}Nel caso di valori complessi coniugati i modi sono sempre $z_{1,2}=\left(\sigma\pm j\omega\right)^{k}$;
per la loro analisi adottiamo la rappresentazione polare:
\[
\rho=\sqrt{\sigma^{2}+\omega^{2}},\;\phi=\arg\left(z_{i}\right)
\]
da cui gli autovalori valgono $z_{1,2}=\rho e^{\pm j\phi}$ e i modi
$z_{1,2}^{k}=\rho^{k}e^{\pm jk\phi}$; questi modi saranno sempre
combinati, nel movimento complessivo, con dei coefficienti $\alpha$
anch'essi complessi coniugati, in generale nella forma $\alpha=\rho_{\alpha}e^{j\phi_{\alpha}}$.

La combinazione lineare dei modi associati agli autovalori complessi
coniugati è:
\[
x_{{\scriptscriptstyle \text{L}}}\left(k\right)=\alpha z_{1}+\alpha^{*}z_{2}=\rho_{\alpha}\rho^{k}e^{j\left(k\phi+\phi_{\alpha}\right)}+\rho_{\alpha}\rho^{k}e^{-j\left(k\phi+\phi_{\alpha}\right)}
\]
\begin{equation}
=\rho_{\alpha}\rho^{k}\left(e^{j\left(k\phi+\phi_{\alpha}\right)}+e^{-j\left(k\phi+\phi_{\alpha}\right)}\right)\overset{{\scriptscriptstyle \text{Eulero}}}{=}\boxed{2\rho_{\alpha}\rho^{k}\cos\left(k\phi+\phi_{\alpha}\right)}\label{eq:Movimento-libero-discreto-complesso}
\end{equation}
dove abbiamo usato la (\ref{eq:Formula-di-Eulero}) nell'ultima uguaglianza,
e i coefficienti in pedice $_{\alpha}$ sono dipendenti dalle condizioni
iniziali; la convergenza del movimento è determinata dal segno dominante
di $\rho^{k}$ (in particolare $\rho$ è il modulo dell'autovalore),
infatti la funzione coseno è limitata e $\rho_{\alpha}$ è costante.
Come per il caso dell'autovalore reale, si osserva il modulo degli
autovalori per determinarne l'andamento generato.
\begin{example}
\emph{Sia dato un sistema LTI a tempo discreto con la seguente matrice
di stato:
\[
A=\begin{bmatrix}1 & 1\\
-1 & 1
\end{bmatrix}
\]
$\checkmark$Si calcoli il movimento libero del sistema in generale.}

Cominciamo calcolando gli autovalori di $A$:
\[
\det\left(zI-A\right)=0\rightarrow\begin{vmatrix}z-1 & -1\\
1 & z-1
\end{vmatrix}=0\rightarrow z^{2}-2z+2=0\rightarrow z_{1,2}=1\pm j
\]
Per questi due autovalori complessi coniugati abbiamo $\rho=\sqrt{2}$
e $\phi=\pi/4$. Il movimento associato alla combinazione lineare
di questi due modi sarà nella forma (\ref{eq:Movimento-libero-discreto-complesso}):
\[
\rho_{\alpha}2\left(\sqrt{2}\right)^{k}\cos\left(k\dfrac{\pi}{4}+\phi_{\alpha}\right)
\]
Una possibile scelta per la matrice di trasformazione, presi autovettori
associati a $z_{1,2}$ con base canonica unitaria, è la seguente:
\[
T_{{\scriptscriptstyle \text{D}}}^{-1}=\begin{bmatrix}1 & 1\\
j & -j
\end{bmatrix}\rightarrow T_{{\scriptscriptstyle \text{D}}}=\dfrac{1}{2}\cdot\begin{bmatrix}1 & -j\\
1 & j
\end{bmatrix}
\]
Il generico movimento libero sarà scritto come:
\[
x_{{\scriptscriptstyle \text{L}}}\left(k\right)=\overset{{\scriptstyle T_{{\scriptscriptstyle \text{D}}}^{-1}}}{\overbrace{\begin{bmatrix}1 & 1\\
j & -j
\end{bmatrix}}}\cdot\overset{{\scriptstyle A_{{\scriptscriptstyle \text{D}}}}}{\overbrace{\begin{bmatrix}\left(\sqrt{2}e^{j\nicefrac{\pi}{4}}\right)^{k} & 0\\
0 & \left(\sqrt{2}e^{-j\nicefrac{\pi}{4}}\right)^{k}
\end{bmatrix}}}\cdot\overset{{\scriptstyle T_{{\scriptscriptstyle \text{D}}}}}{\overbrace{\dfrac{1}{2}\cdot\begin{bmatrix}1 & -j\\
1 & j
\end{bmatrix}}}\cdot x_{0}
\]
\[
=\left(\sqrt{2}\right)^{k}\cdot\begin{bmatrix}\cos\left(k\nicefrac{\pi}{4}\right) & -\sin\left(k\nicefrac{\pi}{4}\right)\\
\sin\left(k\nicefrac{\pi}{4}\right) & \cos\left(k\nicefrac{\pi}{4}\right)
\end{bmatrix}\cdot x_{0}
\]
Da questa scrittura è possibile calcolare qualsiasi movimento del
sistema a fronte di condizioni iniziali.\demo\smallskip{}
\end{example}
Possiamo distinguere gli andamenti dei modi nel tempo discreto studiando
il modulo degli autovalori e considerando se sono complessi coniugati
(vedi \tabref{Classificazione-movimenti-discreti})

\begin{table}[!h]
\begin{centering}
\begin{tabular}{c>{\centering}m{0.55\textwidth}}
$_{\text{Insieme}}\backslash^{\text{Modulo}}$ & $\left|z_{i}\right|<1$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{R}$ & $\begin{array}{l}
z_{i}>0\rightarrow\text{\ensuremath{{\scriptstyle \text{converge asintotico}}}}\\
z_{i}=0\rightarrow\text{\ensuremath{{\scriptstyle \text{converge in tempo finito}}}}\\
z_{i}<0\rightarrow\text{\ensuremath{{\scriptstyle \text{converge a segno alterno}}}}
\end{array}$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{C}$ & $\text{\ensuremath{{\scriptstyle \text{converge come inviluppo di cosinusoide}}}}$\tabularnewline
\hline 
\noalign{\vskip\doublerulesep}
\end{tabular}
\par\end{centering}
\begin{centering}
\begin{tabular}{c>{\centering}m{0.55\textwidth}}
\hline 
$_{\text{Insieme}}\backslash^{\text{Modulo}}$ & $\left|z_{i}\right|>1$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{R}$ & $\begin{array}{l}
z_{i}>1\rightarrow\text{\ensuremath{{\scriptstyle \text{diverge polinomiale}}}}\\
z_{i}<-1\rightarrow\text{\ensuremath{{\scriptstyle \text{diverge polinomiale a segni alterni}}}}
\end{array}$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{C}$ & $\text{\ensuremath{{\scriptstyle \text{diverge come inviluppo di cosinusoide}}}}$\tabularnewline
\hline 
\noalign{\vskip\doublerulesep}
\end{tabular}
\par\end{centering}
\begin{centering}
\begin{tabular}{c>{\centering}m{0.55\textwidth}}
\hline 
$_{\text{Insieme}}\backslash^{\text{Modulo}}$ & $\left|z_{i}\right|=1$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{R}$ & $\begin{array}{l}
z_{i}=1\rightarrow\text{\ensuremath{{\scriptstyle \text{limitato e costante}}}}\\
z_{i}=-1\rightarrow\text{\ensuremath{{\scriptstyle \text{limitato a segni alterni}}}}
\end{array}$\tabularnewline
\noalign{\vskip\doublerulesep}
$z_{i}\in\mathbb{C}$ & $\Re\left(z_{i}\right)=0,\,\Im\left(z_{i}\right)=\pm1\rightarrow\text{\ensuremath{{\scriptstyle \text{limitato come cosinusoide}}}}$\tabularnewline
\noalign{\vskip\doublerulesep}
\end{tabular}
\par\end{centering}
\smallskip{}
\caption{Classificazione dei movimenti nel tempo discreto\label{tab:Classificazione-movimenti-discreti}}
\end{table}

Per concludere il discorso sui modi nel tempo discreto, esaminiamo
il caso di una matrice di stato non diagonalizzabile: cercheremo di
scriverla nella forma di Jordan (\ref{eq:Forma-di-Jordan}), trovando
una matrice di trasformazione $T_{{\scriptscriptstyle \text{J}}}$
adeguata. Compariranno dei modi aggiuntivi nella matrice, al di sopra
della diagonale principale; si avranno dunque sulla diagonale i modi
$z_{i}^{k}$, mentre al di sopra i modi $k^{\eta-1}z^{k-\eta-1}$
dove $\eta$ dipende dalle molteplicità degli autovalori e $i$ è
l'indice di colonna nella matrice.

Le proprietà di convergenza di questi nuovi modi sono determinate
sempre dal modulo dell'autovalore $z$ (l'esponenziale di $z$ domina
sulla potenza di $k$ costante), quindi sono soggetti alle considerazioni
esposte ne \tabref{Classificazione-movimenti-discreti}; rispetto
ad essa, per $\left|z_{i}\right|=1$ si hanno modi divergenti, a causa
del contributo del coefficiente $k$.

\section{Stabilità del sistema}

\subsection{Condizioni di stabilità in sistemi a tempo discreto}

Se prendiamo un movimento $x\left(k\right)$ a partire da $x_{0}$
e un movimento perturbato $\tilde{x}\left(k\right)$ a partire da
$\tilde{x}_{0}=x_{0}+\delta x_{0}$, a parità di ingresso $u\left(k\right)$
studiamo il comportamento di $\delta x\left(k\right)=\tilde{x}\left(k\right)-x\left(k\right)$;
con l'equazione (\ref{eq:Formula-di-Lagrange-discreta}) otteniamo
l'andamento della perturbazione:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Movimenti nel tempo discreto}{\footnotesize{}\index{tempo discreto, movimenti@{\footnotesize{}tempo discreto, movimenti}}}}[-8cm]
\begin{equation}
A^{k}\left(\tilde{x}_{0}-x_{0}\right)=A^{k}\delta x_{0}\label{eq:Andamento-perturbazione-discreta}
\end{equation}
Questo risultato non dipende dall'ingresso né dalla perturbazione:
esso è la risposta libera del sistema alla perturbazione considerata.
\begin{rem}
In un sistema LTI a tempo discreto, presa qualsiasi coppia di movimento
e movimento perturbato, la distanza tra i due movimenti è data sempre
dalla (\ref{eq:Andamento-perturbazione-discreta}); da questo deriva
il seguente Teorema \ref{thm:Stabilit=0000E0-sistema-LTI-discreto}.
\end{rem}
\begin{thm}
\label{thm:Stabilit=0000E0-sistema-LTI-discreto}In un sistema LTI
a tempo dinamico un movimento (incluso quello di equilibrio) è stabile,
asintoticamente stabile o instabile se e solo se sono rispettivamente
stabili, asintoticamente stabili o instabili tutti i movimenti del
sistema.
\end{thm}
\begin{rem}
Notiamo che essendo (\ref{eq:Andamento-perturbazione-discreta}) un
movimento libero, questa espressione è combinazione lineare dei modi
del sistema e il suo andamento dipende dagli autovalori della matrice
di stato. Per il Teorema \ref{thm:Stabilit=0000E0-sistema-LTI-discreto}
possiamo controllare la stabilità del sistema studiando quella dei
sui movimenti liberi.
\end{rem}
Possiamo usare le condizioni ne \tabref{Classificazione-movimenti-discreti}
assieme alla precedente osservazione per ottenere le seguenti considerazioni:
\begin{thm}
Un sistema LTI della forma (\ref{eq:Forma-standard-matrice-LTI-discreto})
si dice asintoticamente stabile se e solo se \uline{tutti} gli
autovalori della sua matrice di stato sono in modulo minori di 1 (ovvero
(\ref{eq:Andamento-perturbazione-discreta}) converge a zero).
\end{thm}
%
\begin{thm}
Un sistema LTI della forma (\ref{eq:Forma-standard-matrice-LTI-discreto})
si dice instabile se \uline{almeno uno} degli autovalori della
sua matrice di stato è in modulo maggiore di 1.
\end{thm}
Se il modulo degli autovalori è unitario, distinguiamo i seguenti
casi per studiare la stabilità del sistema:
\begin{itemize}
\item Con $A$ diagonalizzabile, se $\nexists i\in0\ldots\eta_{n}\,:\,\left|z_{i}\right|>1$
allora il sistema è stabile semplicemente;
\item Con $A$ non diagonalizzabile, il sistema è instabile.
\end{itemize}
Elenchiamo ora alcune proprietà dei sistemi LTI a tempo discreto asintoticamente
stabili:
\begin{enumerate}
\item Un movimento per $k\rightarrow\infty$ non dipende dalle condizioni
iniziali $x\left(k_{0}\right)$;
\item La risposta a un impulso tende ad annullarsi per $t\rightarrow\infty$;
\item La risposta a qualunque ingresso limitato nel tempo tende ad annullarsi
per $t\rightarrow\infty$;
\item Gli stati e le uscite di equilibrio, con ingresso $\overline{u}$
costante nel tempo, sono univocamente definiti e pari a $\overline{x}$
e $\overline{y}$;
\item Il sistema gode della proprietà di stabilità esterna.\bigskip{}
\end{enumerate}

\subsection{Criterio di Jury}

Il polinomio caratteristico di una matrice permette di trovare i suoi
autovalori: se definiamo tale polinomio per i sistemi a tempo discreto
come $\phi\left(z\right)$, gli autovalori associati si trovano a
partire da $\phi\left(z\right)=0$; scrivendo il polinomio nella forma
di combinazione lineare di autovalori $z_{i}$ e coefficienti $\phi_{i}$
avremo
\begin{equation}
\phi\left(z\right)=\phi_{0}z^{n}+\phi_{1}z^{n-1}+\ldots+\phi_{n}\label{eq:Polinomio-caratteristico-discreto}
\end{equation}
Enunciamo un criterio che fornisce una condizione necessaria e sufficiente
per stabilire la stabilità asintotica di un sistema a tempo discreto;
esso si basa sulla seguente \emph{tabella di Jury}, costruita a partire
dal polinomio caratteristico della matrice di stato, scritto nella
forma (\ref{eq:Polinomio-caratteristico-discreto}):
\begin{equation}
\begin{array}{ccccccc}
\phi_{0} & \phi_{1} & \phi_{2} & \ldots & \phi_{n-1} & \phi_{n} & 0\\
h_{0} & h_{1} & h_{2} & \ldots & h_{\nu} & 0 & 0\\
\ell_{1} & \ell_{2} & \ldots & \ell_{\nu-1} & 0 & 0 & 0
\end{array}\label{eq:Tabella-di-Jury}
\end{equation}
Questa tabella si compila grazie al seguente \emph{algoritmo di Jury}
che dalle riga precedente ($h_{i}$) ottiene la successiva ($\ell_{i}$):
\begin{equation}
\ell_{i}=\dfrac{1}{h_{1}}\cdot\det\left(\begin{bmatrix}h_{1} & h_{\nu-i+1}\\
h_{\nu} & h_{i}
\end{bmatrix}\right)\rightarrow h_{i}-\dfrac{h_{\nu}\cdot h_{\nu-i+1}}{h_{1}}\label{eq:Algoritmo-di-Jury}
\end{equation}
Si osserva che in generale la tabella è triangolare, e inoltre l\textquoteright algoritmo
non si può applicare per il caso $h_{1}=0$ per almeno una riga (in
tal caso si dice che la (\ref{eq:Tabella-di-Jury}) non è ben definita).
L\textquoteright algoritmo termina quando si otterrebbe uno zero nella
prima posizione della riga più in basso.
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Criterio di Jury}{\footnotesize{}\index{Jury, criterio@{\footnotesize{}Jury, criterio}}}}\label{thm:Criterio-di-Jury}Un sistema LTI a tempo discreto della
forma (\ref{eq:Forma-standard-matrice-LTI-discreto}) è asintoticamente
stabile se e solo se la tabella di Jury (\ref{eq:Tabella-di-Jury})
del polinomio caratteristico della matrice di stato del sistema è
ben definita, e tutti gli elementi sulla prima colonna della tabella
hanno segno concorde.
\end{thm}
\begin{example}
\emph{Consideriamo un sistema dinamico a tempo discreto, col seguente
polinomio caratteristico:
\[
\phi\left(z\right)=z^{2}+\alpha z+\beta
\]
$\checkmark$Studiare per quali valori di $\alpha$ e $\beta$ il
sistema è stabile.}

Scegliendo di applicare il criterio di Jury, costruiamo la tabella
(\ref{eq:Tabella-di-Jury}) nel modo seguente:

\begin{minipage}[t]{1\columnwidth}%
\begin{center}
\begin{tabular}{cccc}
1 & $\alpha$ & $\beta$ & 0\tabularnewline[\doublerulesep]
\cline{1-3} 
$1-\beta^{2}$ & $\alpha\left(1-\beta\right)$ & 0 & 0\tabularnewline[\doublerulesep]
$1-\beta^{2}-\dfrac{\alpha^{2}\left(1-\beta\right)^{2}}{1-\beta^{2}}$ & 0 & 0 & 0\tabularnewline[\doublerulesep]
\end{tabular}
\par\end{center}%
\end{minipage}

Applicando il Teorema \ref{thm:Criterio-di-Jury} cerchiamo i valori
dei coefficienti che rendano concordi i segni dei termini sulla prima
colonna; otteniamo dunque le seguenti condizioni, osservando che il
termine 1 è positivo:
\[
\begin{cases}
1-\beta^{2}>0 & \left(1\right)\\
1-\beta^{2}-\dfrac{\alpha^{2}\left(1-\beta\right)^{2}}{1-\beta^{2}} & \left(2\right)
\end{cases}=\begin{cases}
\beta\in\left(-1,\,1\right)\\
1+\beta\in\left(-\alpha,\,\alpha\right)
\end{cases}
\]
Per giungere a questa conclusione si è usata la condizione $\left(1\right)$
nella $\left(2\right)$, studiando il segno del numeratore $-\alpha^{2}\left(1-\beta\right)^{2}$.\demo
\end{example}

\section{Sistemi non lineari a tempo discreto}

Prendiamo un sistema a tempo discreto stazionario e non lineare, nella
forma (\ref{eq:Forma-standard-matrice-LTI-discreto}); per risolvere
in forma chiusa il calcolo di un movimento, ci concentriamo sugli
equilibri di questi sistemi: cerchiamo una coppia stato-ingresso $\overline{x},\,\overline{u}$
tale che valga (\ref{eq:Condizioni-equilibrio-tempo-discreto}).

Per studiare la stabilità di questi equilibri, possiamo approssimare
il modello del sistema, localmente alla condizione di equilibrio,
con lo sviluppo di Taylor al primo ordine delle equazioni del sistema;
questa approssimazione lineare si ottiene nel modo seguente:
\[
\begin{array}{c}
f\left(x\left(k\right),\,u\left(k\right)\right)\simeq f\left(\overline{x},\,\overline{u}\right)+\left.\dfrac{\partial f}{\partial x}\right|_{\overline{x},\overline{u}}\left(x\left(k\right)-\overline{x}\right)+\left.\dfrac{\partial f}{\partial u}\right|_{\overline{x},\overline{u}}\left(u\left(k\right)-\overline{u}\right)\\
g\left(x\left(k\right),\,u\left(k\right)\right)\simeq g\left(\overline{x},\,\overline{u}\right)+\left.\dfrac{\partial g}{\partial x}\right|_{\overline{x},\overline{u}}\left(x\left(k\right)-\overline{x}\right)+\left.\dfrac{\partial g}{\partial u}\right|_{\overline{x},\overline{u}}\left(u\left(k\right)-\overline{u}\right)
\end{array}
\]
Se definiamo le quantità $\delta x\left(k\right)=x\left(k\right)-\overline{x}$
per l'equazione di stato e $\delta u\left(k\right)=u\left(k\right)-\overline{u}$
per l'equazione di uscita, le precedenti diventano\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Forma linearizzata nel tempo discreto}{\footnotesize{}\index{Linearizzazione nel tempo discreto@{\footnotesize{}Linearizzazione nel tempo discreto}}}}[1.5cm]
\begin{equation}
\begin{array}{c}
\delta x\left(k+1\right)=f\left(x\left(k\right),\,u\left(k\right)\right)-f\left(\overline{x},\,\overline{u}\right)=\overset{A}{\overbrace{\left.\dfrac{\partial f}{\partial x}\right|_{\overline{x},\overline{u}}}}\delta x\left(k\right)+\overset{B}{\overbrace{\left.\dfrac{\partial f}{\partial u}\right|_{\overline{x},\overline{u}}}}\delta u\left(k\right)\\
\delta y\left(k\right)=g\left(x\left(k\right),\,u\left(k\right)\right)-g\left(\overline{x},\,\overline{u}\right)=\overset{C}{\overbrace{\left.\dfrac{\partial g}{\partial x}\right|_{\overline{x},\overline{u}}}}\delta x\left(k\right)+\overset{D}{\overbrace{\left.\dfrac{\partial g}{\partial u}\right|_{\overline{x},\overline{u}}}}\delta u\left(k\right)
\end{array}\label{eq:Forma-linearizzata-tempo-discreto}
\end{equation}
Ritroviamo le equazioni della forma standard nel tempo discreto (\ref{eq:Forma-standard-matrice-LTI-discreto});
l\textquoteright approssimazione fatta vale in un intorno appropriato
dell'equilibrio. Come per i sistemi lineari, valgono i risultati sulla
stabilità asintotica e sul modulo degli autovalori della matrice di
stato $A$. In particolare enunciamo i seguenti teoremi:
\begin{thm}
Lo stato di equilibrio $\overline{x}$ elativo all'ingresso $\overline{u}$
per un sistema non lineare della forma (\ref{eq:Forma-standard-matrice-LTI-discreto}),
si dice asintoticamente stabile se tutti gli autovalori della matrice
di stato A del sistema (\ref{eq:Forma-linearizzata-tempo-discreto})
hanno modulo strettamente minore di 1.
\end{thm}
%
\begin{thm}
Lo stato di equilibrio $\overline{x}$ relativo all'ingresso $\overline{u}$
per un sistema non lineare della forma (\ref{eq:Forma-standard-matrice-LTI-discreto}),
si dice instabile se almeno uno degli autovalori della matrice di
stato A del sistema (\ref{eq:Forma-linearizzata-tempo-discreto})
ha modulo maggiore di uno.
\end{thm}
Se uno degli autovalori avesse modulo pari a 1, non si potrebbe concludere
nulla sulla sua stabilità, con gli strumenti della linearizzazione;
si noti che i due teoremi appena enunciati forniscono condizioni solo
sufficienti.
\begin{example}
\emph{Sia dato un sistema non lineare a tempo discreto con la seguente
equazione di stato:
\[
\begin{array}{l}
x_{1}\left(k+1\right)=x_{1}^{3}\left(k\right)+x_{2}\left(k\right)x_{3}\left(k\right)\\
x_{2}\left(k+1\right)=\sin\left(\dfrac{4}{9}\pi\cdot x_{2}\left(k\right)\right)-\dfrac{1}{8}x_{3}\left(k\right)\\
x_{3}\left(k+1\right)=\alpha x_{3}\left(k\right)+u\left(k\right)
\end{array}
\]
con $\alpha\in\mathbb{R}$; $\checkmark$calcolare l'ingresso di equilibrio
e la terza variabile di stato, in funzione del parametro reale ($\overline{u}\left(\alpha\right)$
e $\overline{x}_{3}\left(\alpha\right)$), tali che $\overline{x}=\begin{bmatrix}1/2\\
3/8\\
\overline{x}_{3}
\end{bmatrix}$ sia uno stato di equilibrio.}

Facendo un passo indietro, classifichiamo il sistema: esso è un sistema
a tempo discreto, non lineare, del 3° ordine, ha un ingresso, stazionario
(non abbiamo informazioni sull'uscita nell'ambito dell'esercizio).

Per ottenere le condizioni che determinano l'equilibrio, poniamo ciascuna
equazione di stato pari allo stato corrispondente, sfruttando la (\ref{eq:Condizioni-equilibrio-tempo-discreto}):
\[
\begin{cases}
\dfrac{1}{2}=\left(\dfrac{1}{2}\right)^{3}+\dfrac{1}{8}\cdot\overline{x}_{3} & \mathrm{\left(I\right)}\\
\dfrac{1}{8}=\sin\left(\dfrac{4}{9}\pi\cdot\dfrac{3}{8}\right)-\dfrac{1}{8}\cdot\overline{x}_{3} & \left(\mathrm{II}\right)\\
\overline{x}_{3}=\alpha\overline{x}_{3}+\overline{u}\left(\alpha\right) & \left(\mathrm{III}\right)
\end{cases}\rightarrow\,\begin{cases}
\overline{x}_{3}=1 & \mathrm{\left(I\right)}\\
\dfrac{1}{2}=\dfrac{1}{2} & \mathrm{\left(II\right)}\\
1-\alpha=\overline{u}\left(\alpha\right) & \mathrm{\left(III\right)}
\end{cases}
\]
dove abbiamo ricavato dalla $\mathrm{\left(I\right)}$ il valore numerico
di $\overline{x}_{3}$, che abbiamo poi usato nella $\mathrm{\left(II\right)}$
e nella $\mathrm{\left(III\right)}$; il fatto che dalla $\mathrm{\left(II\right)}$
si ricavi una identità ci conferma che stiamo usando una condizione
di equilibrio dello stato ammissibile; dalla $\mathrm{\left(III\right)}$
si ricava infine il valore dell'uscita di equilibrio.

\emph{$\checkmark$Studiare ora le proprietà di stabilità dell'equilibrio
al variare del parametro $\alpha\in\mathbb{R}$.}

Per approcciare il problema, linearizziamo la matrice di stato intorno
all'equilibrio appena ottenuto, e studiamo il modulo degli autovalori
corrispondenti:
\[
A_{{\scriptscriptstyle \text{L}}}=\begin{bmatrix}3\overline{x}_{1}^{2} & \overline{x}_{3} & \overline{x}_{2}\\
0 & \nicefrac{4}{9}\pi\cos\left(\nicefrac{4}{9}\pi\overline{x}_{2}\right) & -\nicefrac{1}{8}\\
0 & 0 & \alpha
\end{bmatrix}=\begin{bmatrix}\nicefrac{3}{4} & 1 & \nicefrac{3}{8}\\
0 & \nicefrac{2\sqrt{3}}{9} & -\nicefrac{1}{8}\\
0 & 0 & \alpha
\end{bmatrix}
\]
La matrice di stato linearizzata è costituita dalle derivate parziali:
l'indice di riga rappresenta le funzioni di stato non lineari, l'indice
di colonna lo stato rispetto al quale si deriva parzialmente; tutte
le derivate parziali sono valutate in $\overline{x},\,\overline{u}$.

La matrice trovata è diagonale, dunque i suoi autovalori sono i termini
sulla diagonale principale; scrivendo in modo numerico abbiamo $z_{1}=0.75,\,z_{2}\simeq1.2,\,z_{3}=\alpha$:
dato che $\left|z_{2}\right|>1$, l'equilibrio è instabile (vedi \tabref{Classificazione-movimenti-discreti})
comunque scelto $\alpha$.\demo
\end{example}

\chapter{Funzione di trasferimento}

\section{Definizione}

Richiamiamo la scrittura matriciale di un sistema LTI a tempo continuo
(\ref{eq:Forma-standard-matrice-LTI}); possiamo allora cercare la
trasformata di Laplace (\ref{eq:Trasformata-Laplace}) per ciascuna
equazione del sistema:
\[
\begin{array}{l}
\mathscr{L}\left[\dot{x}\left(t\right)\right]=sX\left(s\right)-x\left(0\right)=A\cdot X\left(s\right)+B\cdot U\left(s\right)\\
\mathscr{L}\left[y\left(t\right)\right]=C\cdot X\left(s\right)+D\cdot U\left(s\right)
\end{array}
\]
Dalla trasformata dell'equazione di stato possiamo ricavare il valore
di $X\left(s\right)$ invertendo nel modo seguente:
\[
\left(sI-A\right)\cdot X\left(s\right)-\left(sI-A\right)\cdot x\left(0\right)=B\cdot U\left(s\right)
\]
\[
X\left(s\right)=\left(sI-A\right)^{-1}x\left(0\right)+\left(sI-A\right)^{-1}B\cdot U\left(s\right)
\]
Considerando il termine $\left(sI-A\right)^{-1}$ associato a $e^{At}$,
osserviamo un'analogia coi movimenti dello stato, descritti da (\ref{eq:Formula-di-Lagrange}):
si tratta della stessa equazione, vista nel dominio di Laplace; sostituendo
nella trasformata dell'equazione di uscita l'espressione ottenuta
per $X\left(s\right)$, otteniamo:
\[
Y\left(s\right)=\left[C\cdot\left(sI-A\right)^{-1}\cdot B+D\right]U\left(s\right)+C\left(sI-A\right)^{-1}x\left(0\right)
\]
dove il coefficiente di $U\left(s\right)$ è la trasformata del movimento
forzato, mentre il coefficiente di $x\left(0\right)$ è la trasformata
del movimento libero dell'uscita; in particolare chiamiamo funzione
di trasferimento, e la indichiamo con $G\left(s\right)$, il prodotto
di convoluzione\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Funzione di trasferimento}{\footnotesize{}\index{Trasferimento nel tempo continuo, funzione@{\footnotesize{}Trasferimento nel tempo continuo, funzione}}}}[0.5cm]
\begin{equation}
G\left(s\right)=C\cdot\left(sI-A\right)^{-1}\cdot B+D\label{eq:Funzione-trasferimento}
\end{equation}
Essa fornisce informazioni sulla dipendenza dell'uscita forzata dall'ingresso.

Dato che la funzione di trasferimento è la componente forzata dell'uscita
nel dominio di Laplace, possiamo scrivere l'uscita in funzione di
essa:
\begin{equation}
Y\left(s\right)=G\left(s\right)\cdot U\left(s\right)\label{eq:Uscita-trasferimento-Laplace}
\end{equation}
Notiamo che, avendo $Y\left(s\right)$ grado $p$ e $U\left(s\right)$
grado $m$, allora $G\left(s\right)$ avrà dimensioni $p\times m$;
inoltre, se abbiamo un sistema SISO, la funzione di trasferimento
è scalare (a 1 dimensione, essendo $p=m=1$) e vale la scrittura $G\left(s\right)=Y\left(s\right)/U\left(s\right)$.

Per osservare che il significato della (\ref{eq:Funzione-trasferimento})
è quello di trasformata della risposta dell'uscita a un impulso (a
partire da condizioni iniziali nulle), prendiamo il caso SISO con
$u\left(t\right)=\text{imp}\left(t\right)$: la sua trasformata vale
$U\left(s\right)=1$. Allora l'equazione di uscita assumerà la forma
$Y\left(s\right)=G\left(s\right)$, che eguaglia la funzione di trasferimento
con la trasformata dell'uscita.

\section{Proprietà}

\subsection{Struttura della funzione e cancellazioni}

Consideriamo di nuovo per semplicità un sistema LTI SISO; scriveremo
la sua funzione di trasferimento (con le rispettive dimensioni per
ciascuna matrice) come:
\[
G\left(s\right)=\overset{{\scriptscriptstyle 1\times n}}{C}\cdot\underset{{\scriptscriptstyle n\times n}}{\left(sI-A\right)^{-1}}\cdot\overset{{\scriptscriptstyle n\times1}}{B}+\underset{{\scriptscriptstyle 1\times1}}{D}
\]
Da questa scrittura possiamo ricavare la matrice inversa $\left(sI-A\right)^{-1}$
dalla Definizione \ref{def:Matrice-inversa} come matrice dei complementi
algebrici diviso il determinante; quest'ultimo è un polinomio in $s$
di grado al più $n$ che chiamiamo $D\left(s\right)$, mentre i complementi
algebrici sono determinanti delle sotto-matrici dell'inversa, quindi
avranno al più grado $n-1$. Con queste considerazioni la funzione
di trasferimento può essere riscritta come:
\[
G\left(s\right)=C\cdot\dfrac{\left[\Delta_{s_{i}}\right]}{\det\left(sI-A\right)}\cdot B+D=\dfrac{1}{D\left(s\right)}\left(C\cdot\left[\Delta_{s_{i}}\right]\cdot B\right)+D=\dfrac{N^{\prime}\left(s\right)}{D\left(s\right)}+D
\]
dove $N^{\prime}\left(s\right)$ è la combinazione lineare derivata
dal prodotto della matrice dei coefficienti algebrici con $C$ e $B$,
e $D$ è non nulla.

\marginpar{Avevamo osservato ne \subsecref{Processi-a-tempo-continuo} che un
sistema si dice strettamente proprio quando l'ingresso non compare
nell'equazione di uscita; in un sistema LTI vale $D=0$ e anche la
funzione di trasferimento è strettamente propria}Se vale $D=0$ la funzione di trasferimento risulta razionale e \emph{strettamente
propria}, dalla precedente osservazione per cui $n\left(N^{\prime}\left(s\right)\right)<n\left(D\left(s\right)\right)$;
se $D$ è non nulla si ottiene al più una funzione \emph{bi-propria}
(numeratore e denominatore hanno stesso grado).

Nel prodotto $C\cdot\left[\Delta_{s_{i}}\right]\cdot B$ si possono
verificare delle cancellazioni tra zeri e poli; formalizziamo questa
eventualità scrivendo (a meno di un guadagno $\rho$):
\[
G\left(s\right)=\rho\cdot\dfrac{\prod_{i=1}^{n-1}\left(s+z_{i}\right)}{\prod_{i=1}^{n}\left(s+p_{i}\right)}
\]
Se vi fossero cancellazioni tra termini di $N\left(s\right)$ e $D\left(s\right)$,
posto $\nu$ il grado del denominatore, varrebbe $\nu<n$; in generale
possiamo scrivere la funzione di trasferimento come:
\[
G\left(s\right)=\dfrac{N\left(s\right)}{D\left(s\right)}=\dfrac{\beta_{\nu}s^{\nu}+\beta_{\nu-1}s^{\nu-1}+\ldots+\beta_{0}}{\alpha_{\nu}s^{\nu}+\alpha_{\nu-1}s^{\nu-1}+\ldots+\alpha_{0}}
\]

dove abbiamo $\beta_{\nu}\neq0\iff D\neq0$, ovvero il grado di numeratore
e denominatore è uguale solo se la matrice $D$ è non nulla. Ricaviamo
da questa scrittura gli zeri come le radici che verificano $N\left(s\right)=0$
e i poli come le radici che verificano $D\left(s\right)=0$.
\begin{rem}
\label{oss:Stabilit=0000E0-segno-poli}Il polinomio al denominatore
della funzione di trasferimento vale $D\left(s\right)=\det\left(sI-A\right)$,
che è proprio il polinomio caratteristico (\ref{eq:Polinomio-caratteristico})
della matrice di stato $A$, se eguagliato a zero per trovarne le
radici: allora i poli (le radici del denominatore di $G\left(s\right)$)
coincidono con alcuni autovalori di $A$.

Questo è un utile strumento per misurare la stabilità di un sistema,
a partire dalla sua funzione di trasferimento: la stabilità asintotica
di un sistema infatti dipende dalla parte reale degli autovalori della
sua matrice di stato (Definizione \ref{def:Stabilit=0000E0-asintotica});
in un sistema di ordine $n$, la cui funzione di trasferimento ha
un denominatore di ordine $n$, si ha la certezza che tutti i poli
siano tutti gli autovalori della matrice $A$: se essi hanno parte
reale negativa, il sistema risulta asintoticamente stabile.
\end{rem}
\emph{}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{example}
\emph{Sia dato un circuito idraulico consistente in una pompa di portata
$u\left(t\right)$ che, prelevando liquido da un serbatoio a capacità
infinita, viene smistato in due serbatoi cilindrici, con due tubi
di portata $u\left(t\right)/2$. Il livello del liquido nei due serbatoi
è indicato con $h_{1,2}\left(t\right)$ e la sezione di ciascun serbatoio
è indicata con $s_{1,2}$. Si voglia misurare il volume complessivo
nei due serbatoi ($y\left(t\right)=s_{1}h_{1}\left(t\right)+s_{2}h_{2}\left(t\right)$).
$\checkmark$Scrivere una funzione di trasferimento per questo sistema.}
\end{example}
%
\end{minipage}\emph{}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.7]{\string"Illustrazioni/3_2-3 Circuito idraulico serbatoi\string".pdf}
\par\end{center}
\captionof{figure}{Circuito idraulico con serbatoi}%
\end{minipage}

Innanzitutto scriviamo la variazione del livello di liquido nel tempo
(rispetto all'$i$-esimo serbatoio) come:
\[
\dot{h}_{i}\left(t\right)=\dfrac{u\left(t\right)}{2}\cdot\dfrac{1}{s_{i}}
\]
e scegliamo come stato del sistema il livello istantaneo del liquido
nei due serbatoi:
\[
x\left(t\right)=\begin{bmatrix}x_{1}\left(t\right)\\
x_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}h_{1}\left(t\right)\\
h_{2}\left(t\right)
\end{bmatrix}
\]
Per calcolare la funzione di trasferimento, da qui sono possibili
due strade:

\noun{Formula della funzione di trasferimento}\\
Scriviamo il sistema nella forma (\ref{eq:Forma-standard-matrice-LTI}):\marginpar{Si osserva una cancellazione nella funzione di trasferimento (il grado
del denominatore non è 2); il sistema in tal caso si dice \emph{non
controllabile}: infatti è impossibile controllare in modo differente
i volumi dei due serbatoi}
\[
\dot{x}\left(t\right)=\overset{{\scriptstyle A}}{\overbrace{\begin{bmatrix}0 & 0\\
0 & 0
\end{bmatrix}}}\cdot x\left(t\right)+\overset{{\scriptstyle B}}{\overbrace{\begin{bmatrix}\nicefrac{1}{2s_{1}}\\
\nicefrac{1}{2s_{2}}
\end{bmatrix}}}\cdot u\left(t\right)
\]
\[
y\left(t\right)=\overset{{\scriptstyle C}}{\overbrace{\begin{bmatrix}s_{1} & s_{2}\end{bmatrix}}}\cdot x\left(t\right)+\overset{{\scriptstyle D}}{\overbrace{0}}
\]
Sostituiamo i coefficienti nella (\ref{eq:Funzione-trasferimento}):
\[
G\left(s\right)=\begin{bmatrix}s_{1} & s_{2}\end{bmatrix}\cdot\begin{bmatrix}s & 0\\
0 & s
\end{bmatrix}^{-1}\cdot\begin{bmatrix}\nicefrac{1}{2s_{1}}\\
\nicefrac{1}{2s_{2}}
\end{bmatrix}+0=\begin{bmatrix}s_{1} & s_{2}\end{bmatrix}\cdot\dfrac{1}{s^{2}}\cdot\begin{bmatrix}s & 0\\
0 & s
\end{bmatrix}\cdot\begin{bmatrix}\nicefrac{1}{2s_{1}}\\
\nicefrac{1}{2s_{2}}
\end{bmatrix}
\]
\[
=\begin{bmatrix}s_{1} & s_{2}\end{bmatrix}\cdot\begin{bmatrix}\nicefrac{1}{s} & 0\\
0 & \nicefrac{1}{s}
\end{bmatrix}\cdot\begin{bmatrix}\nicefrac{1}{2s_{1}}\\
\nicefrac{1}{2s_{2}}
\end{bmatrix}=\begin{bmatrix}\nicefrac{s_{1}}{s} & \nicefrac{s_{2}}{s}\end{bmatrix}\cdot\begin{bmatrix}\nicefrac{1}{2s_{1}}\\
\nicefrac{1}{2s_{2}}
\end{bmatrix}=\dfrac{1}{2s}+\dfrac{1}{2s}=\boxed{\dfrac{1}{s}}
\]
\bigskip{}

\noun{Trasformata di Laplace delle derivate}\\
Scriviamo la trasformata di ciascuna equazione del sistema e sostituiamo
nella trasformata dell'equazione di uscita le trasformate delle equazioni
di stato:
\[
\mathscr{L}\left[\dot{x}_{1}\left(t\right)=\dfrac{1}{2}\cdot\dfrac{u\left(t\right)}{s_{1}}\right]\rightarrow sX_{1}\left(s\right)=\dfrac{U\left(s\right)}{2s_{1}}\rightarrow X_{1}\left(s\right)=\dfrac{U\left(s\right)}{2s\cdot s_{1}}
\]
\[
\mathscr{L}\left[\dot{x}_{2}\left(t\right)=\dfrac{1}{2}\cdot\dfrac{u\left(t\right)}{s_{2}}\right]\rightarrow sX_{2}\left(s\right)=\dfrac{U\left(s\right)}{2s_{2}}\rightarrow X_{2}\left(s\right)=\dfrac{U\left(s\right)}{2s\cdot s_{2}}
\]
\[
\mathscr{L}\left[y\left(t\right)=s_{1}x_{1}\left(t\right)+s_{2}x_{2}\left(t\right)\right]=s_{1}X_{1}\left(s\right)+s_{2}X_{2}\left(s\right)
\]
Consideriamo nulle le condizioni iniziali degli stati, per poter ignorare
il termine che comparirebbe nella trasformata della derivata (tale
termine non influenza la funzione di trasferimento, dato che essa
riguarda ingresso e uscita). Sostituendo nella trasformata dell'uscita
otteniamo:
\[
Y\left(s\right)=\cancel{s_{1}}\dfrac{U\left(s\right)}{2s\cdot\cancel{s_{1}}}+\cancel{s_{2}}\dfrac{U\left(s\right)}{2s\cdot\cancel{s_{2}}}=\dfrac{1}{s}U\left(s\right)
\]
Dal momento che il sistema è strettamente proprio e SISO possiamo
ottenere usando (\ref{eq:Uscita-trasferimento-Laplace}):
\[
G\left(s\right)=\dfrac{Y\left(s\right)}{U\left(s\right)}=\boxed{\dfrac{1}{s}}
\]

\demo\smallskip{}

\begin{minipage}[c]{0.65\textwidth}%
\begin{example}
\emph{\label{exa:Sistema-2ord-cancellazione-polo}Sia dato un sistema
costituito da un carrello di massa $m$, in movimento su un piano
indefinito con coefficiente di attrito dinamico $\beta$, situato
in posizione $p\left(t\right)$ e sospinto da una forza esterna $F\left(t\right)$;
si voglia misurare la velocità del carrello ($\dot{p}\left(t\right)$).
$\checkmark$Scrivere una funzione di trasferimento per il sistema.}
\end{example}
%
\end{minipage}%
\begin{minipage}[c]{0.4\textwidth}%
\begin{center}
\includegraphics[scale=1.5]{\string"Illustrazioni/3_2-2 Carrello su piano attrito\string".pdf}
\par\end{center}
\captionof{figure}{Carrello su piano con attrito}%
\end{minipage}

L'equazione della dinamica del sistema si ottiene come:
\[
m\ddot{p}\left(t\right)+\beta\dot{p}\left(t\right)=F\left(t\right)
\]
Nel contesto dell'esercizio vale $u\left(t\right)=F\left(t\right)$,
$y\left(t\right)=\dot{p}\left(t\right)$; scegliamo inoltre gli stati
del sistema come $x\left(t\right)=\begin{bmatrix}x_{1}\left(t\right)\\
x_{2}\left(t\right)
\end{bmatrix}=\begin{bmatrix}p\left(t\right)\\
\dot{p}\left(t\right)
\end{bmatrix}$.

Procediamo trasformando le equazioni di stato (sempre a meno delle
condizioni iniziali):
\[
\mathscr{L}\left[\dot{p}\left(t\right)\right]=sP\left(s\right)
\]
\[
\mathscr{L}\left[\ddot{p}\left(t\right)\right]=s^{2}P\left(s\right)
\]
L'equazione della dinamica del sistema diventa $ms^{2}P\left(s\right)+\beta sP\left(s\right)=U\left(s\right)$,
dove possiamo sostituire $Y\left(s\right)=sP\left(s\right)$ (ottenuta
da $\mathscr{L}\left[y\left(t\right)\right]=\mathscr{L}\left[\dot{p}\left(t\right)\right]$);
avremo la seguente relazione tra $U\left(s\right)$ e $Y\left(s\right)$,
dalla quale si ottiene l'espressione per la trasformata dell'uscita:
\[
msY\left(s\right)+\beta Y\left(s\right)=U\left(s\right)\rightarrow Y\left(s\right)=\dfrac{U\left(s\right)}{ms+\beta}
\]
Ricaviamo infine la funzione di trasferimento da (\ref{eq:Uscita-trasferimento-Laplace}),
osservando che il sistema è SISO:
\[
G\left(s\right)=\dfrac{Y\left(s\right)}{U\left(s\right)}=\dfrac{1}{ms+\beta}
\]
\demo\bigskip{}

\begin{rem}
Nell'Esempio \ref{exa:Sistema-2ord-cancellazione-polo} viene dato
un sistema del secondo ordine, che possiede infatti due stati, tuttavia
la funzione di trasferimento è razionale e propria con denominatore
di grado 1: questo è dovuto a una cancellazione provocata dall'uscita,
definita come derivata di uno stato. Questo caso ricade sotto il nome
di \emph{non osservabilità} e indica l'impossibilità di ricostruire
l'andamento di tutti gli stati a partire dall'uscita.

Dal risultato dell'Esempio \ref{exa:Sistema-2ord-cancellazione-polo}
possiamo dedurre che la funzione di trasferimento di un sistema completamente
osservabile avrà denominatore di grado massimo (pari al numero di
poli); sfruttando questa osservazione, deduciamo che in un sistema
completamente osservabile tutti i poli sono anche gli autovalori della
matrice di stato: basta osservare la loro parte reale per studiare
l'asintotica stabilità.
\end{rem}

\subsection{Trasferimento nei sistemi con ritardo}

Consideriamo un sistema dinamico con ritardo in ingresso $\tau_{u}>0$,
tale che l'ingresso traslato nel tempo valga $u\left(t\right)=u^{\prime}\left(t-\tau_{u}\right)$;
la sua trasformata sarà del tipo esponenziale (a causa della traslazione):
\[
\mathscr{L}\left[u\left(t\right)\right]=U\left(s\right)=\mathscr{L}\left[u^{\prime}\left(t-\tau_{u}\right)\right]=e^{-\tau_{u}s}U^{\prime}\left(s\right)
\]
A questo punto ricaviamo anche la trasformata dell'uscita usando (\ref{eq:Uscita-trasferimento-Laplace}):
\[
Y\left(s\right)=G\left(s\right)U\left(s\right)=G\left(s\right)\cdot e^{-\tau_{u}s}U^{\prime}\left(s\right)
\]
Notiamo che un ritardo comporta la presenza di un coefficiente esponenziale,
legato alla traslazione, nella funzione di trasferimento.

Lo stesso ragionamento vale per un ritardo $\tau_{y}>0$ in uscita,
dove possiamo sostituire l'uscita $Y\left(s\right)$ con quella appena
ottenuta:
\[
Y^{\prime}\left(s\right)=e^{-\tau_{y}s}Y\left(s\right)=e^{-\tau_{y}s}e^{-\tau_{u}s}G\left(s\right)U^{\prime}\left(s\right)=e^{-\left(\tau_{u+\tau_{y}}\right)s}G\left(s\right)U^{\prime}\left(s\right)
\]
Il termine esponenziale dipende nuovamente dai ritardi, tuttavia la
funzione di trasferimento non è più razionale a coefficienti reali
(l'esponenziale ha comunque la variabile $s$ all'esponente).
\begin{rem}
\marginpar{Questo non vale per i sistemi retro-azionati (saranno discussi successivamente)}Dato
un sistema LTI con ritardo, supponendo di non avere cancellazioni
nella funzione di trasferimento e tutti i poli abbiano parte reale
negativa, ovvero il sistema sarà asintoticamente stabile (dall'Osservazione
\ref{oss:Stabilit=0000E0-segno-poli}); si dimostra che, se il sistema
interno è asintoticamente stabile, eventuali ritardi su ingressi e
uscite non influenzano questa sua proprietà.
\end{rem}

\section{Forme fattorizzate}

Per comodità si usa rappresentare le funzioni di trasferimento, in
un sistema SISO, secondo delle scritture standard fattorizzate:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Forma di Bode}{\footnotesize{}\index{Bode, forma di@{\footnotesize{}Bode, forma di}}}}[2.8cm]
\begin{equation}
G\left(s\right)=\dfrac{\rho\cdot\prod_{i}\left(s+z_{i}\right)\prod_{i}\left(s^{2}+2\zeta_{i}\alpha_{n_{i}}s+\alpha_{n_{i}}^{2}\right)}{s^{g}\cdot\prod_{i}\left(s+p_{i}\right)\prod_{i}\left(s^{2}+2\xi_{i}\omega_{n_{i}}s+\omega_{n_{i}}^{2}\right)}\label{eq:Forma-fattorizzata-standard}
\end{equation}
\begin{equation}
G\left(s\right)=\dfrac{\mu\cdot\prod_{i}\left(1+\tau_{i}s\right)\prod_{i}\left(1+\dfrac{2\zeta_{i}s}{\alpha_{n_{i}}}+\dfrac{s^{2}}{\alpha_{n_{i}}^{2}}\right)}{s^{g}\cdot\prod_{i}\left(1+T_{i}s\right)\prod_{i}\left(1+\dfrac{2\xi_{i}s}{\omega_{n_{i}}}+\dfrac{s^{2}}{\omega_{n_{i}}^{2}}\right)}\label{eq:Forma-di-Bode}
\end{equation}
I termini delle forme fattorizzate hanno il seguente significato:
\begin{itemize}
\item la \emph{costante di trasferimento} $\rho$ è uno scalare, esso è
il valore iniziale del trasferimento; si ottiene applicando (\ref{eq:Teorema-valore-iniziale})
con ingresso un impulso. Risulta che
\[
\lm s{+\infty}{sG\left(s\right)}=s\rho\cdot s^{\left(n_{{\scriptscriptstyle \text{N}}}-n_{{\scriptscriptstyle \text{D}}}\right)}
\]
e si osserva che per una funzione di trasferimento in forma standard
vale $n_{{\scriptscriptstyle \text{N}}}-n_{{\scriptscriptstyle \text{D}}}=-1$,
in tal caso il limite appena calcolato tende a $\rho$;
\item il \emph{tipo} del sistema $g$ è un intero che indica il numero di
poli ($g>0$) o zeri ($g<0$) nell'origine; se $g$ è positivo si
dice che il sistema presenta degli integratori ideali, poiché l'uscita
sarà la trasformata dell'integrale dell'ingresso; se $g$ è negativo
si dice che il sistema presenta dei derivatori ideali, poiché l'uscita
sarà la trasformata della derivata dell'ingresso;
\item i poli $p_{i}$ e gli zeri $z_{i}$ cambiati di segno sono scalari
non nulli;
\item le \emph{pulsazioni naturali} $\omega_{i}$ e $\alpha_{i}$ delle
coppie di poli e zeri complessi coniugati sono scalari strettamente
maggiori di 0;
\item gli \emph{smorzamenti} $\xi_{i}$ e $\zeta_{i}$ delle coppie di poli
e zeri complessi coniugati sono scalari con modulo strettamente minore
di 1 (se in modulo fossero maggiori di 1 non si otterrebbero radici
complesse coniugate dalla seconda produttoria);
\item il \emph{guadagno statico} $\mu$ è uno scalare, esso è il valore
finale del trasferimento; si ottiene applicando (\ref{eq:Teorema-valore-finale})
con uno segnale costante in ingresso, ad esempio lo scalino $\overline{u}\cdot\text{sca}\left(t\right)$
di ampiezza $\overline{u}$, la cui trasformata è $\overline{u}/s$.
In assenza di poli o zeri nell'origine ($g=0$) risulta che
\[
\lm s0{\,s\cdot G\left(s\right)\cdot\dfrac{\overline{u}}{s}}=\overline{u}\cdot\mu
\]
dove $\overline{u}$ è l'ampiezza dello scalino in ingresso. Otteniamo
in effetti il rapporto tra l'ampiezza dello scalino in ingresso (ingresso
di equilibrio) e l'ampiezza dell'uscita (di equilibrio);
\item le \emph{costanti di tempo} $T_{i}=1/p_{i}$ dei poli e $\tau_{i}=1/z_{i}$
degli zeri sono scalari.
\end{itemize}

\subsection*{Poli complessi coniugati}

Se rappresentiamo i poli complessi coniugati sul piano di Gauss, appaiono
evidenti alcune proprietà riguardo pulsazioni naturali e smorzamenti:
preso un polo stabile, esso avrà (risolvendo le radici) $\Re\left(p\right)=-\xi\omega_{n}$,
$\Im\left(p\right)=\pm\omega_{n}\sqrt{1-\xi^{2}}$; in particolare
$\omega_{n}$ è la distanza dall'origine di ciascun polo della coppia
coniugata, mentre il coseno dell'angolo $\theta$ che questa distanza
forma con l'asse reale è pari a $\xi$, dunque vale $\theta=\arccos\left(\xi\right)$.

Da queste osservazioni segue che, a parità di pulsazione $\omega_{n}$
lo smorzamento $\xi$ è inversamente proporzionale all'angolo $\theta$
tra le distanze dei due complessi coniugati.

\subsection*{Guadagno generalizzato}

Per sistemi che hanno tipo $g>0$, la grandezza $\mu$ non è ben definita
(il limite per ottenerla vale $\infty$); si definisce allora il guadagno
statico generalizzato come:
\[
\lm s{+\infty}{s^{g}G\left(s\right)}\qquad\text{per}\,g>0
\]
In questo modo si eliminano i poli nell'origine.

\section{Risposta forzata allo scalino}

\begin{minipage}[c]{0.65\textwidth}%
Consideriamo un sistema dinamico nel dominio del tempo, espresso in
forma (\ref{eq:Forma-standard-matrice-LTI}); se abbiamo un ingresso
generico $u\left(t\right)$ è necessario risolvere un'equazione differenziale
ordinaria per ottenere l'uscita $y\left(t\right)$. Questi risultati
sono riassunti in (\ref{eq:Formula-di-Lagrange}), che tuttavia non
risulta comodo da calcolare; si adotta la seguente strategia:%
\end{minipage}%
\begin{minipage}[c]{0.45\textwidth}%
\begin{center}
\includegraphics[scale=0.6]{\string"Illustrazioni/3_4-1 Equivalenza risposta dominio tempo con Laplace\string".pdf}
\par\end{center}
\captionof{figure}{Equivalenza risposta nel dominio del tempo con dominio di Laplace}%
\end{minipage}
\begin{enumerate}
\item Trasformiamo il segale di ingresso nel dominio di Laplace;
\item Calcoliamo la funzione di trasferimento;
\item Otteniamo l'uscita nel dominio di Laplace;
\item Antitrasformiamo l'uscita per ottenerla nel dominio del tempo.
\end{enumerate}
Useremo l'ingresso canonico a scalino $u\left(t\right)=\overline{u}\cdot\text{sca}\left(t\right)$
poiché si tratta di un segnale facilmente realizzabile nella pratica
in un sistema dinamico; in particolare ci poniamo nelle condizioni
di uno scalino unitario in sistemi asintoticamente stabili del I e
del II ordine, quindi sistemi con al più due poli (con parte reale
negativa) e al più uno zero, e nessun polo è nell'origine.

\subsection{Valori iniziale e finale della risposta\label{subsec:Valori-della-risposta}}

Calcoliamo il valore finale della risposta allo scalino a partire
dalla trasformata di Laplace dell'uscita, usando la funzione di trasferimento:
\[
Y\left(s\right)=G\left(s\right)\cdot\dfrac{1}{s}
\]
Applicando (\ref{eq:Teorema-valore-finale}) otteniamo (scrivendo
nella (\ref{eq:Forma-di-Bode}) la funzione di trasferimento):
\[
\lm s0{\,s\cdot Y\left(s\right)}=\lm s0{\,s\cdot G\left(s\right)\cdot\dfrac{1}{s}}=\mu
\]
Questo vale in assenza di zeri nell'origine, altrimenti si avrebbe
un $s^{g+1}$ al numeratore che annulla l'uscita (con uno zero nell'origine
$g=-1$).

Calcoliamo il valore iniziale come l'uscita al tempo $t=0$, usando
(\ref{eq:Teorema-valore-iniziale}):
\[
y\left(t\rightarrow0\right)=\lm s{+\infty}{s\cdot Y\left(s\right)}=\lm s{+\infty}{G\left(s\right)}
\]
Questo limite vale $\rho$ se numeratore e denominatore sono di pari
grado, altrimenti si annulla.

Possiamo calcolare anche il valore iniziale delle derivate dell'uscita
nello stesso modo: supponendo che la funzione di trasferimento sia
strettamente propria, allora il valore iniziale della derivata prima
vale
\[
\lm s{+\infty}{s\cdot\mathscr{L}\left[\dot{y}\left(t\right)\right]}=\lm s{+\infty}{s\left[s\cdot Y\left(s\right)\right]}=\lm s{+\infty}{s^{\cancel{2}}\cdot G\left(s\right)\cdot\dfrac{1}{\cancel{s}}}
\]

Osserviamo che l'annullamento del limite dipende dal grado relativo
(il numeratore è moltiplicato per $s$): in generale il valore delle
prime $n_{{\scriptscriptstyle \text{D}}}-n_{{\scriptscriptstyle \text{N}}}-1$
derivate è nullo, mentre la successiva vale $\rho$.

Nel caso di sistemi del I e II ordine c'è un transitorio per la risposta
allo scalino, tipicamente una oscillazione convergente; elenchiamo
alcuni termini per la nomenclatura e l'analisi di questa risposta:

\begin{minipage}[c]{0.5\textwidth}%
\begin{itemize}
\item Il valore di stato stazionario $y_{\infty}=\mu\cdot\overline{u}$
è il prodotto del guadagno statico per l'ampiezza dello scalino;
\item Il massimo valore che raggiunge l'uscita nel transitorio è $y_{{\scriptscriptstyle \text{MAX}}}$;
\item La \emph{sovraelongazione} $s_{\%}=\dfrac{y_{{\scriptscriptstyle \text{MAX}}}-y_{\infty}}{y_{\infty}}$
è la distanza del picco dal valore asintotico;
\end{itemize}
%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/3_4-2 Risposta allo scalino ordine elevato\string".pdf}
\par\end{center}
\captionof{figure}{Risposta allo scalino per sistemi con 2 poli complessi}\label{fig:Risposta-sistemi-2-ord-complessi-coniugati}%
\end{minipage}
\begin{itemize}
\item Il \emph{tempo di assestamento} $T_{a,\varepsilon}$ è l'istante dopo
il quale l'uscita è definitivamente compresa in $\left(y_{\infty}+\varepsilon,\,y_{\infty}-\varepsilon\right)$;
\item Il \emph{tempo di salita} $T_{s}=y^{-1}\left(0.9y_{\infty}\right)-y^{-1}\left(0.1y_{\infty}\right)$
è l'intervallo di tempo nel quale l'uscita raggiunge il valore stazionario
$y_{\infty}$ per la prima volta approssimato tra il $10\%$ e il
$90\%$.
\end{itemize}

\subsection{Risposta per sistemi del I ordine}

Consideriamo solo il caso di sistemi strettamente propri (una funzione
di trasferimento bi-propria genera una risposta dell'uscita allo scalino
poco interessante): il numeratore della funzione di trasferimento
di un sistema del genere sarà una costante e il denominatore avrà
un singolo polo; l'uscita si ottiene da (\ref{eq:Uscita-trasferimento-Laplace}):\marginpar{Si tenga a mente che la trasformata dello scalino vale $\mathscr{L}\left[\text{sca}\left(t\right)\right]=1/s$}
\[
G\left(s\right)=\dfrac{\mu}{1+Ts},\qquad Y\left(s\right)=\dfrac{\mu}{s\left(1+Ts\right)}
\]

Per calcolare l'uscita nel dominio del tempo, antitrasformiamo l'espressione
appena ottenuta; per prima cosa usiamo (\ref{eq:Metodo-cancellazione-denominatore})
per scrivere in modo adeguato tale espressione:
\[
Y\left(s\right)=\dfrac{a}{s}+\dfrac{b}{1+Ts}\rightarrow a+aTs+bs=\mu\rightarrow s\left(aT+b\right)+a=\mu
\]
\[
\begin{cases}
a=\mu\\
b=-aT=-\mu T
\end{cases}
\]
Sostituendo nell'espressione dell'uscita possiamo calcolare la sua
antitrasformata:
\[
Y\left(s\right)=\dfrac{\mu}{s}-\dfrac{\mu T}{1+Ts}=\mu\left(\dfrac{1}{s}-\dfrac{1}{s+\nicefrac{1}{T}}\right)
\]
\begin{equation}
\mathscr{L}^{-1}\left[Y\left(s\right)\right]=\mu\left(1-e^{-\nicefrac{t}{T}}\right)\text{sca}\left(t\right)\label{eq:Risposta-scalino-ord-1}
\end{equation}
Le caratteristiche di questa risposta sono le seguenti:
\begin{itemize}
\item Valore iniziale nullo al tempo zero ($y\left(0\right)=0$);
\item Valore iniziale della derivata prima pari a $\lm s{+\infty}{s^{2}\dfrac{\mu}{1+Ts}\cdot\dfrac{1}{s}}=\dfrac{\mu}{T}$
(pendenza nella tangente nell'origine);
\item Tempo di assestamento in $\varepsilon$ pari a $T_{a,\varepsilon}\Rightarrow y\left(T_{a,\varepsilon}\right)=\mu\left(1-\varepsilon\right)=\mu\left(1-e^{-\nicefrac{T_{a}}{T}}\right)\text{sca}\left(t\right)\rightarrow e^{-\nicefrac{T_{a}}{T}}=\varepsilon\rightarrow\boxed{T_{a}=-T\ln\left(\varepsilon\right)}$.
\end{itemize}
\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=1.4]{\string"Illustrazioni/3_4-3 Risposta del I ord scalino\string".pdf}
\par\end{centering}
\caption{Risposta allo scalino in sistemi del I ordine}

\end{figure}


\subsection{Risposta per sistemi del II ordine}

Scriviamo in forma (\ref{eq:Forma-di-Bode}) la funzione di trasferimento,
supponendo che $T_{1}>T_{2}$; la funzione di uscita si ricava moltiplicando
direttamente per la trasformata dell'ingresso ($1/s$):
\[
G\left(s\right)=\dfrac{\mu}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)},\qquad Y\left(s\right)=\dfrac{\mu}{s\left(1+T_{1}s\right)\left(1+T_{2}s\right)}
\]
Utilizziamo il metodo di Heaviside (\ref{eq:Metodo-di-Heaviside})
per ottenere l'antitrasformata dell'uscita:
\[
Y\left(s\right)=\dfrac{a}{s}+\dfrac{b}{1+T_{1}s}+\dfrac{c}{1+T_{2}s}
\]
\[
\begin{array}{l}
a=\left.\dfrac{\mu}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)}\right|_{s=0}=\mu\\
b=\left.\dfrac{\mu}{s\left(1+T_{2}s\right)}\right|_{s=-\nicefrac{1}{T_{1}}}=\dfrac{\mu}{{\scriptstyle -\nicefrac{1}{T_{1}}}\left(1-{\scriptstyle \nicefrac{T_{2}}{T_{1}}}\right)}=\dfrac{-\mu T_{1}^{2}}{T_{1}-T_{2}}\\
b=\left.\dfrac{\mu}{s\left(1+T_{1}s\right)}\right|_{s=-\nicefrac{1}{T_{2}}}=\dfrac{\mu}{{\scriptstyle -\nicefrac{1}{T_{2}}}\left(1-{\scriptstyle \nicefrac{T_{1}}{T_{2}}}\right)}=\dfrac{\mu T_{1}^{2}}{T_{1}-T_{2}}
\end{array}
\]
\[
Y\left(s\right)=\dfrac{\mu}{s}-\dfrac{\mu T_{1}^{2}}{\left(T_{1}-T_{2}\right)\left(1+T_{1}s\right)}+\dfrac{\mu T_{2}^{2}}{\left(T_{1}-T_{2}\right)\left(1+T_{2}s\right)}
\]

Riscriviamo infine l'espressione dell'uscita per favorire l'antitrasformazione,
raccogliendo i termini di secondo grado dei numeratori:
\[
Y\left(s\right)=\mu\left(\dfrac{1}{s}-\dfrac{\mu T_{1}}{\left(T_{1}-T_{2}\right)}\cdot\dfrac{1}{{\scriptstyle \nicefrac{1}{T_{1}}}+s}+\dfrac{\mu T_{2}}{\left(T_{1}-T_{2}\right)}\cdot\dfrac{1}{{\scriptstyle \nicefrac{1}{T_{2}}}+s}\right)
\]
\begin{equation}
y\left(t\right)=\mathscr{L}^{-1}\left[Y\left(s\right)\right]=\mu\left(1-\dfrac{T_{1}}{T_{1}-T_{2}}e^{-\nicefrac{t}{T_{1}}}+\dfrac{T_{2}}{T_{1}-T_{2}}e^{-\nicefrac{t}{T_{2}}}\right)\text{sca}\left(t\right)\label{eq:Risposta-scalino-ord-2}
\end{equation}

\begin{rem}
\label{oss:Velocit=0000E0-della-risposta}Se fosse $T_{1}\gg T_{2}$,
il polo associato a $T_{1}$ si dice dominante e la risposta si avvicina
a quella del primo ordine studiata nella sezione precedente; quando
invece $T_{1}\sim T_{2}$, la risposta complessiva risulterà rallentata
dalla presenza di un secondo polo rispetto al caso del I ordine.
\end{rem}
Calcoliamo ora le derivate nell'origine; se non abbiamo zeri nell'origine,
con due poli si avrà la derivata prima nulla e la derivata seconda
pari al guadagno statico:
\[
\dot{y}\left(0\right)=\lm s{+\infty}{\dfrac{s^{2}\mu}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)s}}=0
\]
\[
\ddot{y}\left(0\right)=\lm s{+\infty}{\dfrac{s^{3}\mu}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)s}}=\dfrac{\mu}{T_{1}T_{2}}
\]
dove abbiamo usato il teorema (\ref{eq:Teorema-valore-iniziale}).

Nel caso dei poli reali coincidenti avremo $T_{1}=T_{2}=T$, ovvero
la risposta del sistema sarà la più lenta possibile per quanto detto
nell'Osservazione \ref{oss:Velocit=0000E0-della-risposta}; scriviamo
funzione di trasferimento e uscita come:
\[
G\left(s\right)=\dfrac{\mu}{\left(1+Ts\right)^{2}},\qquad Y\left(s\right)=\dfrac{\mu}{s\left(1+Ts\right)^{2}}=\dfrac{a}{s}+\dfrac{b}{1+Ts}+\dfrac{c}{\left(1+Ts\right)^{2}}
\]
Scegliamo di usare (\ref{eq:Metodo-di-Heaviside}) per calcolare $a$,
e di ottenere $b$ e $c$ da (\ref{eq:Metodo-cancellazione-denominatore}):
\[
a=\left.\dfrac{\mu}{\left(1+Ts\right)^{2}}\right|_{s=0}=\mu
\]
\[
\mu=aT^{2}s^{2}+2aTs+a+bs\left(1+Ts\right)+cs
\]
\[
=s^{2}\left(sT^{2}+bT\right)+s\left(2aT+b+c\right)+a
\]
\[
\begin{cases}
aT^{2}+bT=0\\
2aT+b+c=0
\end{cases}\Rightarrow\begin{cases}
b=-\mu T\\
c=-\mu T
\end{cases}
\]
Riscriviamo infine l'uscita sostituendo i coefficienti e troviamo
la sua antitrasformata:
\[
Y\left(s\right)=\dfrac{\mu}{s}-\frac{\mu T}{1+Ts}-\frac{\mu T}{\left(1+Ts\right)^{2}}=\mu\left(\dfrac{1}{s}-\dfrac{1}{\left({\scriptstyle \nicefrac{1}{T}}+s\right)}-\dfrac{1}{T\left({\scriptstyle \nicefrac{1}{T}}+s\right)^{2}}\right)
\]
\begin{equation}
y\left(t\right)=\mathscr{L}^{-1}\left[Y\left(s\right)\right]=\mu\left(1-e^{-\nicefrac{t}{T}}-\dfrac{1}{T}e^{-\nicefrac{t}{T}}\right)\text{sca}\left(t\right)\label{eq:Risposta-scalino-ord-2-poli-reali-coincidenti}
\end{equation}

\begin{rem}
La velocità di risposta, calcolata in maniera analitica tramite le
derivate dell'uscita, si ottiene come prima e vale che il tempo di
assestamento all'$1\%$ è circa $7T$, mentre per il sistema a singolo
polo questo valore è circa $5T$.
\end{rem}

\subsection{Sistemi del II ordine con uno zero}

Rimanendo all'interno delle nostre ipotesi, abbiamo due poli reali
negativi (sistema asintoticamente stabile) e uno zero (il numeratore
avrà grado 1); la forma generale della funzione di trasferimento sarà
la seguente:
\[
G\left(s\right)=\dfrac{\mu\left(1+\tau s\right)}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)}
\]
L'uscita sarà pari alla trasformata dell'ingresso (scalino) per la
funzione di trasferimento:
\[
Y\left(s\right)=\dfrac{\mu\left(1+\tau s\right)}{s\left(1+T_{1}s\right)\left(1+T_{2}s\right)}=\dfrac{a}{s}+\dfrac{b}{1+T_{1}s}+\dfrac{c}{1+T_{2}s}
\]
Per calcolare i coefficienti nella riscrittura dell'uscita usiamo
il metodo (\ref{eq:Metodo-di-Heaviside}):
\[
\begin{array}{l}
a=\left.\dfrac{\mu\left(1+\tau s\right)}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)}\right|_{s=0}=\mu\\
b=\left.\dfrac{\mu\left(1+\tau s\right)}{\left(1+T_{2}s\right)}\right|_{s=-\nicefrac{1}{T_{1}}}=\dfrac{\mu\left(1-\tau/T_{1}\right)}{-1/T_{1}\left(1-T_{2}/T_{1}\right)}=-\dfrac{\mu T_{1}\left(T_{1}-\tau\right)}{T_{1}-T_{2}}\\
c=\left.\dfrac{\mu\left(1+\tau s\right)}{\left(1+T_{1}s\right)}\right|_{s=-\nicefrac{1}{T_{2}}}=\dfrac{\mu\left(1-\tau/T_{2}\right)}{-1/T_{2}\left(1-T_{1}/T_{2}\right)}=\dfrac{\mu T_{2}\left(T_{2}-\tau\right)}{T_{1}-T_{2}}
\end{array}
\]
\[
Y\left(s\right)=\mu\left(\dfrac{1}{s}-\dfrac{\mu\left(T_{1}-\tau\right)}{\left(T_{1}-T_{2}\right)\left(1/T_{1}+s\right)}+\dfrac{\mu\left(T_{2}-\tau\right)}{\left(T_{1}-T_{2}\right)\left(1/T_{2}+s\right)}\right)
\]
L'antitrasformata presenta uno scalino e due esponenziali:
\begin{equation}
y\left(t\right)=\mu\left(1-\dfrac{T_{1}-\tau}{T_{1}-T_{2}}e^{-\nicefrac{t}{T_{1}}}+\dfrac{T_{2}-\tau}{T_{1}-T_{2}}e^{-\nicefrac{t}{T_{2}}}\right)\text{sca}\left(t\right)\label{eq:Risposta-scalino-ord-2-con-zero}
\end{equation}
Ora la funzione di uscita dipende anche dalla costante di tempo dello
zero; assumiamo che $T_{1}>T_{2}$, per avere la quantità al denominatore
sempre positiva, e analizziamo il valore dell'uscita rispetto alla
variazione di $\tau$.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/3_4-4 Risposta del II ord zero positivo\string".pdf}
\par\end{center}
\captionof{figure}{Risposta del 2 ordine con zero reale positivo}\label{fig:Risposta-2-ord-zero-positivo}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/3_4-5 Risposta del II ord zero negativo\string".pdf}
\par\end{center}
\captionof{figure}{Risposta del 2 ordine con zero reale negativo}\label{fig:Risposta-2-ord-zero-negativo}%
\end{minipage}\bigskip{}

\noun{$\qquad$}\textbf{\noun{Zero positivo}}

Prendiamo uno zero con parametro $\tau<0$: la costante di tempo sarà
positiva; nel grafico della risposta compare una \emph{sottoelongazione}
(si veda \figref{Risposta-2-ord-zero-positivo}), tanto più marcata
quanto più il modulo dello zero tende a 0.

Si può considerare uno zero positivo in prossimità dell'origine come
un \emph{derivatore puro}, che dà all'uscita un impulso nella prima
fase del transitorio; si dice anche che questo comportamento è in
\emph{contro-fase}. Lo stesso comportamento si avrebbe per guadagno
negativo.

Possiamo calcolare la pendenza nell'origine della risposta usando
il teorema (\ref{eq:Teorema-valore-iniziale}) sull'uscita:
\[
\dot{y}\left(0\right)=\lm s{+\infty}{s^{2}Y\left(s\right)}=\lm s{+\infty}{s^{2}G\left(s\right)\dfrac{1}{s}}=\lm s{+\infty}{s\dfrac{\mu\left(1+\tau s\right)}{\left(1+T_{1}s\right)\left(1+T_{2}s\right)}}=\dfrac{\mu\tau}{T_{1}T_{2}}
\]
Notiamo che un guadagno elevato o in prossimità dell'origine ($-\nicefrac{1}{\tau}\ll1\implies\left|\tau\right|\gg0$)
la pendenza aumenta.

Bisogna precisare che la vicinanza con l'origine di cui abbiamo parlato
è in realtà da riferirsi alla distanza con i poli negativi, nello
specifico con quelli dominanti (discuteremo successivamente l'andamento
asintotico dei sistemi).\bigskip{}

\noun{$\qquad$}\textbf{\noun{Zero negativo}}

Prendiamo uno zero con $\tau>0$: la costante di tempo sarà negativa;
se essa è maggiore di $-1/T_{1}$, si ha il comportamento simmetrico
rispetto al caso positivo, col presentarsi di una \emph{sovraelongazione}
(si veda \figref{Risposta-2-ord-zero-negativo}) durante il transitorio,
tanto maggiore quanto più lo zero è vicino all'origine (come prima,
se lo zero fosse nell'origine si avrebbe un impulso che precede il
transitorio); Uno zero reale negativo allora velocizza la risposta
del sistema.\bigskip{}

\noun{$\qquad$}\textbf{\noun{Zero nei pressi del polo}}

Se si aumenta in modulo $\tau$ spostando lo zero sempre più a sinistra,
prima o poi esso sarà quasi coincidente col primo polo ($\tau\simeq T_{1}$):
in un primo momento il transitorio procederà senza elongazioni alla
velocità $\mu/T_{2}$ stabilita dal polo rimanente.

A seconda della posizione relativa tra lo zero e il polo dominante,
si ha un \emph{effetto coda} durante il transitorio, ovvero la pendenza
iniziale è determinata dalla costante di tempo più ``veloce'', seguita
da un lungo transitorio determinato dal polo più ``lento''.\bigskip{}

\noun{$\qquad$}\textbf{\noun{Zero cancella un polo}}

Quando vale effettivamente $\tau=T_{1}$, si verifica una cancellazione
zero-polo e la risposta assomiglia a quella di un sistema di ordine
1 senza zeri.

\bigskip{}

\noun{$\qquad$}\textbf{\noun{Zero molto piccolo negativo}}

Quando vale $\left|\tau\right|\gg0$, la costante di tempo diventa
trascurabile e il sistema risponde come se non avesse affatto lo zero.\bigskip{}


\subsection{\label{subsec:Sistemi-ord-2-poli-complessi-coniugati}Sistemi del
II ordine con poli complessi coniugati}

La forma della funzione di trasferimento in questo caso può essere
scritta nella seguente forma:
\[
G\left(s\right)=\frac{\mu\omega_{n}^{2}}{\left(s^{2}+2\xi\omega_{n}s+\omega_{n}^{2}\right)}\qquad\omega_{n}>0,\,\xi\in\left(0,1\right)
\]
In questo modo i poli saranno in
\[
p_{1,2}=\overset{\sigma}{\overbrace{-\xi\omega_{n}}}\pm j\overset{\omega}{\overbrace{\sqrt{1-\xi^{2}}}}
\]
e per i valori scelti di smorzamento e pulsazione abbiamo due poli
complessi coniugati con parte reale negativa. Calcoliamo come al solito
la risposta dell'uscita antitrasformando la sua espressione nel dominio
di Laplace, dopo averla scritta col metodo di Heaviside:
\[
Y\left(s\right)=\frac{\mu\omega_{n}^{2}}{s\left(s-\sigma-j\omega\right)\left(s-\sigma+j\omega\right)}
\]
\[
a=\left.\dfrac{\mu\omega_{n}^{2}}{\left(s-\sigma-j\omega\right)\left(s-\sigma+j\omega\right)}\right|_{s=0}=\mu
\]
\[
\begin{array}{l}
b=\left.\dfrac{\mu\omega_{n}^{2}}{\left(s-\sigma+j\omega\right)}\right|_{s=\sigma+j\omega}=\dfrac{\mu\omega_{n}^{2}}{\left(\sigma+j\omega\right)\left(\sigma+j\omega-\sigma+j\omega\right)}=\dfrac{\mu\omega_{n}^{2}}{2}\cdot\dfrac{-\omega^{2}-j\sigma\omega}{\omega^{4}+\omega^{2}\sigma^{2}}\\
=\dfrac{\mu\omega_{n}^{2}}{\underset{{\scriptstyle \omega_{n}^{2}}}{2\underbrace{\left(\omega^{2}+\sigma^{2}\right)}}}\left(-1-j\dfrac{\sigma}{\omega}\right)=\dfrac{\mu}{2\omega}\left(-\omega-j\sigma\right)
\end{array}
\]
Scriviamo il coefficiente $b$ in forma esponenziale, sostituendo
$\omega$ e $\sigma$ con le variabili originali:
\[
b=\dfrac{\mu}{s\sqrt{1-\xi^{2}}}e^{j\arg\left(-\omega-j\sigma\right)}
\]
Questo numero si trova nel secondo quadrante sul piano complesso,
e il suo argomento vale:
\[
\arg\left(-\omega-j\sigma\right)=\arctan\left(\dfrac{\xi\cancel{\omega_{n}}}{\cancel{\omega_{n}}\sqrt{1-\xi^{2}}}\right)+\dfrac{\pi}{2}\implies b=\dfrac{\mu}{s\sqrt{1-\xi^{2}}}e^{j\left(\arccos\left(\xi\right)+\nicefrac{\pi}{2}\right)}
\]
Il coefficiente $c$ è il complesso coniugato di quello appena trovato:
\[
c=b^{*}=\dfrac{\mu}{s\sqrt{1-\xi^{2}}}e^{-j\left(\arccos\left(\xi\right)+\nicefrac{\pi}{2}\right)}
\]

Sostituendo nell'espressione dell'uscita si ha
\[
Y\left(s\right)=\mu\left[\dfrac{1}{s}+\dfrac{1}{2\sqrt{1-\xi^{2}}}\left(\frac{e^{j\left(\arccos\left(\xi\right)+\nicefrac{\pi}{2}\right)}}{s-\left(\sigma+j\omega\right)}+\frac{e^{-j\left(\arccos\left(\xi\right)+\nicefrac{\pi}{2}\right)}}{s-\left(\sigma-j\omega\right)}\right)\right]
\]
Antitrasformiamo l'uscita usando (\ref{eq:Antitrasformata-Laplace-poli-complessi-coniugati}),
e otteniamo la seguente espressione:
\[
y\left(t\right)=\mu\left[1+\dfrac{\cancel{2}}{\cancel{2}\sqrt{1-\xi^{2}}}e^{-\sigma t}\cdot\cos\left(\omega t+\arccos\left(\xi\right)+\frac{\pi}{2}\right)\right]\text{sca}\left(t\right)
\]
\begin{equation}
=\mu\left[1-\dfrac{e^{-\xi\omega_{n}t}}{\sqrt{1-\xi^{2}}}\cdot\sin\left(\omega_{n}\sqrt{1-\xi^{2}}t+\arccos\left(\xi\right)\right)\right]\text{sca}\left(t\right)\label{eq:Risposta-scalino-ord-2-poli-complessi-coniugati}
\end{equation}

La risposta (mostrata ne \figref{Risposta-sistemi-2-ord-complessi-coniugati})
ha valore iniziale e derivata prima nulli nell'origine, poi segue
una sovraelongazione e l'uscita segue un andamento oscillante convergente
al valore di guadagno, con inviluppo esponenziale $e^{-\xi\omega_{n}t}$.
Nel caso di smorzamento nullo ($\xi=0$) le oscillazioni non si attenuano
nel tempo, e si ottiene una risposta oscillante limitata (sinusoidale)
nel tempo tra 0 e $\mu$.
\begin{rem}
Si può controllare che la sovraelongazione dipende solo dallo smorzamento:
vale infatti
\[
y_{{\scriptscriptstyle \text{MAX}}}=\mu\left(1+e^{\nicefrac{-\xi\pi}{\sqrt{1-\xi^{2}}}}\right)
\]
La sovraelongazione in percentuale vale $s_{\%}=e^{\nicefrac{-\xi\pi}{\sqrt{1-\xi^{2}}}}\cdot100$
(abbiamo usato la definizione enunciata ne \subsecref{Valori-della-risposta});
in generale sovraelongazione e smorzamento sono legati da una relazione
esponenziale di proporzionalità inversa.
\end{rem}
%
\begin{rem}
Sia smorzamento che pulsazione naturale influenzano la velocità con
cui le pulsazioni tendono a 0: l'inviluppo esponenziale del movimento
è analogo a quello di una risposta del primo ordine, con costante
di tempo $T=1/\xi\omega_{n}$.

Il tempo di assestamento, come nel caso di poli reali, vale $T_{a,\varepsilon}=-\ln\left(\varepsilon\right)/\xi\omega_{n}$.
\end{rem}

\section{Approssimazione a poli dominanti}

\marginpar{In presenza di zeri o poli con parte reale positiva (instabili) non
valgono le approssimazioni seguenti}Consideriamo un sistema asintoticamente stabile di ordine maggiore
del secondo, nel quale \uline{tutte} le singolarità (poli e zeri)
abbiano parte reale negativa; nel caso i cui alcuni poli o zeri abbiano
la parte reale in modulo molto maggiore di quella degli altri (la
costante di tempo associata è molto piccola), possiamo trascurare
quelle singolarità nell'espressione della risposta allo scalino del
sistema.
\begin{example}
\emph{\label{ese:Approssimazione-polo-dominante}Sia data la seguente
funzione di trasferimento:}
\[
G\left(s\right)=\frac{5}{\left(1+s\right)\left(1+10s\right)\left(\frac{s^{2}}{900}+\frac{s}{30}+1\right)}
\]
\emph{$\checkmark$Calcolare la risposta allo scalino del sistema.}

La consegna richiede di calcolare l'uscita dalla funzione di trasferimento
in risposta allo scalino; osserviamo che si tratta di un sistema del
$\mathrm{IV}$ ordine, e non vi sono state cancellazioni: sono presenti
due poli reali ($s_{1}=-1,\,s_{2}=-\frac{1}{10}$) e due poli complessi
coniugati ($s_{3,4}=-15\pm30\sqrt{\nicefrac{3}{4}}$, per quanto osservato
ne \subsecref{Sistemi-ord-2-poli-complessi-coniugati}).

Le costanti di tempo associate a ciascun polo saranno rispettivamente:
\[
T_{3,4}=\frac{1}{15}\,<\,T_{1}=1\,<\,T_{2}=10
\]
Se osserviamo i poli sul piano complesso, il polo più vicino all'origine
ha la costante di tempo maggiore, ed è proprio il polo dominante ($s_{2}$);
possiamo trascurare gli altri poli nel calcolo della risposta al sistema,
ottenendo la seguente funzione di trasferimento
\[
G^{\prime}\left(s\right)=\dfrac{5}{\left(1+10s\right)}
\]
la cui funzione di uscita ottenuta antitrasformando è
\[
y^{\prime}\left(t\right)=\mu\left(-e^{-10t}\right)\text{sca}\left(t\right).
\]
\end{example}
Se avessimo degli zeri con parte reale positiva, al contrario dei
poli positivi (i quali non possono mai essere trascurati), nel caso
essi abbiano costante di tempo molto piccola rispetto ai poli dominanti,
possiamo ignorare il loro contributo nella funzione di trasferimento,
aspettandoci un andamento qualitativo simile a quelli mostrati ne
\figref{Risposta-2-ord-zero-positivo} e \figref{Risposta-2-ord-zero-negativo}.\demo
\begin{example}
\emph{Prendiamo la funzione di trasferimento dell'Esercizio \ref{ese:Approssimazione-polo-dominante}
e ipotizziamo che abbia anche uno zero in $s_{z}=1$: $\checkmark$calcolare
la funzione di uscita in questo caso.}

Osserviamo che il nuovo zero ha parte reale positiva, e la sua costante
di tempo ($\tau_{z}=1$) è piccola rispetto a quella del polo dominante
($T_{2}=10$): possiamo approssimare la funzione di trasferimento
ignorando lo zero; si avrà un andamento in uscita con una sottoelongazione
dovuta allo zero positivo trascurato, poi delle oscillazioni attorno
al valore asintotico dovute ai poli complessi coniugati e infine il
transitorio si stabilirà attorno al valore finale in circa.\demo
\end{example}

\section{Realizzazione}

La realizzazione è il procedimento analitico che permette di ottenere
la descrizione di un sistema nella forma standard (\ref{eq:Forma-standard-matrice-LTI})
a partire dalla sua funzione di trasferimento; il modello trovato
per il sistema dovrà avere la stessa funzione di trasferimento di
partenza.

Si sceglie per comodità un sistema nella \emph{forma canonica di raggiungibilità}
(non ci sono cancellazioni polo-zero), dalla quale è possibile arrivare
ad equazioni adeguate adottando una sua rappresentazioni equivalente.

Partiamo dalla scrittura generale di una funzione di trasferimento
di un sistema SISO, immaginando di aver raccolto il termine di grado
massimo al denominatore:
\[
G\left(s\right)=\frac{\beta_{n}s^{n}+\beta_{n-1}s^{n-1}+\ldots+\beta_{0}}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}
\]
Cerchiamo ora delle matrici $A,\,B,\,C,\,D$ tali che valga l'equazione
(\ref{eq:Funzione-trasferimento}); nel caso più generale $\beta_{n}\neq0$
e il sistema sarà proprio (non strettamente), quindi anche la matrice
$D$ sarà non nulla. Cerchiamo di scomporre la funzione di trasferimento
nella combinazione di $\beta_{n}$ con una funzione strettamente propria,
ottenendo che $D=\beta_{n}$:
\[
G\left(s\right)=\frac{\beta_{n}\left(s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}\right)+\hat{\beta}_{n-1}s^{n-1}+\hat{\beta}_{n-2}s^{n-2}\ldots+\hat{\beta}_{0}}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}
\]
\[
=\frac{\beta_{n}s^{n}+\bigl(\overset{\beta_{n-1}}{\overbrace{\beta_{n}\alpha_{n-1}+\hat{\beta}_{n-1}}}\bigr)s^{n-1}+\ldots+\bigl(\overset{\beta_{0}}{\overbrace{\beta_{n}\alpha_{0}+\hat{\beta}_{0}}}\bigr)}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}
\]
Possiamo ricavare in generale da queste relazioni $\hat{\beta}_{i}$
come 
\[
\hat{\beta}_{i}=\beta_{i}-\beta_{i+1}\alpha_{i}
\]
La funzione di partenza vale allora
\[
G\left(s\right)=\beta_{n}+\frac{\hat{\beta}_{n-1}s^{n-1}+\hat{\beta}_{n-2}s^{n-2}+\ldots+\hat{\beta}_{0}}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}
\]
dove si ha la somma di una costante $\beta_{n}$ con una frazione
propria, il cui denominatore ha dei coefficienti $\hat{\beta}_{i}$
che sono funzioni dei coefficienti originali; notiamo per confronto
con (\ref{eq:Funzione-trasferimento}) che $\beta_{n}=D$.

Nel caso la funzione di trasferimento sia già strettamente propria
lo è anche il sistema, e la matrice $D$ risulta nulla.

Per trovare una realizzazione dobbiamo operare una scelta per il vettore
degli stati; il sistema derivante avrà $n$ stati, come il grado del
denominatore di $G\left(s\right)$:
\[
x\left(t\right)=\begin{bmatrix}x_{1}\left(t\right)\\
\dot{x}_{1}\left(t\right)\\
\vdots\\
\frac{\partial^{n-1}x\left(t\right)}{\partial t^{n-1}}
\end{bmatrix}
\]
Questa è una delle infinite possibili scelte, che comporta il seguente
modello:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Forma canonica di raggiungibilità}{\footnotesize{}\index{Forma canonica di raggiungibilità@{\footnotesize{}Forma canonica di raggiungibilità}}}}[1.8cm]
\begin{equation}
\begin{array}{c}
\dot{x}\left(t\right)=\overset{A}{\overbrace{\begin{bmatrix}0 & 1 & 0 & 0\\
0 & 0 & 1 & 0\\
0 & 0 & 0 & 1\\
-\alpha_{0} & -\alpha_{1} & \cdots & -\alpha_{n-1}
\end{bmatrix}}}x\left(t\right)+\overset{B}{\overbrace{\begin{bmatrix}0\\
\vdots\\
0\\
1
\end{bmatrix}}}u\left(t\right)\\
\\
y\left(t\right)=\overset{C}{\overbrace{\begin{bmatrix}\hat{\beta}_{0} & \hat{\beta}_{1} & \cdots & \hat{\beta}_{n-1}\end{bmatrix}}}x\left(t\right)+\overset{D}{\overbrace{\beta_{n}}}\cdot u\left(t\right)
\end{array}\label{eq:Forma-canonica-raggiungibilit=0000E0}
\end{equation}
Nella matrice $A$ le prime $n-1$ equazioni di stato sono banali,
poiché ogni derivata è pari allo stato successivo; essa è chiamata
forma canonica di raggiungibilità poiché l'ingresso è in grado di
influenzare l'ultimo stato, mentre gli stati successivi sono suoi
integratori (l'ingresso influenza tutti gli stati).\bigskip{}

Verifichiamo che da questa forma canonica si riottiene l'equazione
di partenza; applichiamo la trasformata degli stati ottenendo:
\[
\mathscr{L}^{-1}\left[\dot{x}\left(t\right)\right]=\begin{bmatrix}X_{1}\left(s\right)\\
sX_{1}\left(s\right)\\
\vdots\\
s^{n-1}X_{1}\left(s\right)\\
sX_{n}\left(s\right)
\end{bmatrix}
\]
dove l'ultima equazione di stato vale:
\[
sX_{n}\left(s\right)=-\alpha_{0}X_{1}\left(s\right)-\alpha_{1}sX_{1}\left(s\right)+\ldots-\alpha_{n-1}s^{n-1}X_{1}\left(s\right)+U\left(s\right)
\]
Il termine $U\left(s\right)$ è dovuto all'1 in ultima posizione della
matrice colonna $B$; raccogliendo gli $X_{i}\left(s\right)$ a sinistra
si ottiene:
\[
X_{i}\left(s\right)=\frac{s^{i-1}U\left(s\right)}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}
\]
Sostituendo questa espressione dello stato nell'equazione di uscita
avremo:
\[
Y\left(s\right)=C\cdot X\left(s\right)+\beta_{n}U\left(s\right)=\frac{\hat{\beta}_{n-1}s^{n-1}+\hat{\beta}_{n-2}s^{n-2}+\ldots+\hat{\beta}_{0}}{s^{n}+\alpha_{n-1}s^{n-1}+\ldots+\alpha_{0}}U\left(s\right)+\beta_{n}\cdot U\left(s\right)
\]
La matrice $C$ è una riga che moltiplicata per $X\left(s\right)$
dà una somma di termini con stesso denominatore in $\hat{\beta}$
e $s$, tutti moltiplicati per l'uscita; raccogliendo $U\left(s\right)$
nella precedente si riottiene la funzione di trasferimento di partenza
come $G\left(s\right)\cdot U\left(s\right)$.\bigskip{}

\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{s^{2}+3s+2}{s^{2}+6s+12}
\]
$\checkmark$Si ricavi la realizzazione di un sistema dinamico nella
forma canonica di raggiungibilità a cui corrisponde questa funzione
di trasferimento.}

Il grado di numeratore e denominatore è lo stesso, quindi possiamo
affermare che il sistema sarà proprio non strettamente; la funzione
di stato inoltre può essere riscritta come la somma di una costante
per una funzione razionale propria:
\[
G\left(s\right)=\frac{s^{2}+6s+12}{s^{2}+6s+12}+\frac{0+\left(3-6\right)s+\left(2-12\right)}{s^{2}+6s+12}=1+\frac{-3s-10}{s^{2}+6s+12}
\]
Possiamo ottenere le matrici della forma canonica direttamente da
(\ref{eq:Forma-canonica-raggiungibilit=0000E0}), osservando la riscrittura
appena effettuata:
\end{example}
\begin{itemize}
\item Sappiamo che, essendo la funzione di trasferimento propria, vale 
\[
D=\beta_{n}=1;
\]
\item Il grado del denominatore è pari a 2, quindi la matrice $A$ avrà
ordine 2; essa avrà nulli tutti gli elementi fino alla penultima riga,
con degli 1 nella sopra-diagonale principale, mentre nell'ultima riga
avremo gli inversi dei coefficienti del denominatore a partire da
quello di grado più basso:
\[
A=\begin{bmatrix}0 & 1\\
-12 & -6
\end{bmatrix};
\]
\item La matrice $B$ è una colonna di 2 elementi, tutti nulli eccetto l'ultimo;
\item La matrice $C$ è una riga formata dai coefficienti (non invertiti)
del numeratore a partire da quello di grado più basso
\[
C=\begin{bmatrix}-10 & -3\end{bmatrix};
\]
\end{itemize}
La forma (\ref{eq:Forma-standard-matrice-LTI}) di un sistema con
la funzione di trasferimento assegnata risulta:
\[
\begin{cases}
\dot{x}\left(t\right)=\begin{bmatrix}0 & 1\\
-12 & -6
\end{bmatrix}\cdot x\left(t\right)+\begin{bmatrix}0\\
1
\end{bmatrix}\cdot u\left(t\right)\\
\\
y\left(t\right)=\begin{bmatrix}-10 & -3\end{bmatrix}\cdot x\left(t\right)+u\left(t\right)
\end{cases}
\]

Usando la relazione (\ref{eq:Funzione-trasferimento}) si riottiene
la funzione di trasferimento assegnata dall'esercizio.\demo

\chapter{Schemi a blocchi}

\section{Elementi costitutivi}

Per realizzare delle formalizzazioni matematiche di sistemi interconnessi,
che siano comode dal punto di vista analitico, si usa il linguaggio
degli schemi a blocchi. I principali elementi che li costituiscono
sono:

\begin{table}[!h]
\begin{centering}
\begin{tabular}{>{\centering}m{0.3\textwidth}>{\raggedright}m{0.5\textwidth}}
Rappresentazione & %
\begin{minipage}[t]{0.5\textwidth}%
\begin{center}
Descrizione
\par\end{center}%
\end{minipage}\tabularnewline\addlinespace
\cmidrule{2-2} 
\includegraphics{\string"Illustrazioni/4_1-1 Sistema\string".pdf} & \emph{Sistema}, dotato di un ingresso $u$ e un'uscita $y$, associato
a una funzione di trasferimento $G\left(s\right)$;\tabularnewline\addlinespace
\cmidrule{2-2} 
\includegraphics{\string"Illustrazioni/4_1-2 Somma\string".pdf} & \emph{Nodo somma}, dotato di almeno due ingressi $u_{1}$ e $u_{2}$
caratterizzati da un segno $+$ o $-$, e una sola uscita $y=u_{1}-u_{2}$;\tabularnewline\addlinespace
\cmidrule{2-2} 
\includegraphics{\string"Illustrazioni/4_1-3 Diramazione\string".pdf} & \emph{Diramazione}, consiste nello sdoppiare un segnale: si rappresenta
con un ingresso $u$ e almeno due uscita $y_{1}$ e $y_{2}$ pari
all'ingresso.\tabularnewline\addlinespace
\end{tabular}
\par\end{centering}
\caption{Elementi costitutivi degli schemi a blocchi}
\label{tab:Elementi-costitutivi-schemi-blocchi}
\end{table}

\begin{minipage}[c]{0.4\textwidth}%
\begin{center}
\includegraphics[scale=0.9]{\string"Illustrazioni/4_1-4 Schema MIMO con blocchi SISO\string".pdf}
\par\end{center}
\captionof{figure}{Sistema con più ingressi e uscite rappresentato coi blocchi costitutivi}\label{fig:Sistema-con-pi=0000F9-uscite-blocchi-SISO}%
\end{minipage}%
\begin{minipage}[c]{0.6\textwidth}%
Per semplicità considereremo i sistemi SISO scalari; in presenza di
un sistema con ingressi e uscite multipli, ci si può ricondurre comunque
al caso SISO.
\begin{rem}
Prendiamo un sistema quadrato che in generale potrebbe avere molti
ingressi e uscite; nel nostro caso scegliamo un sistema di ordine
2 (nel dominio di Laplace); se è di ordine due e ha due uscite, la
matrice di trasferimento ha ordine 2, quindi possiede 4 funzioni di
trasferimento (ognuna razionale fratta); le uscite del sistema saranno
legati nel modo seguente: 
\[
Y\left(s\right)=\begin{bmatrix}Y_{1}\left(s\right)\\
Y_{2}\left(s\right)
\end{bmatrix}=\begin{bmatrix}G_{1,1}\left(s\right) & G_{1,2}\left(s\right)\\
G_{2,1}\left(s\right) & G_{2,2}\left(s\right)
\end{bmatrix}\cdot\begin{bmatrix}U_{1}\left(s\right)\\
U_{2}\left(s\right)
\end{bmatrix}
\]
Lo schema corrispondente, realizzato usando solo i blocchi SISO, è
ne \figref{Sistema-con-pi=0000F9-uscite-blocchi-SISO}.
\end{rem}
%
\end{minipage}

Lo schema è stato ottenuto rispettando la scrittura delle equazioni
di uscita, effettuando il prodotto righe per colonne della matrice
di trasferimento con quella degli ingressi; infatti vale:
\[
\begin{cases}
Y_{1}\left(s\right)=U_{1}\left(s\right)G_{1,1}\left(s\right)+U_{2}\left(s\right)G_{1,2}\left(s\right)\\
Y_{2}\left(s\right)=U_{1}\left(s\right)G_{2,1}\left(s\right)+U_{2}\left(s\right)G_{2,2}\left(s\right)
\end{cases}
\]

Vediamo \marginpar{Per descrivere il modello in esame sarà necessario uno schema per
la parte elettrica, uno schema per l'attuatore meccanico e uno schema
per l'aeroplano}un esempio di analisi tramite schema a blocchi di un meccanismo chiamato
\emph{equilibratore}: negli aeroplani si hanno tre gradi di libertà
che interessa controllare, le tre rotazioni attorno agli assi dello
spazio (beccheggio, rollio, imbardata); la superficie mobile degli
alettoni sulla coda è l'equilibratore.\bigskip{}

\begin{minipage}[c]{0.5\textwidth}%
\begin{example}
\emph{Sia dato il modello di circuito per un equilibratore dove: $v\left(t\right)$
è la tensione di comando (che rappresenta la posizione della cloche);
la serie di resistore e induttore rappresentano i parametri interni
del motore $M$ il quale, grazie alla corrente $i\left(t\right)$,
muove un albero meccanico collegato all'equilibratore; $\checkmark$scrivere
uno schema a blocchi che descriva il sistema.}
\end{example}
%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/4_1-5 Modello per equilibratore\string".pdf}
\par\end{center}
\captionof{figure}{Modello per equilibratore di un aereo}%
\end{minipage}\smallskip{}

\marginpar{\noun{(1)}\protect \\
\noun{Sistema Elettrico}}Cominciamo descrivendo il sistema elettrico, il cui ingresso è la
tensione di controllo $v\left(t\right)$ e l'uscita la coppia fornita
dal motore $T\left(t\right)$; in prima approssimazione vale $T=ki\left(t\right)$
con $k$ una costante caratteristica del motore.

Quando il motore comincia a girare si crea una differenza di tensione
indicata come forza elettro-motrice, pari in prima approssimazione
a $\mathscr{E}\left(t\right)=k\dot{\delta}\left(t\right)$, dove $\delta\left(t\right)$
è l'angolo di rotazione del motore e la sua derivata la velocità angolare
(per semplicità il motore ha una singola costante caratteristica $k$).

L'equazione di equilibrio elettrico sarà:
\[
v\left(t\right)=Ri\left(t\right)+L\frac{\partial i\left(t\right)}{\partial t}+\mathscr{E}\left(t\right)
\]
Osserviamo che l'induttanza è l'unico componente dinamico; esplicitiamo
la derivata rispetto al tempo della corrente, ottenendo:
\[
\frac{\partial i\left(t\right)}{\partial t}=\frac{1}{L}\left(v\left(t\right)-Ri\left(t\right)-k\dot{\delta}\left(t\right)\right)\qquad\text{(stato)}
\]
\[
T\left(t\right)=ki\left(t\right)\qquad\text{(uscita)}
\]
Anche $\dot{\delta}\left(t\right)$ è un ingresso per il sistema;
ricaviamo la funzione di trasferimento considerando gli ingressi $v\left(t\right)$,
$\dot{d}\left(t\right)$ e l'uscita $T\left(t\right)$:
\[
sI\left(s\right)=-\frac{R}{L}I\left(s\right)+\frac{1}{L}V\left(s\right)-\frac{k}{L}s\Delta\left(s\right)
\]
\[
\rightarrow I\left(s\right)=\frac{1}{L}\cdot\frac{1}{\left(s+\frac{R}{L}\right)}\cdot V\left(s\right)-\frac{k}{L}\cdot\frac{s}{\left(s+\frac{R}{L}\right)}\cdot\Delta\left(s\right)
\]
si ottiene trasformando l'equazione di stato associata a $i\left(t\right)$,
e considerando che $\mathscr{L}\left[\dot{\delta}\left(t\right)\right]=\Delta\left(s\right)$;
la trasformata dell'equazione di uscita si può riscrivere come il
prodotto di $k$ per la trasformata appena ottenuta $I\left(s\right)$:
\begin{equation}
T\left(s\right)=kI\left(s\right)=\frac{k}{L}\cdot\frac{1}{\left(s+\frac{R}{L}\right)}\cdot V\left(s\right)-\frac{k^{2}}{L}\cdot\frac{s}{\left(s+\frac{R}{L}\right)}\cdot\Delta\left(s\right)\label{eq:Trasferimento-1-sistema}
\end{equation}
Osserviamo che abbiamo le equazioni di un sistema del primo ordine,
asintoticamente stabile (con polo $-R/L$).

Analizziamo \marginpar{\noun{(2)}\protect \\
\noun{Sistema Meccanico}}adesso il sistema meccanico che trasferisce la coppia all'equilibratore
dell'aeroplano; un certo coefficiente di attrito $\beta$ si sviluppa
tra i cuscinetti e l'asse del motore, con un angolo di rotazione $\delta$
e una coppia applicata $T$; il sistema ha una sua inerzia alla rotazione
$J$.

Il sistema ha la seguente equazione di equilibrio:
\[
J\ddot{\delta}\left(t\right)+\beta\dot{\delta}\left(t\right)=T\left(t\right)
\]
La trasformata di Laplace di questa equazione è:
\[
Js^{2}\Delta\left(s\right)+\beta s\Delta\left(s\right)=T\left(s\right)
\]
Notiamo che l'ingresso di questo secondo sistema è la coppia (in uscita
dal sistema (\ref{eq:Trasferimento-1-sistema})), mentre l'uscita
è l'angolo di rotazione $\Delta$:
\begin{equation}
\Delta\left(s\right)=\frac{1}{\left(Js+\beta\right)s}T\left(s\right)\label{eq:Trasferimento-2-sistema}
\end{equation}
Abbiamo ottenuto un sistema del secondo ordine (denominatore di grado
2) con i poli $p_{1}=0,\,p_{2}=\beta/J$, semplicemente stabile con
un polo nell'origine; intuitivamente l'uscita di questo secondo sistema
sarà un ingresso in retroazione per il precedente (\ref{eq:Trasferimento-1-sistema}).

Per \marginpar{\noun{(3)}\protect \\
\noun{Sistema Velivolo}}concludere, analizziamo la meccanica di volo dell'aeroplano; abbiamo
in ingresso l'angolo $\Delta$ di rotazione dell'equilibratore, inoltre
il velivolo avrà un centro di massa ${\scriptstyle CM}$, la distanza
$d$ tra il punto in cui sarà applicata la forza dinamica e il centro
di massa; muovendo l'alettone si genera una forza $F_{{\scriptscriptstyle \text{D}}}$
di resistenza aerodinamica e una coppia resistente $M_{{\scriptscriptstyle \text{D}}}$.

Consideriamo il moto rotativo di beccheggio dell'aereo, orientato
con un angolo di rotazione $\theta$; in generale il velivolo avrà
un suo momento d'inerzia $J_{{\scriptscriptstyle \text{A}}}$, legato
a un coefficiente di attrito viscoso $\beta_{{\scriptscriptstyle \text{A}}}$.

L'equazione di equilibrio (in modo simile alla precedente) si ottiene
come:
\[
J_{{\scriptscriptstyle \text{A}}}\ddot{\theta}\left(t\right)+\beta_{{\scriptscriptstyle \text{A}}}\dot{\theta}\left(t\right)=M_{{\scriptscriptstyle \text{D}}}\left(t\right)+dF_{{\scriptscriptstyle \text{D}}}
\]
Approssimiamo la coppia e la forza legate all'aerodinamica con una
proporzione con lo spostamento dell'alettone:
\[
\begin{array}{l}
M_{{\scriptscriptstyle \text{D}}}\left(t\right)=k_{{\scriptscriptstyle A}}\delta\left(t\right)\\
F_{{\scriptscriptstyle \text{D}}}\left(t\right)=k_{{\scriptscriptstyle B}}\delta\left(t\right)
\end{array}
\]
dove le costanti $k_{{\scriptscriptstyle A,B}}$ sono proprie del
terzo sistema in esame; sostituendo nella precedente e trasformando
otteniamo:
\[
J_{{\scriptscriptstyle \text{A}}}s^{2}\Theta\left(s\right)+\beta_{{\scriptscriptstyle \text{A}}}s\Theta\left(s\right)=\left(k_{{\scriptscriptstyle A}}+dk_{{\scriptscriptstyle B}}\right)\Delta\left(s\right)
\]
L'uscita di interesse è proprio l'angolo di beccheggio dell'aeroplano,
mentre l'ingresso è la posizione dell'alettone; la funzione di trasferimento
è:
\begin{equation}
\Theta\left(s\right)=\frac{k_{{\scriptscriptstyle A}}+dk_{{\scriptscriptstyle B}}}{\left(J_{{\scriptscriptstyle \text{A}}}s+\beta_{{\scriptscriptstyle \text{A}}}\right)s}\Delta\left(s\right)\label{eq:Trasferimento-3-sistema}
\end{equation}
Abbiamo ottenuto un sistema del secondo ordine con i poli $p_{1}=0,\,p_{2}=\beta_{{\scriptscriptstyle \text{A}}}/J_{{\scriptscriptstyle \text{A}}}$,
semplicemente stabile con un polo nell'origine.

\begin{figure}[!h]
\begin{raggedright}
Lo schema a blocchi del sistema complessivo si ottiene dalle funzioni
di trasferimento (\ref{eq:Trasferimento-1-sistema}), (\ref{eq:Trasferimento-2-sistema})
e (\ref{eq:Trasferimento-3-sistema}) in forma fattorizzata:
\par\end{raggedright}
\begin{centering}
\includegraphics{\string"Illustrazioni/4_1-6 Schema per equilibratore dell'esercizio\string".pdf}
\par\end{centering}
\caption{Schema a blocchi dei 3 sistemi connessi}

\raggedright{}Nella sezione successiva vedremo come interpretare la
topologia di questo schema, per ottenere una unica funzione di trasferimento
tra il primo ingresso e l'ultima uscita.\demo
\end{figure}


\section{Regole di elaborazione}

\subsection{Sistemi in serie}

Si tratta di una cascata di due sistemi dinamici $G_{1}\left(s\right)$
con ingresso $U$ e  $G_{2}\left(s\right)$ con ingresso $U^{\prime}$,
uscita intermedia del primo sistema; valgono le seguenti regole di
elaborazione:
\[
\begin{cases}
U^{\text{\ensuremath{\prime}}}\left(s\right)=G_{1}\left(s\right)U\left(s\right)\\
Y\left(s\right)=G_{2}\left(s\right)U^{\prime}\left(s\right)=G_{2}\left(s\right)G_{1}\left(s\right)U\left(s\right)
\end{cases}
\]
Segue che la funzione di trasferimento complessiva della serie dei
sistemi è pari al \uline{prodotto} delle loro funzioni di trasferimento:
\begin{equation}
G\left(s\right)=G_{2}\left(s\right)G_{1}\left(s\right)=\frac{N_{G_{1}}\left(s\right)\cdot N_{G_{2}}\left(s\right)}{D_{G_{1}}\left(s\right)\cdot D_{G_{2}}\left(s\right)}\label{eq:Sistemi-in-serie}
\end{equation}
\begin{minipage}[c]{0.5\textwidth}%
Nel caso dei sistemi SISO è indifferente scambiare di posto le funzioni
di trasferimento nel prodotto, mentre nel caso di sistemi MIMO è necessario
rispettare l'ordine dei blocchi, dall'ultimo al primo della cascata
(si hanno prodotti di matrici, che non sono commutativi).%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/4_2-1 Sistemi in serie\string".pdf}
\par\end{center}
\captionof{figure}{Schema per sistemi in serie}%
\end{minipage}

I poli della funzione di trasferimento complessiva sono (a meno di
cancellazioni), rispetto alle singole funzioni, l'unione dei poli
delle singole funzioni di trasferimento: l'ordine complessivo è infatti
la somma degli ordini delle funzioni e gli autovalori rimangono inalterati;
se anche uno solo dei sistemi della serie è instabile, il sistema
complessivo sarà instabile.

In presenza di cancellazioni critiche (viene cancellato un polo instabile),
si ottiene un sistema complessivo apparentemente stabile, che ha tuttavia
dei modi interni instabili.

\subsection{Sistemi in parallelo}

Presentano una diramazione in ingresso, che immette lo stesso valore
in sistemi con trasferimento differente; le uscite di tali sistemi
sono raccolte da un nodo somma; valgono le seguenti regole di elaborazione:
\[
Y\left(s\right)=G_{1}\left(s\right)U\left(s\right)+G_{2}\left(s\right)U\left(s\right)=\left(G_{1}\left(s\right)+G_{2}\left(s\right)\right)U\left(s\right)
\]
Segue che la funzione di trasferimento complessiva del parallelo dei
sistemi è pari alla \uline{somma} delle loro funzioni di trasferimento:
\begin{equation}
G\left(s\right)=G_{1}\left(s\right)+G_{2}\left(s\right)=\frac{N_{G_{1}}\left(s\right)}{D_{G_{1}}\left(s\right)}+\frac{N_{G_{2}}\left(s\right)}{D_{G_{2}}\left(s\right)}=\frac{N_{G_{1}}\left(s\right)\cdot D_{G_{2}}\left(s\right)+N_{G_{2}}\left(s\right)\cdot D_{G_{1}}\left(s\right)}{D_{G_{1}}\left(s\right)\cdot D_{G_{2}}\left(s\right)}\label{eq:Sistemi-in-parallelo}
\end{equation}

Come nel caso della serie, i poli della funzione di trasferimento
complessiva (a meno di cancellazioni) sono l'unione dei poli delle
singole funzioni di trasferimento: l'ordine complessivo è la somma
degli ordini delle funzioni; se anche uno solo dei sistemi del parallelo
è instabile, il sistema complessivo sarà instabile.

In presenza di cancellazioni critiche, si ottiene un sistema complessivo
apparentemente stabile, che ha tuttavia dei modi interni instabili.

\subsection{Sistemi in retroazione}

Presentano un nodo somma che riporta l'uscita di un sistema nell'ingresso
dell'altro, sommandola all'ingresso esterno; l'uscita del primo sistema
è inoltre riportata in ingresso al secondo tramite una diramazione;
a seconda del segno del nodo somma si parla di retroazione negativa
o positiva; valgono le seguenti regole di elaborazione:
\[
\begin{cases}
U^{\prime}\left(s\right)=U\left(s\right)-G_{2}\left(s\right)Y\left(s\right)\\
Y\left(s\right)=G_{1}\left(s\right)\cdot U^{\prime}=G_{1}\left(s\right)\cdot\left(U\left(s\right)-G_{2}\left(s\right)Y\left(s\right)\right)
\end{cases}
\]
Riscriviamo la funzione di uscita in forma fattorizzata:
\[
1+G_{1}\left(s\right)G_{2}\left(s\right)Y\left(s\right)=G_{1}\left(s\right)U\left(s\right)\rightarrow Y\left(s\right)=\frac{G_{1}\left(s\right)}{1\mp G_{1}\left(s\right)G_{2}\left(s\right)}U\left(s\right)
\]
dove il $\mp$ dipende dall'opposto del segno della retroazione (nel
nostro caso $+$ per retroazione negativa); la regola generale per
ricavare il trasferimento complessivo consiste nel fare il rapporto
tra il ramo diretto e la funzione di anello, ovvero il prodotto di
tutte le funzioni di trasferimento sull'anello di retroazione:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Funzione di trasferimento d'anello}{\footnotesize{}\index{Funzione di trasferimento di anello@{\footnotesize{}Funzione di trasferimento di anello}}}}
\begin{equation}
L\left(s\right)=G_{1}\left(s\right)\cdot G_{2}\left(s\right)\label{eq:Funzione-trasferimento-di-anello}
\end{equation}
Enunciamo la seguente regola generale, per il calcolo della funzione
di trasferimento:
\begin{equation}
G\left(s\right)=\frac{H\left(s\right)}{1\mp L\left(s\right)}\label{eq:Sistemi-in-retroazione}
\end{equation}
dove $H\left(s\right)$ è il \emph{ramo diretto}, la serie di sistemi
tra l'ingresso e l'uscita di $G\left(s\right)$; nel nostro caso abbiamo
che il ramo diretto vale $G_{1}\left(s\right)$, con retroazione negativa:
\[
G\left(s\right)=\frac{G_{1}\left(s\right)}{1+G_{1}\left(s\right)G_{2}\left(s\right)}
\]

I poli della funzione di trasferimento complessiva si ottengono scrivendo
la forma fattorizzata rispetto al numeratore e denominatore delle
funzioni di trasferimento coinvolte nella retroazione:
\[
G\left(s\right)=\frac{N_{1}\left(s\right)D_{2}\left(s\right)}{D_{1}\left(s\right)D_{2}\left(s\right)+N_{1}\left(s\right)N_{2}\left(s\right)}
\]
In generale non sappiamo se le radici del nuovo denominatore coincidano
con quelle dei polinomi di partenza; è infatti possibile ricorrere
alla retroazione per spostare i poli instabili del sistema originario.
A meno di cancellazioni, l'ordine del sistema complessivo è la somma
dei gradi dei singoli sistemi.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/4_2-2 Sistemi in parallelo\string".pdf}
\par\end{center}
\captionof{figure}{Schema per sistemi in parallelo}\label{fig:Schema-sistemi-parallelo}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics{\string"Illustrazioni/4_2-3 Sistemi in retroazione\string".pdf}
\par\end{center}
\captionof{figure}{Schema per sistemi in retroazione}\label{fig:Schema-sistemi-retroazione}%
\end{minipage}

\subsection{Stabilità dei sistemi in retroazione}

Consideriamo un caso generale per la stabilità dei sistemi in retroazione
(vedi \figref{Schema-sistemi-retroazione}): prendendo due sistemi
con trasferimento $G_{a}\left(s\right)$ e $G_{b}\left(s\right)$
chiusi in un anello di retroazione negativa possiamo affermare che,
in assenza di cancellazioni tra le due funzioni, presi uscita e ingresso
qualsiasi sull'anello chiuso, scriviamo il trasferimento usando (\ref{eq:Sistemi-in-retroazione}):
\[
G\left(s\right)=\frac{N_{H}\left(s\right)}{D_{H}\left(s\right)}\cdot\frac{D_{a}\left(s\right)D_{b}\left(s\right)}{D_{a}\left(s\right)D_{b}\left(s\right)+N_{a}\left(s\right)N_{b}\left(s\right)}
\]
dove il denominatore sarà di grado massimo, e il denominatore della
funzione $H\left(s\right)$ avrà al più tutti i poli della funzione
$G\left(s\right)$.

In caso di cancellazioni critiche, per una opportuna scelta di ingresso
e uscita si manifestano dei poli instabili apparenti (la stabilità
dipende dalla scelta di ingresso e uscita).
\begin{example}
\emph{Siano date le seguenti funzioni di trasferimento:
\[
G_{1}\left(s\right)=\frac{\left(s+1\right)}{\left(s+2\right)\left(s+3\right)},\qquad G_{2}\left(s\right)=\frac{1}{\left(s+1\right)\left(s+2\right)}
\]
$\checkmark$Calcolare il trasferimento di anello del sistema in retroazione
ne }\figref{Schema-sistemi-retroazione}\emph{ con le due funzioni
di trasferimento assegnate.}

Calcoliamo la funzione di trasferimento di anello (\ref{eq:Funzione-trasferimento-di-anello}):
\[
L\left(s\right)=\frac{1}{\left(s+2\right)^{2}\left(s+3\right)}
\]
C'è stata una cancellazione (non critica, è stato cancellato un polo
negativo reale pari a $-1$); questo si deduce dal fatto che il grado
del denominatore è inferiore alla somma dei gradi dei denominatori
di $G_{1}$ e $G_{2}$.

Scriviamo il denominatore della funzione di trasferimento come:
\[
1+L\left(s\right)=1+\frac{1}{\left(s+2\right)^{2}\left(s+3\right)}=\frac{1+\left(s+2\right)^{2}\left(s+3\right)}{\left(s+2\right)^{2}\left(s+3\right)}
\]
Cerchiamo adesso il ramo diretto $H\left(s\right)$, riscrivendo (\ref{eq:Sistemi-in-retroazione}):
\[
G\left(s\right)=H\left(s\right)\cdot\frac{\left(s+2\right)^{2}\left(s+3\right)}{1+\left(s+2\right)^{2}\left(s+3\right)}
\]
Dalla scelta di $H\left(s\right)$, quindi di ingresso e uscita, il
trasferimento della retroazione cambia, perché è avvenuta una cancellazione:
\end{example}
\begin{itemize}
\item Consideriamo $H\left(s\right)=1$\\
otteniamo il trasferimento $G\left(s\right)=\frac{\left(s+2\right)^{2}\left(s+3\right)}{1+\left(s+2\right)^{2}\left(s+3\right)}$;
\item Consideriamo $H\left(s\right)=G_{2}\left(s\right)$\\
otteniamo il trasferimento $G\left(s\right)=\frac{\left(s+2\right)\left(s+3\right)}{1+\left(s+1\right)\left(s+2\right)^{2}\left(s+3\right)}$.
\end{itemize}
Notiamo che il grado del denominatore dipende strettamente dalla scelta
del ramo diretto, in presenza di cancellazioni.

\chapter{Risposta in frequenza}

\section{Risposta alla sinusoide}

Consideriamo un sistema LTI, SISO, stazionario e asintoticamente stabile,
descritto da (\ref{eq:Forma-standard-matrice-LTI}), con funzione
di trasferimento (\ref{eq:Funzione-trasferimento}); determiniamo
la risposta del sistema a un ingresso sinusoidale:
\[
u\left(t\right)=\overline{u}\cdot\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)\overset{{\scriptstyle \mathscr{L}}}{\longrightarrow}U\left(s\right)=\frac{\omega}{s^{2}+\omega^{2}}\overline{U}
\]
Scriviamo la risposta forzata in funzione dei poli della funzione
di trasferimento, usando il metodo di Heaviside (\ref{eq:Metodo-di-Heaviside})
per ottenere i termini dei poli complessi coniugati:
\[
Y\left(s\right)=G\left(s\right)\frac{\omega}{s^{2}+\omega^{2}}\overline{U}=\serie{i=1}n{\frac{P_{i}}{s+p_{i}}}+\frac{G\left(j\omega\right)\cancel{\omega}\overline{U}}{\left(s-j\omega\right)2j\cancel{\omega}}-\frac{G\left(-j\omega\right)\cancel{\omega}\overline{U}}{\left(s+j\omega\right)2j\cancel{\omega}}
\]
La sua antitrasformata sarà una sommatoria di esponenziali:
\[
y\left(t\right)=\left(\serie{i=1}n{P_{i}e^{-p_{i}t}}+\frac{\overline{U}}{2j}G\left(j\omega\right)e^{j\omega t}-\frac{\overline{U}}{2j}G\left(-j\omega\right)e^{-j\omega t}\right)\text{sca}\left(t\right)
\]
Osserviamo che la funzione di trasferimento valutata per $s=\pm j\omega$
è complessa; il suo valore può essere scritto in forma esponenziale:
\[
G\left(\pm j\omega\right)=\left|G\left(j\omega\right)\right|\cdot e^{\pm j\arg\left(G\left(j\omega\right)\right)}
\]
Scegliamo di valutare la risposta per un tempo $t\rightarrow\infty$,
che nel sistema asintoticamente stabile considerato fa tendere a zero
i movimenti dei poli reali negativi, mettendo in evidenza la somma
di termini complessi coniugati:
\[
y\left(t\rightarrow\infty\right)=\left|G\left(j\omega\right)\right|\overline{U}\left(\frac{e^{j\left(\omega t+\arg\left(G\left(j\omega\right)\right)\right)}-e^{-j\left(\omega t+\arg\left(G\left(j\omega\right)\right)\right)}}{2j}\right)\text{sca}\left(t\right)
\]
Applicando le formule di Eulero (\ref{eq:Formula-di-Eulero}) al numeratore
nella parentesi si ottiene:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Risposta all'ingresso sinusoidale}{\footnotesize{}\index{Risposta all'ingresso sinusoidale@{\footnotesize{}Risposta all'ingresso sinusoidale}}}}
\begin{equation}
y\left(t\right)=\left|G\left(j\omega\right)\right|\overline{U}\cdot\sin\left(\omega t+\arg\left(G\left(j\omega\right)\right)\right)\text{sca}\left(t\right)\label{eq:Risposta-ingresso-sinusoidale}
\end{equation}
Questa uscita ha la stessa pulsazione della sinusoide in ingresso
ma un'ampiezza alterata dal termine $\left|G\left(j\omega\right)\right|$;
si osserva anche uno sfasamento di $\arg\left(G\left(j\omega\right)\right)$.

Il risultato appena ottenuto si formalizza come il seguente Teorema
\ref{thm:Teorema-fondamentale-risposta-frequenza}:
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Teorema fondamentale della risposta in frequenza}{\footnotesize{}\index{Risposta in frequenza, teorema fondamentale@{\footnotesize{}Risposta in frequenza, teorema fondamentale}}}}[-0.2cm]\label{thm:Teorema-fondamentale-risposta-frequenza}Se si
applica a un sistema lineare, stazionario e asintoticamente stabile
(con funzione di trasferimento $G\left(s\right)$) un ingresso sinusoidale
$u\left(t\right)=\overline{u}\sin\left(\omega t\right)$, l'uscita
a transitorio esaurito assume l'andamento (\ref{eq:Risposta-ingresso-sinusoidale})
indipendentemente dallo stato iniziale.
\end{thm}
L'indipendenza dalle condizioni iniziali si ricava dalla sovrapposizione
degli effetti: l'uscita sarà la somma di movimento libero e forzato,
e l'asintotica stabilità implica l'annullamento della componente libera.
La velocità con cui l'uscita assume questa espressione dipende dalle
costanti di tempo dominanti del sistema (in termini ingegneristici,
si prende 5 volte la costante di tempo più alta, assumendo tutti i
transitori esauriti dopo questo tempo).

Il Teorema \ref{thm:Teorema-fondamentale-risposta-frequenza} non
vale nei casi in cui, tra gli zeri della funzione, è presente il termine
$s^{2}+\omega^{2}$: esso si cancella nell'equazione di uscita col
denominatore, annullando di fatto l'uscita. Questa caratteristica
si chiama \emph{proprietà bloccante degli zeri}.

Definiamo la risposta in frequenza di un sistema come\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Risposta armonica}{\footnotesize{}\index{Risposta armonica@{\footnotesize{}Risposta armonica}}}}[0.5cm]
\begin{equation}
\begin{array}{c}
G\left(j\omega\right)=C\left(j\omega I-A\right)^{-1}B+D\\
=\left|G\left(j\omega\right)\right|e^{j\arg\left(G\left(j\omega\right)\right)}
\end{array}\label{eq:Risposta-armonica}
\end{equation}
chiamata anche \emph{funzione di risposta armonica}; essa è funzione
della pulsazione. Questa definizione viene estesa (purché sia applicata
a un sistema LTI) anche per sistemi MIMO, e sistemi instabili - per
questi ultimi non valgono più le considerazioni riguardo (\ref{eq:Risposta-ingresso-sinusoidale}).

Prendiamo per esempio la risposta in frequenza associata al ritardo
di tempo; avremo la funzione di trasferimento $G\left(s\right)=e^{-\tau s}$
e l'uscita $y\left(t\right)=u\left(t-\tau\right)$. Applicando la
definizione (\ref{eq:Risposta-armonica}) si ottiene:
\[
G\left(j\omega\right)=e^{-\tau j\omega},\qquad\left|G\left(j\omega\right)\right|=1,\qquad\arg\left(G\left(j\omega\right)\right)=-\tau\omega
\]
Osserviamo che la funzione di risposta armonica ha modulo unitario
e fase proporzionale alla pulsazione tramite il ritardo di tempo.

In generale, per una data pulsazione possiamo calcolare (\ref{eq:Risposta-armonica})
e avere la variazione di ampiezza dell'uscita rispetto all'ingresso;
per esempio con una sinusoide pura in ingresso al sistema, si valuta
la funzione di trasferimento in $s=j\omega$ e possiamo calcolare
direttamente l'uscita. Combinazioni lineari di sinusoidi in ingresso
corrispondono, per sovrapposizione degli effetti, a una combinazione
lineare delle uscite, ottenute nel medesimo modo.

\section{Analisi della risposta in frequenza}

\subsection{Segnali esprimibili come serie di Fourier}

Prendiamo\marginpar{Si faccia attenzione alla notazione per gli ingressi: useremo $f\left(t\right)$
al posto di $u\left(t\right)$ nel resto del capitolo} un segnale periodico con periodo $T$, per cui valga quindi $f\left(t+T\right)=f\left(t\right)$;
se ipotizziamo $f\left(t+M\right)\neq f\left(t\right)\;\forall M\neq T$
e definiamo $\omega_{0}=2\pi/T$, allora possiamo associare alla funzione
del tempo $f\left(t\right)$ dei coefficienti complessi:
\[
F_{n}=\frac{1}{T}\somme T{}{f\left(t\right)\cdot e^{-jn\omega_{0}t}}t
\]
Se la funzione $f\left(t\right)$ è reale, allora $F_{-n}=F_{n}^{*}$;
i coefficienti associati $F_{n}$ si chiamano \emph{coefficienti di
Fourier}.

Esprimiamo la funzione $f\left(t\right)\in\mathbb{R}$ come:
\[
f\left(t\right)=F_{0}+\serie{n=1}{\infty}{\left(F_{n}e^{jn\omega_{0}t}+F_{n}^{*}e^{-jn\omega_{0}t}\right)}
\]
\begin{equation}
\overset{{\scriptscriptstyle \text{Eulero}}}{=}F_{0}+2\serie{n=1}{\infty}{\left|F_{n}\right|\cos\left(n\omega_{0}t+\arg\left(F_{n}\right)\right)}\label{eq:Scomposizione-in-serie-di-Fourier}
\end{equation}
Questa relazione si chiama \emph{scomposizione in serie di Fourier};
qualsiasi segnale nel tempo continuo può essere scomposto in una sommatoria
in generale infinita ma numerabile di cosinusoidi.

Se un segnale nella forma (\ref{eq:Scomposizione-in-serie-di-Fourier})
l'ingresso di un sistema LTI asintoticamente stabile, l'uscita si
scrive:
\[
y\left(t\right)=Y_{0}+2\serie{n=1}{\infty}{\left|Y_{n}\right|\cos\left(n\omega_{0}t+\arg\left(Y_{n}\right)\right)}
\]
dove i coefficienti di Fourier valgono rispettivamente:
\[
\begin{array}{c}
Y_{0}=\left|G\left(0\right)\right|F_{0}=\mu F_{0},\\
\vdots\\
\left|Y_{n}\right|=\left|F_{n}\right|\cdot\left|G\left(j\omega_{0}n\right)\right|,\;\arg\left(Y_{n}\right)=\arg\left(F_{n}\right)+\arg\left(G\left(j\omega_{0}n\right)\right)
\end{array}
\]
Osserviamo che il sistema dinamico non altera il contenuto in frequenza
del segnale di ingresso: il segnale di uscita sarà nella stessa banda
di frequenze di quello di ingresso; al più saranno alterati modulo
e fase dei contributi per ciascuna frequenza.

\subsection{Segnali dotati di trasformata di Fourier}

Possiamo considerare la trasformata di Fourier come la serie di Fourier
in cui le componenti in frequenza sono un'infinità non numerabile;
se abbiamo un segnale $f\left(t\right)$ definito per $t\in\left(-\infty,\,+\infty\right)$,
se esiste\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Trasformata di Fourier}{\footnotesize{}\index{Fourier, trasformata di@{\footnotesize{}Fourier, trasformata di}}}}[0.8cm]
\begin{equation}
F\left(j\omega\right)=\somme{-\infty}{+\infty}{f\left(t\right)e^{-j\omega t}}t=\mathscr{F}\left[f\left(t\right)\right]\label{eq:Trasformata-di-Fourier}
\end{equation}
essa si dice trasformata di Fourier del segnale; tipicamente essa
si indica col nome di \emph{spettro} in frequenza del segnale.

Se la funzione $f\left(t\right)$ è definita in $\mathbb{R}$, si
dimostra che $F\left(-j\omega\right)=F^{*}\left(j\omega\right)$;
inoltre si può esprimere:
\[
f\left(t\right)=\frac{1}{\pi}\somme 0{+\infty}{\left|F\left(j\omega\right)\right|\cos\left(\omega t+\arg\left(F\left(j\omega\right)\right)\right)}{\omega}
\]

\begin{example}
\emph{Sia dato il seguente segnale:
\[
f\left(t\right)=\text{imp}\left(t\right)
\]
$\checkmark$Calcolare la trasformata di Fourier del segnale.}

Applichiamo direttamente la definizione (\ref{eq:Trasformata-di-Fourier})
e scriviamo:
\[
F\left(j\omega\right)=\somme{-\infty}{+\infty}{\text{imp}\left(t\right)e^{-j\omega t}}t=e^{-j\omega0}=1
\]
Otteniamo questo risultato dalla definizione di impulso, il quale
è non nullo solo in $t=0$; questo segnale ha un contenuto in frequenza
costante su qualsiasi banda.

Se questo segnale $f\left(t\right)$ è l'ingresso di un sistema LTI,
con funzione di trasferimento $G\left(s\right)$, a transitorio esaurito
avremo, usando (\ref{eq:Scomposizione-in-serie-di-Fourier}):
\[
y\left(t\right)=\frac{1}{\pi}\somme 0{+\infty}{\overset{{\scriptstyle \left|Y\left(j\omega\right)\right|}}{\overbrace{\left|G\left(j\omega\right)\right|\left|F\left(j\omega\right)\right|}}\cos\bigl(\omega t+\overset{{\scriptstyle \arg\left(Y\left(j\omega\right)\right)}}{\overbrace{\arg\left(G\left(j\omega\right)\right)+\arg\left(F\left(j\omega\right)\right)}}\bigr)}{\omega}
\]
Si osserva un effetto di alterazione del modulo e di sfasamento; a
fronte di un segnale limitato in banda (la sua trasformata di Fourier
è non nulla solo per un certo intervallo di $\omega$) l'uscita avrà
lo stesso contenuto in frequenza, ovvero il sistema dinamico non aggiunge
componenti di frequenza in uscita al di fuori della banda imposta
dall'ingresso.\demo
\end{example}
\begin{rem}
Una prima interpretazione che possiamo dare alla funzione di risposta
armonica (\ref{eq:Risposta-armonica}) è il rapporto tra lo spettro
(\ref{eq:Trasformata-di-Fourier}) del segnale di ingresso e quello
di uscita.
\end{rem}
Lo spettro di un segnale e legato alla potenza del segnale stesso:
per esempio, un sistema asintoticamente stabile agisce attenuando
i modi delle componenti dello spettro alle alte frequenze.

\subsection{Segnali d'ingresso esponenziali}

Immaginiamo di avere l'ingresso $u\left(t\right)=e^{\lambda t}\overline{u}\cdot\text{sca}\left(t\right)$
con $\lambda>0$ (esponenziale divergente); la sua trasformata di
Laplace vale:
\[
\mathscr{L}\left[u\left(t\right)\right]=U\left(s\right)=\frac{\overline{U}}{s-\lambda}
\]

e l'uscita sarà pari a $Y\left(s\right)=G\left(s\right)U\left(s\right)$;
se il sistema è asintoticamente stabile, possiamo esprimere l'uscita
come:
\[
Y\left(s\right)=\serie{i=1}n{\frac{P_{i}}{s-p_{i}}+G\left(\lambda\right)\frac{\overline{U}}{s-\lambda}}
\]
Antitrasformando, dopo aver atteso l'esaurimento dei transitori, avremo:
\[
y\left(t\right)=G\left(\lambda\right)\overline{U}e^{\lambda t},\quad t\rightarrow\infty
\]
L'uscita forzata risulta un esponenziale con stesso esponente dell'ingresso
e coefficiente $G\left(\lambda\right)$; se ci fosse uno zero in $\lambda$,
si avrebbe una cancellazione e l'annullamento dell'uscita (di nuovo
emerge la proprietà bloccante degli zeri). Nel caso di questo esempio,
uno zero bloccante permette di avere uscita nulla non ostante l'ingresso
esponenziale arrivi a una ampiezza infinita.

\section{Diagrammi di Bode}

I diagrammi di Bode sono strumenti grafici per valutare l'andamento
nel tempo della funzione di risposta armonica (\ref{eq:Risposta-armonica}),
in particolare del suo modulo e della sua fase. Entrambi presentano
sull'ascissa la pulsazione $\omega$, definita da 0 a $+\infty$;
per questo asse si utilizza una scala logaritmica in base 10, in modo
che compaiano a distanza costante (decadi) potenze crescenti di 10.

Spostarsi di una decade sull'asse della pulsazione implica aumentare
o diminuire la pulsazione di un'ordine di grandezza.

Infine, l'ordinata presenta il modulo o la fase della risposta armonica,
a seconda del tipo di diagramma.

\subsection{Diagrammi del modulo}

Esso presenta sull'ordinata il modulo della risposta armonica espresso
in decibel, per il quale vale la relazione:
\[
\left|G\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\left|G\left(j\omega\right)\right|
\]
\[
\left|G\left(j\omega\right)\right|=10^{\frac{\left|G\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}}{20}}
\]
A meno del fattore 20, anche l'ordinata avrà una scala logaritmica
in base 10; in particolare, per le proprietà del logaritmo si verifica
che per $\left|G\left(j\omega\right)\right|=0\,dB$ vale $\left|G\left(j\omega\right)\right|_{{\scriptscriptstyle 10}}=1$;
per avere un modulo nullo sarebbe necessaria una pulsazione di $\omega=-\infty$. 

\begin{table}[!h]
\begin{centering}
\begin{tabular}{cc||cc||cc}
Decimale & Decibel & Decimale & Decibel & Decimale & Decibel\tabularnewline[\doublerulesep]
\hline 
1 & $0\,\text{dB}$ & $\sqrt{5}$ & $7\,\text{dB}$ & $\sqrt{10}$ & $10\,\text{dB}$\tabularnewline[\doublerulesep]
$\sqrt{2}$ & $3\,\text{dB}$ & $\sqrt{6}$ & $7.8\,\text{dB}$ & $2\sqrt{5}$ & $13\,\text{dB}$\tabularnewline[\doublerulesep]
$\sqrt{3}$ & $4.8\,\text{dB}$ & $\sqrt{7}$ & $8.5\,\text{dB}$ & 10 & $20\,\text{dB}$\tabularnewline[\doublerulesep]
2 & $6\,\text{dB}$ & $2\sqrt{2}$ & $9\,\text{dB}$ & $10\sqrt{10}$ & $30\,\text{dB}$\tabularnewline[\doublerulesep]
\end{tabular}
\par\end{centering}
\caption{Conversioni di ampiezze in scala logaritmica}
\label{tab:Conversioni-di-ampiezze}
\end{table}

Usando \tabref{Conversioni-di-ampiezze} possiamo vedere dei valori
notevoli di ampiezze in scala logaritmica e i corrispondenti valori
decimali (i valori in decibel sono approssimati). 

Per tracciare il diagramma della risposta armonica è necessario conoscere
l'andamento di quattro elementi fondamentali; per far emergere questa
caratteristica, è necessario scrivere la funzione di trasferimento
in forma fattorizzata, in particolare useremo quella di Bode (\ref{eq:Forma-di-Bode}):
\[
G\left(s\right)=\frac{\mu}{s^{g}}\cdot\frac{\prod_{i}\left(1+\tau_{i}s\right)\cdot\prod_{i}\left(1+2s\cdot\nicefrac{\zeta_{i}}{\alpha_{ni}}+\nicefrac{s^{2}}{\alpha_{ni}^{2}}\right)}{\prod_{i}\left(1+T_{i}s\right)\cdot\prod_{i}\left(1+2s\cdot\nicefrac{\xi_{i}}{\omega_{ni}}+\nicefrac{s^{2}}{\omega_{ni}^{2}}\right)}
\]
Valutando questa funzione per $s=j\omega$ (risposta armonica) ed
esprimendola in decibel, avremo il logaritmo di una frazione di prodotti,
che per le proprietà del logaritmo diventa una combinazione lineare:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Risposta armonica in forma di Bode}{\footnotesize{}\index{Risposta armonica in forma di Bode@{\footnotesize{}Risposta armonica in forma di Bode}}}}[1.3cm]
\begin{equation}
\begin{array}{c}
\left|G\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\left(\mu\right)-20g\log_{10}\left(j\omega\right)+\sum_{i}20\log_{10}\left|1+\tau_{i}j\omega\right|\\
\\
+\sum_{i}20\log_{10}\left|1+2j\omega\frac{\zeta_{i}}{\alpha_{ni}}+\frac{\left(j\omega\right)^{2}}{\alpha_{ni}^{2}}\right|-\sum_{i}20\log_{10}\left|1+T_{i}j\omega\right|\\
\\
-\sum_{i}20\log_{10}\left|1+2j\omega\frac{\xi_{i}}{\omega_{ni}}+\frac{\left(j\omega\right)^{2}}{\omega_{ni}^{2}}\right|
\end{array}\label{eq:Risposta-armonica-forma-Bode}
\end{equation}
Questa espressione mette in evidenza il fatto che, per ottenere la
funzione di risposta armonica in decibel, è necessaria la somma di
un numero finito (quattro) di andamenti:
\begin{enumerate}
\item Guadagno statico: $\mu$;
\item Poli o zeri nell'origine: $1/s^{g}$;
\item Poli o zeri reali: $\frac{1}{1+Ts},\,\frac{1}{1+\tau s}$;
\item Poli o zeri complessi coniugati: $\frac{1}{1+2s\xi/\omega_{n}+s^{2}/\omega_{n}^{2}},\,\frac{1}{1+2s\zeta/\alpha_{n}+s^{2}/\alpha_{n}^{2}}$.
\end{enumerate}
\noun{$\qquad$}\textbf{\noun{Guadagno statico}}\\
Il valore di guadagno è indipendente da $\omega$, e rimane costante;
il sua andamento è costante e interseca l'asse del modulo in $\left|\mu\right|_{{\scriptscriptstyle dB}}=20\log_{10}\left|\mu\right|$.
Il segno è determinato dal segno di $\mu$.\medskip{}

\noun{$\qquad$}\textbf{\noun{Poli o zeri nell'origine}}\\
Prendiamo $G_{p}\left(s\right)=1/s$ per un polo e $G_{z}\left(s\right)=s$
per uno zero nell'origine; il modulo della risposta armonica vale,
rispettivamente:
\[
\left|G_{p}\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\left(1/\left|\omega\right|\right)=-20\log_{10}\left|\omega\right|
\]
\[
\left|G_{z}\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\left|\omega\right|
\]

\begin{minipage}[c]{0.5\textwidth}%
Rappresentiamo sul diagramma di Bode del modulo, in corrispondenza
di $\omega=1$, una retta che interseca l'asse delle pulsazioni in
$\omega=1$, con coefficiente angolare che dipende, in generale, dal
numero di poli e di zeri nell'origine (quindi dal tipo $g$):
\[
\left.\frac{\partial}{\partial\omega}\right|_{{\scriptscriptstyle \omega=1}}=-20\cdot g\,dB/\text{dec}
\]
La retta scende di $20\,\text{dB}$ per ogni decade, per ogni polo
nell'origine; ne \figref{Bode-modulo-singolarit=0000E0-origine} viene
riportata la pendenza della retta del modulo rispetto al grado relativo.%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-1 Bode modulo singolarità origine\string".pdf}
\par\end{center}
\begin{center}
\captionof{figure}{Diagramma di Bode del modulo per singolarità nell'origine}\label{fig:Bode-modulo-singolarit=0000E0-origine}
\par\end{center}%
\end{minipage}\smallskip{}

\begin{example}
\emph{\label{exa:Esempio-bode-modulo-somma-grafici}Sia data la seguente
funzione di trasferimento:}
\[
G\left(s\right)=\frac{10}{s}
\]
\emph{$\checkmark$Disegnarne il diagramma di Bode del modulo.}

Calcoliamo la risposta armonica:
\[
\left|G\left(j\omega\right)\right|=10\cdot\frac{1}{\left|j\omega\right|}\overset{{\scriptscriptstyle dB}}{\longrightarrow}20\log_{10}\left(10\right)+20\log_{10}\left|\frac{1}{j\omega}\right|=20-20\log_{10}\left|j\omega\right|
\]

\begin{minipage}[c]{0.5\textwidth}%
Osserviamo che si ottiene esattamente la somma dei contributi del
termine costante $\left(1\right)$ e del polo nell'origine $\left(2\right)$;
anche il diagramma di Bode sarà la somma dei grafici di questi due
andamenti: un guadagno positivo si traduce in una traslazione verso
l'alto dell'andamento delle singolarità nell'origine.\demo%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-2 Bode modulo polo origine esercizio\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per la funzione dell'esercizio}%
\end{minipage}\smallskip{}
\end{example}
\noun{$\qquad$}\textbf{\noun{Poli e zeri reali}}\\
Prendiamo una funzione di trasferimento del tipo $G_{p}\left(s\right)=\frac{1}{1+Ts}$
per un polo (in $s=-1/T$) e $G_{z}\left(s\right)=\frac{1}{1+\tau s}$
per uno zero (in $s=-1/\tau$) reali; il modulo della risposta armonica
vale, rispettivamente:
\[
\left|G_{p}\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=-20\log_{10}\left|1+Tj\omega\right|=-20\log_{10}\sqrt{1+T^{2}\omega^{2}}
\]
\[
\left|G_{z}\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\sqrt{1+T^{2}\omega^{2}}
\]
A prescindere dal segno della parte reale del polo o dello zero, la
risposta armonica non cambia (e nemmeno il diagramma di Bode). Se
chiamiamo $\omega_{p}=1/\left|T\right|$ e $\omega_{z}=1/\left|\tau\right|$
il \emph{valore assoluto} del polo e dello zero in $G_{p}\left(s\right)$
e $G_{z}\left(s\right)$, possiamo tracciare il diagramma normalizzato
rispetto a $\omega/\omega_{p,z}$ in modo che il polo o lo zero si
trovino sempre in $\omega/\omega_{p,z}=1$:
\[
\left|G_{p,z}\left(j\frac{\omega}{\omega_{p,z}}\right)\right|_{{\scriptscriptstyle dB}}=\mp20\log_{10}\sqrt{1-\left(\frac{\omega}{\omega_{p,z}}\right)^{2}}
\]

A differenza del diagramma del modulo del guadagno o delle singolarità
nell'origine, per poli o zeri reali il diagramma tracciato in modo
asintotico non corrisponde con quello effettivo; possiamo comunque
conoscere con precisione l'andamento asintotico della risposta armonica:
\[
\left|G_{p}\left(j\frac{\omega}{\omega_{p}}\right)\right|_{{\scriptscriptstyle dB}}\simeq\begin{cases}
-20\log_{10}\left(1\right)=0 & \text{per }\omega/\omega_{p}\ll1\\
-20\log_{10}\left(\omega/\omega_{p}\right) & \text{per }\omega/\omega_{p}\gg1
\end{cases}
\]
\[
\left|G_{z}\left(j\frac{\omega}{\omega_{z}}\right)\right|_{{\scriptscriptstyle dB}}\simeq\begin{cases}
20\log_{10}\left(1\right)=0 & \text{per }\omega/\omega_{z}\ll1\\
20\log_{10}\left(\omega/\omega_{z}\right) & \text{per }\omega/\omega_{z}\gg1
\end{cases}
\]
Rispetto alla variabile $\omega/\omega_{p,z}$, abbiamo la somma delle
rette (per polo e per zero) $\mp20\log_{10}\left(\omega/\omega_{p,z}\right)$,
che risulta nel coefficiente angolare $-20\cdot g\,\text{dB}/\text{dec}$
in dipendenza dal tipo del sistema; mettendo insieme i due asintoti,
che si incrociano per $\omega/\omega_{p,z}=1$, otteniamo il diagramma
asintotico.

Il diagramma asintotico avrà errore massimo rispetto a quello effettivo
nel punto in cui i due asintoti si congiungono; in quel punto la risposta
armonica vale $20\log_{10}\sqrt{2}=-3\,\text{dB}$.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-3 Bode modulo polo reale\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per poli reali}%
\end{minipage} %
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-4 Bode modulo zero reale\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per zeri reali}%
\end{minipage}\bigskip{}

\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{1}{1+0.1s}
\]
$\checkmark$Tracciare il diagramma del modulo.}

Notando che la funzione possiede un polo in $s=10$, e sapendo che
esso si troverà in $\omega/\omega_{p}=1$, possiamo concludere che
$\omega_{p}=10$; il diagramma corrispondente è ne \figref{Un-polo-s=00003D10}.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-5 Bode modulo un polo s=10\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per un polo in s=10}\label{fig:Un-polo-s=00003D10}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-6 Bode modulo due poli s=10\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per due poli in s=10}\label{fig:Due-poli-s=00003D10}%
\end{minipage}

\marginpar{Grazie all'uso dei decibel, il prodotto del modulo di due singolarità
è scritto come somma dei coefficienti angolari associati}Se avessimo la funzione $G\left(s\right)=\frac{1}{\left(1+0.1s\right)^{2}}$
con due poli coincidenti, dovremmo sommare due grafici come quello
appena ottenuto (vedi \figref{Due-poli-s=00003D10}): in tal caso
a sinistra di $\omega/\omega_{p}$ il modulo della risposta è nullo,
mentre a destra esso è rappresentato da una retta con pendenza $-40\,\text{dB}/\text{dec}$.

Se avessimo degli zeri invece dei poli appena analizzati, l'esercizio
sarebbe stato risolto invertendo i grafici del modulo rispetto all'asse
$\omega$.\demo
\end{example}
\noun{$\qquad$}\textbf{\noun{Poli e zeri complessi coniugati}}\\
Due poli sono complessi coniugati se vale $\xi\in\left(-1,\,1\right)$;
inoltre assumiamo $\omega>0$. Se $\xi=0$ i poli saranno immaginari
puri. Avremo una funzione di trasferimento del tipo:
\[
G_{p}\left(s\right)=\frac{1}{1+2s\frac{\xi}{\omega_{n}}+\frac{s^{2}}{\omega_{n}^{2}}}
\]
la cui risposta armonica vale in modulo:
\[
\left|G_{p}\left(j\omega\right)\right|=\left|\frac{1}{1+2j\omega\frac{\xi}{\omega_{n}}-\frac{\omega^{2}}{\omega_{n}^{2}}}\right|\overset{{\scriptscriptstyle dB}}{\longrightarrow}-20\log_{10}\left|1-\left(\frac{\omega}{\omega_{n}}\right)^{2}+j\cdot\frac{2\omega\xi}{\omega_{n}}\right|
\]
\[
=-20\log_{10}\sqrt{\left(1-\left(\omega/\omega_{n}\right)^{2}\right)^{2}+4\xi^{2}\left(\omega/\omega_{n}\right)^{2}}
\]
A prescindere dal segno della parte reale, la risposta armonica non
cambia (possiamo analizzare il modulo dello smorzamento $\left|\xi\right|$).
Se avessimo voluto condurre questa analisi per due zeri complessi
coniugati, saremmo giunti allo stesso risultato a meno del segno:
\[
\left|G_{z}\left(j\omega\right)\right|_{{\scriptscriptstyle dB}}=20\log_{10}\sqrt{\left(1-\left(\omega/\alpha_{n}\right)^{2}\right)^{2}+4\zeta^{2}\left(\omega/\alpha_{n}\right)^{2}}
\]
Se normalizziamo rispetto alla pulsazione propria, otteniamo i seguenti
asintoti:\marginpar{Abbiamo usato la proprietà dei logaritmi $\log_{a}b^{\alpha}=\alpha\log_{a}b$}\emph{Scrivere
la sua risposta armonica in forma esponenziale.}
\[
\left|G_{p}\left(j\frac{\omega}{\omega_{n}}\right)\right|_{{\scriptscriptstyle dB}}\simeq\begin{cases}
-20\log_{10}\left(1\right)=0 & \text{per }\omega/\omega_{n}\ll1\\
-40\log_{10}\left(\omega/\omega_{n}\right) & \text{per }\omega/\omega_{n}\gg1
\end{cases}
\]
\[
\left|G_{z}\left(j\frac{\omega}{\alpha_{n}}\right)\right|_{{\scriptscriptstyle dB}}\simeq\begin{cases}
20\log_{10}\left(1\right)=0 & \text{per }\omega/\alpha_{n}\ll1\\
40\log_{10}\left(\omega/\alpha_{n}\right) & \text{per }\omega/\alpha_{n}\gg1
\end{cases}
\]
Risulta che il diagramma asintotico è uguale a quello di due poli
o due zeri reali coincidenti; il diagramma effettivo dipende dal valore
di smorzamento:
\begin{itemize}
\item Poli
\begin{itemize}
\item per $\left|\xi\right|=1$ si hanno due poli reali coincidenti, con
pulsazione $\omega_{n}$; il diagramma effettivo avrà distanza di
$-6\,\text{dB}$ dalla pulsazione $\omega/\omega_{n}=1$ (dato che
sommiamo gli andamenti dei due poli);
\item per $\left|\xi\right|=0$ si avrebbe un modulo pari a $+\infty\,\text{dB}$:
il diagramma effettivo presenta un asintoto verticale per $\omega/\omega_{n}=1$.
\end{itemize}
\item Zeri
\begin{itemize}
\item per $\left|\xi\right|=1$ si hanno due zeri reali coincidenti, con
pulsazione $\alpha_{n}$; il diagramma effettivo avrà distanza di
$+6\,\text{dB}$ dalla pulsazione $\omega/\alpha_{n}=1$ (dato che
sommiamo gli andamenti dei due zeri);
\item per $\left|\xi\right|=0$ si avrebbe un modulo pari a $-\infty\,\text{dB}$:
il diagramma effettivo presenta un asintoto verticale per $\omega/\alpha_{n}=1$.\smallskip{}
\end{itemize}
\item \marginpar{La pulsazione di risonanza è definita anche per zeri complessi coniugati,
sostituendo $\alpha_{n}$ a $\omega_{n}$ nell'enunciato}per $\left|\xi\right|\in\left(0,\,1/\sqrt{2}\right)$ il diagramma
effettivo presenterà un massimo, chiamato \emph{picco di risonanza};
esso si trova in corrispondenza della \emph{pulsazione di risonanza},
definita come $\omega_{{\scriptscriptstyle \text{R}}}=\omega_{n}\sqrt{1-2\xi^{2}}$;
minore è lo smorzamento e più il picco sarà vicino al valore di pulsazione
naturale della singolarità.
\end{itemize}
Ponendoci nel caso $\omega/\omega_{n}=1$ per poli e $\omega/\alpha_{n}=1$
per zeri, il modulo della risposta vale:
\[
\left|G_{p}\left(j\omega_{n}\right)\right|=\frac{1}{2\left|\xi\right|},\quad\left|G_{z}\left(j\alpha_{n}\right)\right|=2\left|\xi\right|
\]

\begin{rem}
I sistemi con smorzamento sufficientemente piccolo presentano un picco
di risonanza, ovvero a fronte di un segnale di ingresso, applicato
con componente spettrale su determinate frequenze, l'uscita presenterà
un contenuto in frequenza amplificato attorno a quelle pulsazioni.
\end{rem}
%
\begin{rem}
Per smorzamento nullo ($\zeta=0$) si hanno due zeri immaginari puri:
dal diagramma di Bode si vede l'effetto bloccante degli zeri, poiché
due zeri complessi coniugati di pulsazione $\alpha_{n}$ sono l'inverso
della trasformata (di Fourier) di una sinusoide di pulsazione $\alpha_{n}$.

In corrispondenza di tale pulsazione, sul diagramma si ha guadagno
nullo ($-\infty\,\text{dB}$), ovvero le frequenze attorno alla pulsazione
$\alpha_{n}$ sono eliminate dall'uscita; infatti fornendo in ingresso
una sinusoide pura di pulsazione $\alpha_{n}$, l'uscita sarà nulla.
\end{rem}
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-7 Bode modulo poli cc\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per poli complessi coniugati}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-8 Bode modulo zeri cc\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo per zeri complessi coniugati}%
\end{minipage}

\subsection*{Tracciamento del diagramma del modulo\label{subsec:Tracciamento-Bode-modulo}}

Possiamo tracciare il diagramma di Bode del modulo di una funzione
di trasferimento in due modi: il primo consiste nell'isolare guadagno
statico e singolarità nell'origine, tracciando i diagrammi del modulo
di ciascuna singolarità e poi sommandoli assieme per ciascuna pulsazione
(come è stato fatto nell'Esempio \ref{exa:Esempio-bode-modulo-somma-grafici});
anche se immediato, esso diventa sconveniente per funzioni con molte
singolarità.

Il\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Tracciamento del diagramma del modulo}{\footnotesize{}\index{Tracciamento del diagramma del modulo@{\footnotesize{}Tracciamento del diagramma del modulo}}}}[-0.2cm] secondo approccio consiste nei seguenti passi:
\begin{itemize}
\item Assumendo $\omega\rightarrow0$, tracciamo l'andamento asintotico
di $\mu/s^{g}$; questo è sempre possibile, dato che si può scegliere
una pulsazione iniziale piccola a piacere per la quale il contributo
delle singolarità si annulla; questa sarà in generale una retta con
pendenza $-20\cdot g\,\text{dB}/\text{dec}$, che passerebbe (in assenza
di altre singolarità) per $\mu|_{{\scriptscriptstyle dB}}$ in corrispondenza
di $\omega=1$.
\item Si aumenta la pulsazione, visitando mano a mano ciascuna singolarità,
fino a superare l'ultima almeno di una decade:
\begin{itemize}
\item Ogni volta che si incontra un polo la pendenza cambia di $-20\,\text{dB}/\text{dec}$;
\item Ogni volta che si incontra uno zero la pendenza cambia di $+20\,\text{dB}/\text{dec}$;
\item La pendenza finale, dopo l'ultima singolarità, sarà pari a $-20\,\text{dB}/\text{dec}$
per il grado relativo della funzione.
\end{itemize}
\end{itemize}
Questo approccio risulta più veloce del precedente, necessita soltanto
di individuare tutte le singolarità sull'asse delle pulsazioni.
\begin{example}
\emph{\label{exa:Bode-modulo-esempio-riepilogo}Sia data la seguente
funzione di trasferimento:
\[
G\left(s\right)=\frac{10\left(1-s\right)\left(1+10s\right)}{s\left(1+0.1s\right)\left(1-\frac{s}{300}+\frac{s^{2}}{90000}\right)}
\]
$\checkmark$Tracciare il diagramma asintotico del modulo della funzione.}

Per prima cosa isoliamo il guadagno statico generalizzato, usando
la definizione (\ref{eq:Teorema-valore-iniziale}):
\[
\mu=\lm s0{s^{g}G\left(s\right)}=10=20\,dB
\]
Otteniamo questo risultato poiché il tipo del sistema è $g=1$ (un
polo nell'origine); le singolarità si trovano in corrispondenza dei
seguenti valori
\[
z_{1}=1,\,z_{2}=-1/10,\qquad p_{1}=0,\,p_{2,3}=\{\omega_{n}=300,\,\xi=-1/2\}
\]
Per i poli complessi coniugati $p_{2,3}$ abbiamo considerato smorzamento
e pulsazione naturale, dato che sono gli unici valori determinanti
sul diagramma del modulo; abbiamo ottenuto la pulsazione dal termine
fattorizzato in forma di Bode:
\[
1+2s\frac{\xi}{\omega_{n}}+\frac{s^{2}}{\omega_{n}^{2}}=1-\frac{s}{300}+\frac{s^{2}}{90000}
\]
da cui si ricava direttamente $\omega_{n}=\sqrt{90000}=300$, e impostando
$\frac{2\xi}{300}={\scriptstyle -}\frac{1}{300}$ si ottiene $2\xi=-1\rightarrow\xi=-1/2$.

Indicando sull'ascissa delle pulsazioni una decade precedente ($10^{-2}$)
alla singolarità dalla pulsazione più bassa ($z_{2}\rightarrow10^{-1}$),
e una decade successiva ($10^{3}$) alla singolarità dalla pulsazione
più elevata ($p_{2,3}\rightarrow300$).

Sull'ordinata è comodo segnare multipli interi di $20\,\text{dB}$,
mentre sull'ascissa si segnano le decadi intermedie all'intervallo
prescelto e la posizione delle singolarità (indicando gli zeri con
$\ocircle$ e i poli con $\times$).

\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-9 Bode modulo esercizio 4\string".pdf}
\par\end{centering}
\caption{Diagramma del modulo della funzione per l'esempio}
\end{figure}

Usando il metodo proposto, tracciamo il profilo di una retta che passa
per $\omega=1,\,\left.\mu\right|_{{\scriptscriptstyle dB}}=20\,\text{dB}$,
con pendenza $-20\,\text{dB}/\text{dec}$; questa retta corrisponde
con l'andamento asintotico del modulo fino alla prima singolarità
($z_{2}$): dal momento che si tratta di uno zero, la pendenza cambia
di $+20\,\text{dB}/\text{dec}$, annullandosi; lo zero successivo
$z_{1}$, in $\omega=1$, comporta un ulteriore aumento della pendenza
che diventa $20\,\text{dB}/\text{dec}$.

Segue il polo $p_{1}$ in $\omega=10$, che abbassa di nuovo la pendenza
di $-20\,\text{dB}/\text{dec}$, annullandola; infine i poli complessi
coniugati $p_{2,3}$ in $\omega=300$ abbassano la pendenza di $-40\,\text{dB}/\text{dec}$;
il modulo si azzererà alla decade successiva, in $\omega=3000$. Questo
viene riconfermato dal fatto che il grado relativo è 2 (numeratore
del 2° grado e denominatore del 4°).

Il diagramma effettivo differisce per gli errori di $\pm3\,\text{dB}$
in corrispondenza della pulsazione dei poli e zeri reali ($z_{1},\,z_{2},\,p_{1}$),
e di $-6\,\text{dB}$ in corrispondenza della coppia di poli complessi
coniugati $p_{2,3}$, in prossimità della quale è presente un picco
di risonanza (lo smorzamento $\left|\xi\right|=0.5$ è minore del
limite di sotto-smorzamento $1/\sqrt{2}\simeq0.7$).\demo
\end{example}

\subsection{Diagrammi della fase}

Una generica funzione di trasferimento valutata come risposta armonica,
essa può essere espressa nella forma (\ref{eq:Risposta-armonica});
se essa è il risultato del prodotto di ciascuna singolarità (anch'esse
espresse in forma esponenziale), allora il modulo della risposata
armonica sarà il prodotti dei moduli delle singolarità e la fase della
risposta armonica sarà la somma delle fasi delle singolarità.
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:}
\[
G\left(s\right)=\frac{1+s}{1+10s}
\]
\emph{$\checkmark$Scrivere la sua risposta armonica in forma esponenziale.}

Scomponiamo la frazione in un prodotto di funzioni, poi le esprimiamo
in forma esponenziale:\marginpar{Abbiamo usato la proprietà della fase $\arg\left(1/a\right)=-\arg\left(a\right)$}
\[
G\left(j\omega\right)=\left(1+j\omega\right)\cdot\frac{1}{1+10j\omega}=\left|1+j\omega\right|e^{j\arg\left(1+j\omega\right)}\cdot\left|\left(1+10j\omega\right)^{-1}\right|e^{j\arg\left(1+j\omega\right)^{-1}}
\]
\[
=\left|\frac{1+j\omega}{1+10j\omega}\right|e^{j\left(\arg\left(1+j\omega\right)-\arg\left(1+10j\omega\right)\right)}
\]
\demo
\end{example}
Nei diagrammi di Bode della fase, essa si esprime in gradi; per passare
da radianti a gradi richiamiamo la relazione:
\[
\arg\left(s\right)\,\text{rad}=\frac{\pi}{180{^\circ}}\arg\left(s\right){^\circ}
\]
Esprimendo in forma (\ref{eq:Forma-di-Bode}) la funzione di risposta
armonica, otteniamo (come prima) l'andamento (\ref{eq:Risposta-armonica-forma-Bode});
ricaviamo di nuovo quattro elementi, come per i diagrammi del modulo,
per tracciare i diagrammi della fase.\bigskip{}

$\qquad$\textbf{\noun{Guadagno statico}}\\
Il guadagno $\mu$ è un numero reale: se lo rappresentiamo sul piano
complesso, esso sarà sull'asse reale ($\Im\left(\mu\right)=0$): \marginpar{Si prende per convenzione l'angolo negativo in senso antiorario}
\[
\begin{cases}
\arg\left(\mu\right)=0 & \text{per }\mu>0\\
\arg\left(\mu\right)=-180{^\circ} & \text{per }\mu<0
\end{cases}
\]
Il diagramma di Bode risultante avrà andamento costante a $0{^\circ}$
o $-180{^\circ}$.\bigskip{}

$\qquad$\textbf{\noun{Poli e zeri nell'origine}}\\
Prendiamo la funzione di trasferimento $G_{p}\left(s\right)=1/s$;
la fase della risposta armonica vale:
\[
\arg\left[G_{p}\left(j\omega\right)\right]=\arg\left(1/j\omega\right)=-\arg\left(j\omega\right)
\]

Notiamo che, trattandosi di un polo nell'origine, la fase avrà segno
negativo in ogni caso (per uno zero nell'origine si avrebbe segno
positivo); se rappresentiamo il numero $j\omega$ sull'asse dei numeri
immaginari, dato che nei diagrammi di Bode $\omega>0$, esso sarà
definito solo sul semiasse immaginario positivo.

Segue che la fase associata sarà costante, $-90{^\circ}$ per un polo
e $90{^\circ}$ per uno zero (da ricordare il segno meno della fase
di un polo). In generale si avrà un contributo che dipende dal numero
di poli e zeri nell'origine, ovvero dal tipo del sistema:
\[
\arg\left(1/s^{g}\right)=-\arg\left(s^{g}\right)=-90{^\circ}\cdot g
\]

$\qquad$\textbf{\noun{Poli e zeri reali}}\\
Prendiamo la funzione di trasferimento $G_{p}\left(s\right)=$$\frac{1}{1+sT}$
con un polo reale e $G_{z}\left(s\right)=1+s\tau$ con uno zero reale;
la risposta armonica vale:
\[
\arg\left[G_{p}\left(j\omega\right)\right]=\arg\left(\frac{1}{1+j\omega T}\right)=-\arg\left(1+j\omega T\right)
\]
\[
\arg\left[G_{z}\left(j\omega\right)\right]=\arg\left(1+j\omega\tau\right)
\]
Il numero complesso di cui si cerca la fase ha parte reale pari a
1 e parte immaginaria pari a $\omega T$; se rappresentiamo questo
numero sul piano complesso, esso si troverà sulla retta perpendicolare
all'ascissa, passante in $\Re=1$; inoltre a seconda del segno della
costante di tempo, esso avrà fase positiva o negativa.

Osserviamo che, per $\omega=\pm1/\left|T\right|$, la fase vale $\pm45{^\circ}$,
in dipendenza dal segno della singolarità, e dalla presenza di un
polo che inverte il segno della fase. Inoltre per $\omega\rightarrow+\infty$,
il numero sul piano complesso ha parte immaginaria tendente a $\pm\infty$
e la sua fase tende a $\pm90{^\circ}$.

Riassumiamo queste considerazioni nelle seguenti approssimazioni asintotiche:
\[
\arg\left[G_{p}\left(j\frac{\omega}{\omega_{p}}\right)\right]\simeq\begin{cases}
-\arg\left(1\right)=0{^\circ} & \text{per }\omega/\omega_{p}\ll1\\
-\arg\left(j\frac{\omega}{\omega_{p}}\left(\pm T\right)\right)=\mp90{^\circ} & \text{per }\omega/\omega_{p}\gg1
\end{cases},\,\text{per }T\gtrless0
\]
\[
\arg\left[G_{z}\left(j\frac{\omega}{\omega_{z}}\right)\right]\simeq\begin{cases}
\arg\left(1\right)=0{^\circ} & \text{per }\omega/\omega_{z}\ll1\\
\arg\left(j\frac{\omega}{\omega_{p}}\left(\pm\tau\right)\right)=\pm90{^\circ} & \text{per }\omega/\omega_{z}\gg1
\end{cases},\,\text{per }\tau\gtrless0
\]

\begin{rem}
Si ricordi che il segno dei poli e degli zeri è l'inverso di quello
con cui compaiono fattorizzati nella funzione di trasferimento: per
esempio la funzione $G\left(s\right)=1+\tau s$ presenta uno zero
reale negativo, in $s=-1/\tau$ (lo stesso vale per i poli).
\end{rem}
L'andamento asintotico ha una discontinuità di salto di $90{^\circ}$
per $\omega=1$, mentre l'andamento reale ha la forma di un'arcotangente,
passante per la fase $45{^\circ}$.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-10 Bode fase poli neg (zeri pos)\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase per poli reali negativi e zeri reali positivi}\label{fig:Bode-fase-poli-neg-zeri-pos}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-11 Bode fase poli pos (zeri neg)\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase per zeri reali positivi e zeri reali negativi}\label{fig:Bode-fase-poli-pos-zeri-neg}%
\end{minipage}\bigskip{}

$\qquad$\textbf{\noun{Poli e zeri complessi coniugati}}\\
Prendiamo la funzione di trasferimento $G_{p}\left(s\right)=\frac{1}{1+2s\xi/\omega_{n}+s^{2}/\omega_{n}^{2}}$
con due poli complessi coniugati e $G_{z}\left(s\right)=1+2s\zeta/\alpha_{n}+s^{2}/\alpha_{n}^{2}$
con due zeri complessi coniugati; la fase della risposta armonica
vale:
\[
\arg\left[G_{p}\left(j\omega\right)\right]=-\arg\left(1+2j\xi\cdot\omega/\omega_{n}-\omega^{2}/\omega_{n}^{2}\right)
\]
\[
\arg\left[G_{z}\left(j\omega\right)\right]=\arg\left(1+2j\zeta\cdot\omega/\alpha_{n}-\omega^{2}/\alpha_{n}^{2}\right)
\]
Se rappresentiamo sul piano complesso i numeri immaginari di cui cerchiamo
la fase, vediamo che il segno dello smorzamento determina l segno
della fase, inoltre il segno della fase di poli complessi coniugati
sarà sempre invertito.

Osservando il segno delle singolarità e dello smorzamento giungiamo
alle seguenti conclusioni:
\[
\arg\left[G_{p}\left(j\omega\right)\right]\simeq\begin{cases}
-\arg\left(1\right)=0\text{°} & \text{per }\omega/\omega_{n}\ll1\\
-\arg\left(2j\left(\pm\xi\right)\right)=\mp90{^\circ} & \text{per }\omega/\omega_{n}=1\\
-\arg\left(-\left(\omega/\omega_{n}\right)^{2}\pm2j\xi\omega/\omega_{n}\right)=\mp180{^\circ} & \text{per \ensuremath{\omega}/\ensuremath{\omega_{n}}\ensuremath{\ensuremath{\gg}1}}
\end{cases},\,\text{per }\xi\gtrless0
\]
\[
\arg\left[G_{z}\left(j\omega\right)\right]\simeq\begin{cases}
\arg\left(1\right)=0\text{°} & \text{per }\omega/\alpha_{n}\ll1\\
\arg\left(2j\left(\pm\zeta\right)\right)=\pm90{^\circ} & \text{per }\omega/\alpha_{n}=1\\
\arg\left(-\left(\omega/\alpha_{n}\right)^{2}\pm2\zeta\omega/\omega_{n}\right)=\pm180{^\circ} & \text{per \ensuremath{\omega}/\ensuremath{\alpha_{n}}\ensuremath{\ensuremath{\gg}1}}
\end{cases},\,\text{per }\zeta\gtrless0
\]

Il segno della parte reale di un polo è $-\xi\omega_{n}$: possiamo
vedere la fase di due poli complessi coniugati con $\xi>0$ come la
somma dei contributi di due poli reali negativi. Il ragionamento analogo
vale per gli zeri. In corrispondenza della pulsazione naturale delle
singolarità, l'andamento effettivo assume fase $\pm90{^\circ}$, in
generale comportandosi come un'arcotangente.

La curva effettiva si avvicina a quella asintotica mano a mano che
lo smorzamento si avvicina a zero; per smorzamento nullo l'andamento
effettivo presenta una discontinuità di salto, di $180{^\circ}$;
per smorzamento pari a $1$, si ha la somma di due poli reali coincidenti.

Per convenzione si prende per i poli immaginari puri un salto di $-180{^\circ}$,
e per gli zeri immaginari puri un salto di $+180{^\circ}$.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-12 Bode fase complessi poli neg (zeri pos)\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase per poli complessi coniugati negativi (e zeri positivi)}\label{fig:Bode-fase-complessi-poli-neg-zeri-pos}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-13 Bode fase complessi poli pos (zeri neg)\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase per poli complessi coniugati positivi (e zeri negativi)}\label{fig:Bode-fase-complessi-poli-pos-zeri-neg}%
\end{minipage}

\subsection*{Tracciamento del diagramma della fase}

Possiamo tracciare il diagramma di Bode della fase di una funzione
di trasferimento in due modi: il primo consiste nell'isolare guadagno
statico e singolarità nell'origine, tracciando i diagrammi della fase
di ciascuna singolarità e poi sommandoli assieme per ciascuna pulsazione;
anche se immediato, esso diventa sconveniente per funzioni con molte
singolarità.

Il secondo approccio consiste nei seguenti passi:
\begin{itemize}
\item Si parte da una pulsazione molto piccola, tale che sia possibile trascurare
tutte le singolarità al di fuori dell'origine; per $\omega\rightarrow0$
il contributo di fase iniziale vale
\[
\arg\left(\mu_{0}\right)+90{^\circ}\cdot g
\]
ovvero la fase iniziale è determinata dal segno del guadagno statico
e dal tipo del sistema.
\item Si procede facendo tendere $\omega$ a $\infty$, visitando la pulsazione
di ciascuna singolarità; per ogni polo o zero reale si somma $\mp90{^\circ}$
e per ogni coppia di poli o zeri complessi coniugati si somma $\pm180{^\circ}$,
a seconda del segno della parte reale.
\end{itemize}
\begin{example}
\emph{In riferimento all'Esempio \ref{exa:Esempio-bode-modulo-somma-grafici},
$\checkmark$tracciare il diagramma della fase della risposta armonica
del sistema.}

Riportiamo la funzione di trasferimento, e alcuni dati utili:
\[
G\left(s\right)=\frac{10\left(1-s\right)\left(1+10s\right)}{s\left(1+0.1s\right)\left(1-\frac{s}{300}+\frac{s^{2}}{90000}\right)}
\]
\[
\mu=10,\,g=1,\,z_{1}=1,\,z_{2}=-0.1,\,p_{1}=-10,\,p_{2,3}=\left\{ \omega=300,\,\xi=-1/2\right\} 
\]

Il contenuto di fase iniziale è determinato dal segno positivo del
guadagno statico: si avrà un contributo $0{^\circ}$; inoltre il polo
nell'origine ($g=1$) aggiunge un ulteriore contributo iniziale di
$-90{^\circ}$.

Per $\omega$ crescente incontreremo tutte le singolarità in ordine
crescente di pulsazione:
\end{example}
\begin{itemize}
\item lo zero $z_{2}$ reale negativo, che comporta un guadagno di fase
di $+90{^\circ}$ (vedi \figref{Bode-fase-poli-pos-zeri-neg});
\item lo zero $z_{1}$ reale positivo, che comporta una perdita di fase
di $-90{^\circ}$ (vedi \figref{Bode-fase-poli-neg-zeri-pos});
\item il polo $p_{1}$ reale negativo, che comporta una perdita di fase
di $-90{^\circ}$ (vedi \figref{Bode-fase-poli-neg-zeri-pos});
\item i poli $p_{2,3}$ complessi coniugati, con parte reale positiva, che
comportano un guadagno di fase di $+180{^\circ}$ (vedi \figref{Bode-fase-complessi-poli-pos-zeri-neg}).
\end{itemize}
\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_3-14 Bode fase esercizio 4\string".pdf}
\par\end{centering}
\caption{Diagramma della fase della funzione per l'esempio}
\end{figure}
\demo

\section{\label{sec:Bode-ritardo}Diagrammi di Bode del ritardo di tempo}

Prendiamo un ritardo di tempo positivo $\tau>0$, e una funzione di
trasferimento nella forma della risposta armonica, espressa come esponenziale
$G\left(s\right)=e^{-\tau s}$:
\[
G\left(j\omega\right)=e^{-\tau j\omega}
\]
Il modulo e la fase di questa espressione valgono:
\[
\left|G\left(j\omega\right)\right|=1,\quad\arg\left(G\left(j\omega\right)\right)=-\tau\omega
\]
I diagrammi del modulo e della fase del ritardo risultano:
\begin{itemize}
\item Il diagramma del modulo costante, di valore 0; esso non influenzerà
il modulo della funzione ritardata.
\item Il diagramma della fase un esponenziale divergente a $-\infty$; esso
passerà per il punto $\omega=\frac{1}{\tau},\,\arg\left(\circ\right)=-\frac{180{^\circ}}{\pi}$.
\end{itemize}
Lo sfasamento causato dal ritardo è lineare, tuttavia sul diagramma
di Bode (dotato di scala logaritmica), esso appare come una esponenziale.

Il ritardo è tanto più influente sulla risposta armonica di un sistema
quanto più le frequenze su cui agisce sono elevate, rispetto al valore
del tempo di ritardo $\tau$ (per un valore molto piccolo di ritardo,
solo frequenze elevate della risposta armonica saranno influenzate).\pagebreak{}

\section{Diagramma polare\label{sec:Diagramma-polare}}

\subsection{Definizione}

Il diagramma sul piano complesso del modulo e della fase ricavati
dai diagrammi di Bode della risposta armonica si chiama diagramma
polare; esso rappresenta l'andamento di $G\left(j\omega\right)$ per
$\omega\rightarrow+\infty$, con dominio il semiasse immaginario positivo.
La curva ottenuta è l'immagine della funzione di risposta armonica,
in funzione della fase.

Possiamo tracciare questi diagrammi analizzando i diagrammi di Bode
del modulo e della fase corrispondente, in modo qualitativo; a seguire
degli esempi per mostrare questo concetto.
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{5}{\left(1+\frac{s}{50}\right)}
\]
$\checkmark$Tracciare il diagramma polare della sua risposta armonica.}

Identifichiamo una funzione scritta già nella forma fattorizzata;
il suo guadagno statico vale $\mu=5$, mentre il suo unico polo reale
si trova in $p_{1}=-50$; tracciamo i diagrammi di Bode della risposta
armonica associata:

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_4-1 Bode modulo esempio 1\string".pdf}
\par\end{center}%
\end{minipage}
\end{example}
\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_4-2 Bode fase esempio 1\string".pdf}
\par\end{center}%
\end{minipage}

\bigskip{}

Nel diagramma del modulo abbiamo usato il valore del guadagno statico
in decibel ($\mu|_{{\scriptscriptstyle dB}}=14\,\text{dB}$); i diagrammi
di Bode si ottengono immediatamente, facendo riferimento ai diagrammi
della sezione precedente, associati a un polo reale negativo.

Per $\omega$ che si muove da $0$ a $+\infty$, seguiamo l'andamento
del modulo e della fase sui due diagrammi appena tracciati, ottenendo
la seguente curva complessa che rappresenta il diagramma polare:

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=1.1]{\string"Illustrazioni/5_4-3 Polare esempio 1\string".pdf}
\par\end{center}%
\end{minipage}\bigskip{}

Per $\omega\ll1$ la fase vale $0{^\circ}$ e il modulo $14\,\text{dB}\simeq5$;
il modulo rimane entro $14\,\text{db}$ fino a che $\omega=50\,\text{rad}$;
la fase vale $-45{^\circ}$ e il modulo decresce a $14\,\text{dB}-3\,\text{dB}\simeq5/\sqrt{2}$.
asintoticamente il modulo tende ad annullarsi (in $-\infty\,\text{dB}$),
dunque la curva si avvicinerà all'origine con pendenza asintotica
determinata dal valore finale della fase ($-90{^\circ}$).\demo
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=-\frac{5}{s}\cdot\frac{\left(s+1\right)}{\left(1+\frac{s}{100}\right)}
\]
$\checkmark$Tracciare il diagramma polare della sua risposta armonica.}

Notiamo la presenza di un polo nell'origine ($g=1$), e per il teorema
del valore iniziale (\ref{eq:Teorema-valore-iniziale}) il guadagno
statico vale $\left|\mu\right|=5=14\,\text{dB}$; le singolarità si
trovano, in $z_{1}=-1$ e $p_{1}=-100$:

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_4-4 Bode modulo esempio 2\string".pdf}
\par\end{center}%
\end{minipage}
\end{example}
\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_4-5 Bode fase esempio 2\string".pdf}
\par\end{center}%
\end{minipage}

Per $\omega\rightarrow0$ il modulo tende a $+\infty$, dato il polo
nell'origine ($g>0$); si parte dall'infinito sul semiasse immaginario
positivo (data la fase asintotica di $-270{^\circ}$). C'è un intervallo
di valori in cui la fase si avvicina a $-180{^\circ}$ mentre il modulo
tende a 5 ($14\,\text{dB}$), dopodiché il modulo tende ad 0 e la
fase ritorna a $-270{^\circ}$.

Tracceremo infine il seguente diagramma polare:

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.9]{\string"Illustrazioni/5_4-6 Polare esempio 2\string".pdf}
\par\end{center}%
\end{minipage}\pagebreak{}

\subsection{Diagramma polare del ritardo}

Mostriamo la forma del diagramma polare del ritardo con il seguente
esempio.
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{20}{1+s}e^{-s}
\]
$\checkmark$Tracciare il diagramma polare della risposta armonica
associata.}

Individuiamo il guadagno statico $\mu=20$ e il tipo $g=0$; abbiamo
un polo reale negativo in $p_{1}=-1$, e un ritardo $\tau=1\,\text{rad}$
(ricavato osservando l'esponente della funzione esponenziale).

Per ottenere i diagrammi di Bode, basta adottare le considerazioni
già fatte ne \secref{Bode-ritardo}, sommando i diagrammi del ritardo
a quelli della risposta armonica; il diagramma del modulo non sarà
alterato, mentre il diagramma della fase avrà un contributo aggiuntivo
di $-\omega$ fornito dal ritardo di tempo per $\tau=1$.

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_5-1 Bode modulo esempio 3\string".pdf}
\par\end{center}%
\end{minipage}
\end{example}
\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_5-2 Bode fase esempio 3\string".pdf}
\par\end{center}%
\end{minipage}\bigskip{}

Se avessimo solo il polo, la fase iniziale sarebbe $0{^\circ}$ ($\mu>0$)
ed esso tenderebbe a $-90{^\circ}$ come un'arcotangente, con argomento
pari a $-45{^\circ}$ per $\omega=1$; tuttavia il ritardo somma un
ulteriore contributo di $-1\,\text{rad}\simeq-57.3{^\circ}$, dunque
la fase effettiva in $\omega=1$ è pari a $-102.3{^\circ}$, con andamento
esponenziale (dovuto al contributo del ritardo).

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.25]{\string"Illustrazioni/5_5-3 Polare esempio 3\string".pdf}
\par\end{center}%
\end{minipage}\bigskip{}


\section{\label{sec:Sistemi-a-sfasamento-minimo}Sistemi a sfasamento minimo}

Supponiamo di avere il diagramma di Bode del modulo di una risposta
armonica: è possibile tracciare il diagramma della fase?

In generale la risposta è negativa, dal momento che il segno del guadagno
e delle singolarità non può essere dedotto dal diagramma modulo; se
abbiamo tuttavia un \emph{sistema a smorzamento minimo}, possiamo
tracciarne con certezza il diagramma della fase conoscendo quello
del modulo:
\begin{defn}
Chiamiamo a smorzamento minimo un sistema in cui il guadagno è positivo,
e tutte le singolarità hanno parte reale positiva.
\end{defn}
Analizziamo il seguente esempio per chiarire questo concetto:
\begin{example}
\emph{Sia dato il seguente diagramma di Bode del modulo:}

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_6-1 Bode modulo esempio 4\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo}%
\end{minipage}

\emph{$\checkmark$Tracciare il diagramma di Bode della fase della
stessa funzione, sapendo che il sistema è a smorzamento minimo.}

Assumiamo che il guadagno sia pari a 1 (se fosse diversamente, il
grafico del modulo avrebbe una traslazione verticale pari al guadagno);
isoliamo i punti in cui il diagramma asintotico si spezza: essi saranno
in corrispondenza delle singolarità (già indicate sul bordo inferiore
del grafico).

La pendenza iniziale di $-40\,\text{dB}$ denota la presenza di ben
2 zeri nell'origine (vedi \figref{Bode-modulo-singolarit=0000E0-origine}),
i quali determinano una fase iniziale di $+180{^\circ}$; si procede
in questo modo, cambiando la fase ogni volta che si incontra un punto
in cui sono presenti delle singolarità (la cui natura è determinata
osservando come varia la pendenza del diagramma asintotico del modulo).
Il grafico risultante per la fase è il seguente:
\end{example}
\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_6-2 Bode fase esempio 4\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase}%
\end{minipage}\demo\bigskip{}


\section{Azione filtrante dei sistemi dinamici}

Abbiamo visto che un sistema dinamico LTI, tramite la sua funzione
di risposta armonica associata all'uscita, applica una variazione
su modulo e fase di ogni componente spettrale in ingresso; possiamo
immaginare un processo in cui abbiamo un segnale continuo, iniettato
in un sistema dinamico LTI con funzione di trasferimento $G\left(s\right)$.
Si avrà un certo segnale di uscita, il cui spettro sarà alterato dalla
risposta armonica.

In uscita si avrà lo spettro del modulo delle ampiezze del segnale
entrante, pesate per il modulo della risposta armonica alla corrispondente
pulsazione, e ogni componente della fase sarà sfasata dell'argomento
della risposta armonica alla corrispondente pulsazione.

Questa azione di alterazione dello spettro, da parte dei sistemi dinamici,
viene definita \emph{azione filtrante} del sistema; analizzeremo in
questa sezione dei modelli rilevanti di filtro.

\subsection{Filtro passa-basso}

Si tratta di un sistema che tende ad annullare le componenti spettrali
superiori a una certa pulsazione; un filtro ideale di questo tipo
ha diagramma di Bode del modulo nullo fino a una certa pulsazione
$\overline{\omega}$, poi esso vale $-\infty$ per qualsiasi altra
pulsazione; la fase di un filtro ideale è $0{^\circ}$.

Nella pratica non è possibile realizzare una variazione istantanea
del modulo, tuttavia possiamo utilizzare un sistema con un singolo
polo reale negativo, con la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{1}{1+\left(\frac{s}{\overline{\omega}}\right)}
\]
Per $\mu=1$, $\overline{\omega}>0$, il polo si troverà in $s=-\overline{\omega}$
e l'andamento del modulo sarà nullo fino al polo, poi decrescente
con pendenza $-20\,\text{dB}/\text{dec}$; questa è un'approssimazione
del I ordine di un filtro passa-basso ideale. Mostriamo un esempio
di sistema fisico dotato di questa funzione di trasferimento.

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.9]{\string"Illustrazioni/5_7-1 Circuito RC passa-basso\string".pdf}
\par\end{center}
\captionof{figure}{Circuito RC come filtro passa-basso}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{example}
\emph{Sia dato il seguente circuito, nel quale l'ingresso è la tensione
a vuoto $u\left(t\right)$ ai capi della serie del resistore $R$
e del condensatore $C$; l'uscita è la tensione sul condensatore,
$y\left(t\right)$. $\checkmark$Scrivere la funzione di trasferimento
del sistema.}
\end{example}
%
\end{minipage}

La tensione ai capi della capacità dipende dalla corrente che vi scorre,
secondo la legge:
\[
\dot{y}\left(t\right)=i\left(t\right)/C
\]
A sua volta la corrente nel circuito può essere ottenuta dalla legge
di Ohm sul resistore:
\[
i\left(t\right)=\frac{1}{R}\left(u\left(t\right)-y\left(t\right)\right)
\]
Possiamo sostituire nell'espressione della tensione sul condensatore,
ottenendo:
\[
\dot{y}\left(t\right)=\frac{1}{RC}\left(u\left(t\right)-y\left(t\right)\right)
\]
Trasformiamo questa espressione di uscita nel dominio di Laplace:
\[
\mathscr{L}\left[\dot{y}\left(t\right)\right]=\frac{U\left(s\right)}{RC}-\frac{Y\left(s\right)}{RC}=sY\left(s\right)
\]
Usando (\ref{eq:Uscita-trasferimento-Laplace}) raccogliamo $Y\left(s\right)/U\left(s\right)$
per scrivere la funzione di trasferimento:
\[
G\left(s\right)=\frac{1/RC}{\left(1/RC+s\right)}
\]
Il guadagno stazionario vale $\mu=1$ e si ha un polo in $s=-1/RC$.\demo\bigskip{}

In un filtro reale possiamo individuare l'intervallo di pulsazioni
che passano attraverso il filtro, sotto la seguente definizione.
\begin{defn}
Chiamiamo \emph{banda passante} di un filtro \emph{passa-basso} reale
un intervallo di pulsazioni entro il quale il modulo dista $\pm3\,\text{dB}$
dal valore statico; in modo analitico deve valere:
\[
-3\,\text{dB}\simeq\frac{1}{\sqrt{2}}\leq\frac{\left|G\left(j\omega\right)\right|}{\left|G\left(0\right)\right|}\leq\sqrt{2}\simeq+3\,\text{dB}
\]
ovvero $\omega\in\left(-\infty,\,\overline{\omega}\right]$.
\end{defn}

\subsection{Filtro passa-alto}

Al contrario del sistema appena analizzato, un filtro passa-alto si
comporta in maniera duale, attenuando le componenti spettrali di bassa
frequenza lasciando inalterate quelle maggiori di una certa frequenza
$\underline{\omega}$; il suo diagramma del modulo avrà un andamento
pari a $-\infty\,\text{dB}$ per $\omega<\underline{\omega}$ e $0\,\text{dB}$
per $\omega\geq\underline{\omega}$.

Nella pratica non esistono filtri ideali con questo andamento asintotico,
tuttavia si può approssimare al I ordine con un sistema dinamico dotato
di uno zero nell'origine e un polo reale negativo.
\begin{defn}
Chiamiamo \emph{banda passante} di un filtro \emph{passa-alto} reale
un intervallo di pulsazioni entro il quale il modulo dista $\pm3\,\text{dB}$
dal valore finale; in modo analitico deve valere:
\[
-3\,\text{dB}\simeq\frac{1}{\sqrt{2}}\leq\frac{\left|G\left(j\omega\right)\right|}{\left|G\left(\infty\right)\right|}\leq\sqrt{2}\simeq+3\,\text{dB}
\]
ovvero $\omega\in\left[\underline{\omega},\,+\infty\right)$.
\end{defn}
\begin{minipage}[c]{0.5\textwidth}%
\begin{example}
\emph{Sia dato il seguente circuito, nel quale l'ingresso è la tensione
a vuoto $u\left(t\right)$ ai capi della serie del resistore $R$
e del condensatore $C$; l'uscita è la tensione sul resistore, $y\left(t\right)$.
$\checkmark$Scrivere la funzione di trasferimento del sistema.}
\end{example}
%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.9]{\string"Illustrazioni/5_7-2 Circuito RC passa-alto\string".pdf}
\par\end{center}
\captionof{figure}{Circuito RC come filtro passa-alto}%
\end{minipage}

Scegliamo la tensione sul condensatore come stato $x_{{\scriptscriptstyle \text{C}}}\left(t\right)=u\left(t\right)-y\left(t\right)$;
la sua derivata vale:
\[
\dot{x}_{{\scriptscriptstyle \text{C}}}\left(t\right)=y\left(t\right)/RC
\]
che può anche essere scritta come
\[
\dot{u}\left(t\right)-\dot{y}\left(t\right)=y\left(t\right)/RC
\]
Trasformiamo questa espressione di uscita:
\[
\overset{{\scriptstyle \mathscr{L}}}{\rightarrow}sU\left(s\right)-sY\left(s\right)=Y\left(s\right)/RC
\]
\[
G\left(s\right)=\frac{Y\left(s\right)}{U\left(s\right)}=\frac{s}{\left(s+1/RC\right)}
\]
L'estremo inferiore della banda passante in questo caso è la posizione
del polo ($s=-1/RC$); per filtrare frequenze elevate è possibile
scegliere valori piccoli di resistenza e capacità.\demo\bigskip{}


\subsection{Filtro passa-banda}

Questo\marginpar{Per esempio, il nostro apparato uditivo è un filtro passa-banda tra
$20\,\text{Hz}$ e $20\,k\text{Hz}$} sistema lascia inalterate le componenti spettrali del segnale di
ingresso entro una determinata banda di frequenza; esso si comporterà
come un filtro passa alto, attenuando il segnale a pulsazioni inferiori
di $\underline{\omega}$, e come un filtro passa-basso, attenuando
il segnale a pulsazioni superiori di $\overline{\omega}$.
\begin{defn}
Chiamiamo \emph{banda passante} di un filtro \emph{passa-banda} reale
un intervallo di pulsazioni entro il quale il modulo dista $\pm3\,\text{dB}$
dal valore finale; in modo analitico deve valere $\omega\in\left[\underline{\omega},\,\overline{\omega}\right]$.
\end{defn}

\section{Trasferimento per approssimazione a poli dominanti}

Osserviamo come un'approssimazione al polo dominante influenza i diagrammi
di Bode della risposta armonica, attraverso il seguente esempio.
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{10\left(1+s\right)}{\left(1+\frac{s}{10}\right)\left(1+\frac{s}{0.1}\right)}
\]
$\checkmark$Approssimare la funzione al polo dominante, e tracciare
i diagrammi di Bode della risposta armonica.}

Identifichiamo il guadagno statico $\mu=10\simeq20\,\text{dB}$ e
le singolarità in posizione:
\[
z_{1}=-1,\,p_{1}=-0.1,\,p_{2}=-10
\]
La singolarità con maggiore costante di tempo è quella associata al
polo $p_{2}$; approssimiamo al I ordine la funzione di trasferimento
nel modo seguente:
\[
G\left(s\right)\sim\hat{G}\left(s\right)=\frac{10}{\left(1+\frac{s}{0.1}\right)}
\]
Il diagramma approssimato è tracciato con una linea spessa, mentre
il diagramma effettivo con una linea tratteggiata (non sono raffigurati
gli andamenti asintotici):
\end{example}
\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_8-1 Bode modulo esempio\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo}%
\end{minipage}

\begin{minipage}[c]{1\textwidth}%
\begin{center}
\includegraphics[scale=0.8]{\string"Illustrazioni/5_8-2 Bode fase esempio\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma della fase}%
\end{minipage}

\demo

\chapter{Analisi dei sistemi di controllo}

Richiamiamo di problema di controllo (vedi \subsecref{Problemi-di-controllo}):
abbiamo un processo, che consiste in un aspetto fisico di un oggetto
di interesse, e un suo andamento desiderato; l'insieme di questi due
elementi definisce il problema di controllo.

Il sistema è caratterizzato da un blocco con variabili manipolabili
e disturbi (non manipolabili) in ingresso, e variabili controllate
in uscita (queste ultime traducono in una grandezza misurabile il
funzionamento desiderato).

Risolvere un problema di controllo significa progettare un \emph{regolatore},
ovvero un'altro sistema dinamico che decide quale altro ingresso fornire
al processo per ottenere l'andamento desiderato $w\left(t\right)$.

Un sistema di controllo è dunque l'insieme di regolatore e processo
controllato.

\section{Architetture di sistemi di controllo}

Vi sono due principali architetture dei sistemi di controllo, classificate
in base al fatto che il regolatore sfrutti o meno una stima della
variabile $y\left(t\right)$; in entrambi i casi analizzeremo sistemi
LTI, per i quali vedremo tecniche di progetto model-based, ovvero
useremo un modello per il comportamento del sistema (equazioni della
Fisica, dati sperimentali, ecc$\ldots$).

\subsection{Anello aperto}

I sistemi di controllo in anello aperto sono caratterizzati dal regolatore
che riceve l'andamento desiderato, e in base alla logica di progettazione
definisce l'ingresso da dare al sistema senza conoscere l'andamento
effettivo dell'uscita.

Analizziamo il regolatore nel modo seguente: supponiamo che sia data
una inversione di un processo $P$, definita come
\[
P^{-1}\left(y\left(t\right)\right)=u\left(t\right)
\]
Vorremmo allora la funzione dell'andamento desiderato espressa come
$F^{*}\left(w\left(t\right)\right)=y\left(t\right)$ che indica il
comportamento desiderato; allora un metodo di progettazione consiste
nel scrivere la funzione del regolatore rispetto all'andamento desiderato:
\[
R\left(w\left(t\right)\right)=u\left(t\right)=P^{-1}\left(F^{*}\left(w\left(t\right)\right)\right)
\]
da cui riscriviamo $y\left(t\right)$ come:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Trasferimento in anello aperto}{\footnotesize{}\index{Anello aperto, trasferimento@{\footnotesize{}Anello aperto, trasferimento}}}}[0.2cm]
\begin{equation}
y\left(t\right)=P\left(u\left(t\right)\right)=P\left(P^{-1}\left(F^{*}\left(w\left(t\right)\right)\right)\right)=F^{*}\left(w\left(t\right)\right)\label{eq:Trasferimento-anello-aperto}
\end{equation}

\begin{defn}
Abbiamo mostrato un tipico approccio di \emph{inversione dinamica},
ovvero partendo da un modello $P$ del processo, se possiamo calcolarne
un'inversione $P^{-1}$ tale che $P\left(P^{-1}\left(\square\right)\right)$
restituisca l'argomento $\square$ dell'inversione, allora è lecito
utilizzare $P^{-1}$ come regolatore in anello \uline{aperto}.
\end{defn}
In generale i sistemi sono non lineari e multi-variabili, ma in molti
casi si può semplificare con una linearizzazione (attorno al punto
di funzionamento del sistema) il sistema del problema di controllo
per ottenerne uno SISO.

Dopo aver scomposto il problema di controllo in più problemi SISO,
è possibile esprimere il processo con una funzione di trasferimento
$G\left(s\right)$ che indica il rapporto tra uscita e ingresso; se
il processo è asintoticamente stabile e non presenta zeri a parte
reale positiva, possiamo calcolare la sua inversione come $G^{-1}\left(s\right)$
e usarla nel regolatore per cancellare la dinamica del sistema e sostituirla
col comportamento desiderato $F^{*}\left(s\right)$:
\begin{equation}
R\left(s\right)=G^{-1}\left(s\right)\cdot F^{*}\left(s\right)\label{eq:Regolatore-anello-aperto}
\end{equation}
Mettendo in cascata questa funzione col sistema, si ottiene esattamente
un sistema equivalente per cui il comportamento tra $w\left(t\right)$
e $y\left(t\right)$ è esattamente $F^{*}\left(s\right)$.
\begin{rem}
È richiesto che la funzione (\ref{eq:Regolatore-anello-aperto}) così
ottenuta sia strettamente propria.

Lo svantaggio del controllo in anello aperto è dato dallo scostamento
della realtà fisica dal modello su cui è progettata la logica del
regolatore: esso non può reagire a casi imprevisti.

Possiamo notare questo limite dalle equazioni, aggiungendo un margine
di correttezza di modello $\Delta\left(s\right)$; lo schema a blocchi
è indicato ne \figref{Problema-di-controllo-anello-aperto}.

\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=1.2]{\string"Illustrazioni/6_1-1 Controllo in anello aperto\string".pdf}
\par\end{centering}
\caption{Problema di controllo in anello aperto}
\label{fig:Problema-di-controllo-anello-aperto}
\end{figure}

Se applichiamo il regolatore (\ref{eq:Regolatore-anello-aperto}),
otteniamo la seguente equazione di uscita:
\[
y\left(t\right)=W\left(s\right)\cdot\left[G^{-1}\left(s\right)F^{*}\left(s\right)G\left(s\right)\right]+W\left(s\right)\cdot\left[G^{-1}\left(s\right)F^{*}\left(s\right)\right]\cdot\Delta\left(s\right)+D\left(s\right)
\]
Notiamo che l'incertezza è moltiplicata per la funzione del regolatore,
dunque è possibile attenuare in parte il suo effetto; tuttavia ciò
non può essere fatto senza commettere un errore di approssimazione,
inoltre l'effetto del disturbo influenza interamente l'uscita, senza
che possa essere attenuato in qualche modo.
\end{rem}

\subsection{Anello chiuso}

I sistemi di controllo in anello chiuso sono caratterizzati dal\marginpar{Dato il basso costo de sensori accurati, e i vantaggi di questa architettura,
oggi quasi tutti i sistemi di controllo sono in anello chiuso} regolatore che preleva l'informazione sull'andamento dell'uscita
e la sfrutta per determinare l'ingresso.

Il regolatore in questo caso esprime l'ingresso controllato come $u\left(t\right)=R\left(w\left(t\right),\,y\left(t\right)\right)$:
si hanno a disposizione dei sensori (uno degli svantaggi è il doverli
predisporre) che informano il regolatore sull'andamento dell'uscita;
il regolatore non riceve direttamente in ingresso il valore dell'andamento
desiderato ma si tratta di una retroazione negativa, in cui al regolatore
arriva la differenza $e\left(t\right)=w\left(t\right)-y\left(t\right)$
chiamata \emph{errore di inseguimento}.

\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=1.2]{\string"Illustrazioni/6_1-2 Controllo in anello chiuso\string".pdf}
\par\end{centering}
\caption{Problema di controllo in anello chiuso}
\label{fig:Problema-di-controllo-anello-chiuso}
\end{figure}

Scriviamo la funzione di trasferimento risultante dallo schema a blocchi
(vedi \figref{Problema-di-controllo-anello-chiuso}):
\[
Y\left(s\right)=\frac{R\left(s\right)\cdot\left(G\left(s\right)\Delta\left(s\right)\right)}{1+R\left(s\right)\cdot\left(G\left(s\right)\Delta\left(s\right)\right)}W\left(s\right)+\frac{1}{1+R\left(s\right)\cdot\left(G\left(s\right)\Delta\left(s\right)\right)}D\left(s\right)
\]
Osserviamo che il regolatore ha un primo vantaggio rispetto al caso
dell'anello aperto, infatti può avere un effetto sui disturbi dell'uscita,
e la funzione di trasferimento del valore desiderato è disaccoppiata
da quella del disturbo (possiamo agire su entrambe indipendentemente).

Se trascuriamo momentaneamente l'incertezza di modello $\Delta\left(s\right)$,
e definiamo la funzione di trasferimento di anello (\ref{eq:Funzione-trasferimento-di-anello})
come $L\left(s\right)=R\left(s\right)G\left(s\right)$, possiamo scrivere
l'uscita come:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Trasferimento in anello chiuso}{\footnotesize{}\index{Anello chiuso, trasferimento@{\footnotesize{}Anello chiuso, trasferimento}}}}[1cm]
\begin{equation}
Y\left(s\right)=\overset{{\scriptstyle F\left(s\right)}}{\overbrace{\frac{L\left(s\right)}{1+L\left(s\right)}}}W\left(s\right)+\overset{{\scriptstyle S\left(s\right)}}{\overbrace{\frac{1}{1+L\left(s\right)}}}D\left(s\right)\label{eq:Trasferimento-anello-chiuso}
\end{equation}
Le funzioni che abbiamo rinominato rispetto al trasferimento di anello
sono definite in modo particolare:
\begin{itemize}
\item $S\left(s\right)$ è la funzione di \emph{sensitività} dell'uscita,
che contiene l'informazione sulla sensitività dell'uscita al disturbo;
nel progetto di sistemi di controllo si preferisce mantenere piccola
questa funzione.
\item $F\left(s\right)$ è la funzione di \emph{sensitività complementare},
dato che $F\left(s\right)+S\left(s\right)=1$; idealmente cerchiamo
di ottenere questa funzione il più vicino possibile a 1.
\end{itemize}
Nella pratica si realizzano queste due funzioni in modo che $F\left(s\right)$
si comporti come un filtro passa-basso, e la funzione $S\left(s\right)$
come un filtro passa-alto; infine, un sistema di controllo in anello
chiuso ha un secondo vantaggio, ovvero è possibile alterare la pulsazione
dei poli della funzione di trasferimento, in particolare tramite il
regolatore è possibile stabilizzare un sistema altrimenti instabile
in anello aperto.
\begin{example}
\emph{Sia data la seguente funzione di trasferimento:
\[
G\left(s\right)=\frac{2}{1-s}
\]
appartenente al sistema di un problema di controllo in anello chiuso,
nel quale utilizziamo un regolatore costante pari a $R\left(s\right)=-10$.
$\checkmark$Calcolare le funzioni di sensitività e di sensitività
inversa.}
\end{example}
Calcoliamo il valore di $L\left(s\right)=R\left(s\right)\cdot G\left(s\right)=-20/\left(1-s\right)$;
le due funzioni di sensitività sono dunque pari a:
\[
F\left(s\right)=\frac{L\left(s\right)}{1+L\left(s\right)}=\frac{20}{s+19}=\frac{20}{19}\cdot\frac{1}{1+\nicefrac{s}{19}}
\]
\[
S\left(s\right)=1-F\left(s\right)=\frac{s+19-20}{s+19}=\frac{s-1}{s+19}=-\frac{1}{19}\cdot\frac{1-s}{1+\nicefrac{s}{19}}
\]
Notiamo che il polo del sistema in anello chiuso, dotato di regolatore,
si trova in $s=-19$, a differenza del polo instabile per $s=1$ della
funzione di trasferimento assegnata in partenza; inoltre si nota che
la funzione di sensitività complementare ($F\left(s\right)$) ha guadagno
circa unitario. Il modulo delle due funzioni sul diagramma di Bode
è ne \figref{Anello-chiuso-Bode-sensitivit=0000E0-esempio}.

La velocità di risposta del sistema (l'inverso del modulo del polo)
può essere determinata dimensionando opportunamente il guadagno del
regolatore.\demo

\begin{minipage}[c]{0.5\textwidth}%
\begin{center}
\includegraphics[scale=0.9]{\string"Illustrazioni/6_1-3 Bode modulo funzioni sensitività\string".pdf}
\par\end{center}
\captionof{figure}{Diagramma del modulo delle funzioni di sensitività}\label{fig:Anello-chiuso-Bode-sensitivit=0000E0-esempio}%
\end{minipage}%
\begin{minipage}[c]{0.5\textwidth}%
Vediamo uno schema di riferimento più realistico per lo studio dei
problemi di controllo in anello chiuso; il segnale $u\left(t\right)$
viene dato in ingresso a un attuatore (blocco indicato con $A\left(s\right)$),
che traduce un segnale elettrico in una interazione fisica; all'uscita
dell'attuatore si sommano dei disturbi di attuazione $d_{{\scriptscriptstyle \text{A}}}$
(tipicamente a bassa frequenza).%
\end{minipage}

In generale l'uscita è misurata tramite un trasduttore, che converte
una grandezza fisica in un segnale elettrico, sottoposto a disturbi
di misura $d_{{\scriptscriptstyle \text{T}}}$ (tipicamente ad alta
frequenza).

\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=1.2]{\string"Illustrazioni/6_1-4 Controllo in anello chiuso dettagliato\string".pdf}
\par\end{centering}
\caption{Schema a blocchi per problemi di controllo in retroazione}
\end{figure}

Con l'algebra degli schemi a blocchi, possiamo ricondurci a uno schema
semplificato:
\begin{itemize}
\item rimuoviamo\marginpar{Attenzione a non confondere il disturbo di processo $d$ (agisce sul
valore effettivo dell'uscita) e $n$ (viene visto solo dal regolatore),
quest'ultimo molto più critico} la funzione del trasduttore dall'anello di retroazione, poi moltiplicandola
per $R\left(s\right)$ e il suo inverso per $\tilde{w}\left(t\right)$; 
\item accorpiamo attuatore e impianto, spostando il nodo somma a valle dell'impianto
(al posto di $G\left(s\right)$);
\item chiamiamo $n$ la variabile del disturbo di misura;
\item ignoriamo il trasduttore, che si comporterà come un guadagno statico
(filtro passa basso con banda passante molto più grande di qualsiasi
pulsazione associata a singolarità);
\item accorpiamo tutti i disturbi additivi sull'uscita come disturbi di
processo $d\left(t\right)$.
\end{itemize}
Otteniamo lo schema in figura \ref{fig:Schema-di-riferimento-controllo},
che sarà il nostro riferimento per il progetto dei regolatori.
\begin{figure}[!h]
\begin{centering}
\includegraphics[scale=1.2]{\string"Illustrazioni/6_1-5 Riferimento controllo in anello chiuso\string".pdf}
\par\end{centering}
\caption{\label{fig:Schema-di-riferimento-controllo}Schema di riferimento
per problemi di controllo}
\end{figure}


\section{Progettazione e requisiti di un sistema di controllo}

\subsection{Progetto di un sistema di controllo}

In generale si compiono i seguenti passaggi preliminari alla progettazione
di un sistema di controllo:
\begin{enumerate}
\item Descrivere il problema di controllo, individuando le variabili di
interesse (ingressi, uscite, disturbi);
\item Ricavare le specifiche da ${\scriptstyle \left(1\right)}$, per raggiungere
il comportamento desiderato;
\item Formalizzare un modello a partire da ${\scriptstyle \left(1\right)}$
e ${\scriptstyle \left(2\right)}$ (esso dipende dalle specifiche
e rappresenta un'approssimazione del problema);
\item Progettare un regolatore a partire da ${\scriptstyle \left(3\right)}$,
che possa soddisfare ${\scriptstyle \left(2\right)}$ (problema di
\emph{sintesi}), oppure stabilire se un regolatore assegnato soddisfa
${\scriptstyle \left(2\right)}$ (problema di \emph{analisi}).
\end{enumerate}
Il risultato del progetto sarà una funzione di trasferimento $R\left(s\right)$,
che può essere discretizzata per essere implementata su un calcolatore.

\subsection{Requisiti di un sistema di controllo}
\begin{enumerate}
\item Stabilità asintotica;
\item Prestazioni statiche (riguardano il sistema una volta esauriti i transitori);
\item Prestazioni dinamiche (velocità di risposta).
\end{enumerate}
Per quanto riguarda la stabilità, un sistema si dice dotato di \emph{stabilità
nominale} quando la sua funzione di trasferimento corrisponde al comportamento
del sistema; è necessario inoltre garantire un certo \emph{margine
di stabilità}, per esempio prevedendo nell'anello di controllo casi
in cui il sistema si comporti diversamente dal modello, rientrando
comunque nelle specifiche (idealmente vorremmo un margine di stabilità
elevato).

Per quanto riguarda le prestazioni statiche, consideriamo il valore
finale dell'uscita al termine di tutti i transitori ($t>5T$, con
$T$ associata al polo dominante); consideriamo due tipologie di specifiche:
\begin{itemize}
\item \emph{Precisione di inseguimento} di riferimenti polinomiali (scalino,
rampa, parabola), ovvero è richiesto $e\left(t\right)\ll1$, si considera
inoltre la reiezione di disturbi polinomiali;
\item Comportamento a fronte di segnali sinusoidali, rispetto l'ampiezza
massima (da amplificare o attenuare) delle \emph{oscillazioni di $e\left(t\right)$}
a fronte di $w\left(t\right)$, $d\left(t\right)$ o $n\left(t\right)$;
\end{itemize}
Per quanto riguarda le prestazioni dinamiche, si fa riferimento alla
\emph{risposta allo scalino} $w\left(t\right)=A\cdot\text{sca}\left(t\right)$,
fissando dei valori limite di tempo di assestamento, tempo di salita
e sovraelongazione del movimento.

Per quanto riguarda le prestazioni - statiche o dinamiche - definiremo
delle \emph{prestazioni nominali}, legate all'ipotesi che il sistema
effettivo si comporti come il modello; in caso contrario si parla
di prestazioni robuste, rispetto allo scostamento del modello dalla
realtà.

\section{Criterio di Nyquist per l'asintotica stabilità}

Il criterio permette di capire se, dato un sistema in retroazione,
esso è stabile, osservando solo le proprietà del trasferimento di
anello aperto.

\subsection{Stabilità dei sistemi retro-azionati}

Consideriamo un sistema dotato di funzione di anello in retroazione
negativa e di errore di inseguimento (stiamo semplificando il modello
ne \figref{Schema-di-riferimento-controllo}). Poniamoci nel caso
di un sistema LTI, per il quale la stabilità è una proprietà strutturale:
supponiamo (d'ora in avanti) che nella funzione di trasferimento non
vi siano state cancellazioni, o al più esse sono state non critiche.

Sotto queste ipotesi, l'asintotica stabilità in anello chiuso si verifica
se e solo se i poli della funzione di trasferimento ($1/\left[1+L\left(s\right)\right]$)
hanno parte reale negativa; esprimendo la funzione come:
\[
L\left(s\right)=\frac{N\left(s\right)}{D\left(s\right)}=\frac{1}{1+\frac{N_{{\scriptscriptstyle \text{L}}}\left(s\right)}{D_{{\scriptscriptstyle \text{L}}}\left(s\right)}}=\frac{D_{{\scriptscriptstyle \text{L}}}\left(s\right)}{N_{{\scriptscriptstyle \text{L}}}\left(s\right)+D_{{\scriptscriptstyle \text{L}}}\left(s\right)}
\]
otteniamo i suoi poli come soluzione dell'equazione\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Equazione caratteristica}{\footnotesize{}\index{Equazione caratteristica@{\footnotesize{}Equazione caratteristica}}}}[0.2cm]
\begin{equation}
N_{{\scriptscriptstyle \text{L}}}\left(s\right)+D_{{\scriptscriptstyle \text{L}}}\left(s\right)=0\quad\left({\scriptstyle =\,1+L\left(s\right)}\right)\label{eq:Equazione-caratteristica-retroazione}
\end{equation}

Come già studiato (si veda \subsecref{Segno-degli-autovalori}) è
possibile determinare la stabilità asintotica studiando il segno di
(\ref{eq:Equazione-caratteristica-retroazione}), applicando per esempio
il criterio di Routh (\ref{thm:Criterio-di-Routh}); tuttavia esso
non è immediato da applicare per un sistema di ordine elevato e in
fase di progetto ogni modifica al trasferimento comporta il dover
applicare da capo il criterio.

Dal punto di vista della progettazione, esiste un criterio molto più
comodo e diretto (si tratta di un metodo grafico) chiamato \emph{criterio
di Nyquist}, che fornisce una condizione necessaria e sufficiente
per l'asintotica stabilità di un sistema in anello chiuso.

Per utilizzare il criterio è necessario tracciare prima il \emph{diagramma
di Nyquist}.

\subsection{Diagramma di Nyquist}

Si tratta di un diagramma strettamente legato al diagramma polare
(si veda \secref{Diagramma-polare}): esso è l'immagine, attraverso
la funzione di trasferimento $L\left(s\right)$, di un percorso chiuso
sul piano complesso. Il diagramma consiste in un percorso chiamato
cammino di Nyquist, il quale comprende la curva orientata formata
dal semiasse immaginario positivo, una chiusura (a semicerchio) verso
l'asse immaginario a $-\infty$, e infine il semiasse immaginario
negativo.

Se non vi sono singolarità nell'origine si ha anche $\omega=0$ nel
diagramma polare, altrimenti per singolarità sull'asse immaginario
(poli o zeri nell'origine oppure immaginari puri) il cammino vi passa
attorno con semicirconferenze di raggio infinitesimo.

Sostituendo alla variabile $s$ nella funzione di anello i punti del
cammino di Nyquist, si ottengono i corrispondenti punti sul diagramma
di Nyquist; dato che il cammino è chiuso, anche il diagramma di Nyquist
sarà sempre una curva chiusa (se si ha un tratto del diagramma aperto,
si tracciano a partire da esso tanti semicerchi da 180° pari al numero
di poli nell'origine).
\begin{rem}
Un tratto del diagramma di Nyquist corrisponde esattamente al diagramma
polare, in particolare il tratto immaginario positivo; in aggiunta,
vi è la chiusura all'infinito e il tratto per numeri immaginari puri
con parte reale negativa ($\omega<0$). Per quanto riguarda questo
ultimo tratto, esso è il simmetrico del primo tratto rispetto alla
parte immaginaria, ottenuto come
\[
\overset{{\scriptstyle \omega>0}}{\overbrace{L\left(j\omega\right)}}=\bigl(\overset{{\scriptstyle \omega<0}}{\overbrace{L\left(j\omega^{*}\right)}}\bigr)^{*}
\]
\end{rem}

\subsection{Criterio di Nyquist}

Gli autovalori del sistema in anello chiuso sono le soluzioni dell'equazione
(\ref{eq:Equazione-caratteristica-retroazione}), ovvero i valori
di $s$ tali che $L\left(s\right)=-1$; tale punto è chiamato \emph{punto
critico} sul diagramma di Nyquist.

Se chiamiamo $P$ il numero di poli con parte reale positiva della
funzione di trasferimento in anello aperto (corrispondono a modi divergenti),
e $N$ il numero di giri orientati che il diagramma di Nyquist compie
attorno al punto critico (hanno segno positivo se percorsi in senso
antiorario).

Inoltre diremo che $N$ non è ben definito se il diagramma passa per
il punto critico.
\begin{thm}
\label{thm:Criterio-di-Nyquist}\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Criterio di Nyquist}{\footnotesize{}\index{Criterio di Nyquist@{\footnotesize{}Criterio di Nyquist}}}}[-0.3cm]Una condizione necessaria e sufficiente per l'asintotica
stabilità di un sistema LTI in retroazione, è che $N$ sia ben definito
e valga $N=P$.
\end{thm}
\begin{rem}
Se $N$ non è ben definito allora il sistema in anello chiuso presenta
uno o più poli nell'origine. Se $N<P$, allora $P-N$ è il numero
di poli con parte reale positiva (instabili) in anello chiuso.
\end{rem}

\subsection{Applicazioni del criterio}

\subsubsection*{Sistemi con guadagno variabile}

Nell'anello di retroazione avremo un blocco $k$ con un guadagno statico
scalare e controllabile (possiamo considerarlo un rudimentale regolatore);
studiamo la stabilità al variare di $k$.

Variando il modulo di $k$, il diagramma di Nyquist viene dilatato
o compresso, mentre invertendo il segno di $k$ si ha un a traslazione
del diagramma di 180°. Un trucco grafico per ottenere un diagramma
qualitativo dilatato o compresso, consiste nel moltiplicare la scala
degli assi per lo stesso guadagno $k$.

Per studiare la stabilità con $k\in\mathbb{R}$, prendiamo il diagramma
di Nyquist con $k=1$ e consideriamo il punto critico mobile $-1/k$;
individuiamo sull'asse reale degli intervalli contraddistinti dal
numero di rotazioni compiute dal diagramma attorno al punto critico
mobile.

Dopo aver calcolato il numero di rotazioni $N_{k}$ per ciascun intervallo
e averlo confrontato con $P$, otteniamo i valori di $k$ associati
a ciascun intervallo passando al reciproco.

\subsubsection*{Prestazioni contro stabilità in retroazione}

Consideriamo un sistema di controllo come nel modello di figura \ref{fig:Schema-di-riferimento-controllo},
nel quale il regolatore sia un guadagno statico $k$; la funzione
di anello risulta $L\left(s\right)=k\cdot G\left(s\right)$, mentre
le funzioni di sensitività sono rispettivamente:
\[
F\left(s\right)=\frac{Y\left(s\right)}{w\left(s\right)}=\frac{k\cdot G\left(s\right)}{1+k\cdot G\left(s\right)}\overset{{\scriptscriptstyle k\rightarrow+\infty}}{\longrightarrow}1
\]
\[
S\left(s\right)=\frac{E\left(s\right)}{D\left(s\right)}=-\frac{1}{1+k\cdot G\left(s\right)}\overset{{\scriptscriptstyle k\rightarrow+\infty}}{\longrightarrow}0
\]
Idealmente vorremmo gli andamenti indicati per $k\rightarrow+\infty$,
ovvero che per un guadagno molto elevato il sistema abbia prestazioni
altrettanto elevate, essendo in grado di inseguire qualsiasi riferimento
e annullare ogni disturbo.

Applicando tuttavia il criterio di Nyquist, notiamo che a furia di
aumentare il guadagno (partiamo da una situazione di asintotica stabilità)
vi sarà un valore di $k$ per cui il diagramma di Nyquist passa per
il punto critico, rendendo il sistema instabile; per avere un aumento
di prestazioni bisogna spingere il sistema al limite della stabilità.

\subsection{Condizioni sufficienti per la stabilità asintotica}

Supponiamo che non vi siano poli instabili, con parte reale positiva
($P=0$):
\begin{enumerate}
\item Se vale $\left|L\left(j\omega\right)\right|<1\,\forall\omega\in\mathbb{R}$,
allora il diagramma di Nyquist è interamente contenuto nella circonferenza
di raggio unitario (non potrà incrociare o girare attorno al punto).
\item Se vale $\left|\arg\left(j\omega\right)\right|<\pi\,\forall\omega\in\mathbb{R}$,
il diagramma di Nyquist non passerà per il punto critico né girerà
mai attorno ad esso.
\end{enumerate}
Le precedenti ipotesi, verificandosi, determinano l'asintotica stabilità
del sistema, e si dimostrano usando il Teorema \ref{thm:Criterio-di-Nyquist}.

~

Prendiamo un sistema con ritardo di tempo $\tau>0$; nel dominio di
Laplace esso avrà un andamento con coefficiente $e^{-\tau s}$, la
cui corrispondente risposta armonica vale $e^{-\tau j\omega}$; il
ritardo di fase introdotto è pari a $\arg\left(e^{-\tau j\omega}\right)=-\tau\omega$.

Possiamo anche in questo caso sfruttare il criterio di Nyquist, e
le due ipotesi appena enunciate (tenendo conto dello sfasamento dovuto
al ritardo).

\section{Margini di stabilità}

Fino ad ora abbiamo considerato la stabilità di un sistema di controllo
nelle cosiddette \emph{condizioni nominali}, ovvero avendo nota con
certezza la funzione di trasferimento. Nella pratica vi è sempre un
grado di approssimazione nella costruzione dei modelli, e questo comporta
un grado di incertezza nella funzione di trasferimento.

\subsection{Margine di stabilità vettoriale}

Prendiamo il diagramma polare di una funzione di trasferimento; per
semplicità ci poniamo nel caso $P=0$, e cerchiamo eventuali tratti
del diagramma di Nyquist che girano attorno al punto critico.

Rispetto alla risposta in frequenza (nominale), l'andamento effettivo
sul diagramma polare si trova all'interno di una certa banda di incertezza
(centrata sull'andamento nominale); si hanno condizioni critiche quando
la banda di incertezza comprende il punto critico.
\begin{defn}
La distanza tra il punto $-1,\,j0$ e la curva $L\left(j\omega\right)$
si chiama margine di stabilità vettoriale e si indica con $\Delta n$;
questo valore determina la massima ampiezza che la banda di incertezza
può assumere.
\end{defn}
Per ciascuna pulsazione si ha il valore di incertezza $\Delta\left(j\omega\right)$,
il quale è rappresentato da un cerchio attorno a ciascun punto del
diagramma; il suo raggio non deve mai superare il valore di $\Delta n$.

\subsection{Margine di guadagno}

Immaginiamo di avere un diagramma di Nyquist nel quale esiste un valore
di $\omega$ per cui la fase valga $-180{^\circ}$, ovvero $L\left(j\omega\pi\right)$,
e indichiamo la fase di tale punto
\begin{equation}
\omega_{\pi}=\arg\left(L\left(j\omega\pi\right)\right)\label{eq:Margine-di-guadagno}
\end{equation}

\begin{defn}
Il valore di guadagno che, moltiplicato per la funzione di trasferimento,
fa sì che il punto $L\left(j\omega\pi\right)$ si sovrapponga al punto
critico si chiama \emph{margine di guadagno}; in generale possiamo
indicarlo come $k_{{\scriptscriptstyle \text{m}}}=1/L\left(j\omega\pi\right)$,
che sarebbe il modulo della distanza dal punto in $\omega_{\pi}$
al punto critico.
\end{defn}
Nel caso di una funzione di trasferimento la cui fase non raggiunge
mai i 180°, essa avrà margine di guadagno infinito.

\subsection{Margine di fase}

Prendiamo una funzione di trasferimento che abbia diagramma di Nyquist
che abbia un punto in comune con la circonferenza di raggio unitario;
chiamiamo la pulsazione di tale punto \emph{pulsazione critica}, definita
come:
\begin{equation}
\omega_{{\scriptscriptstyle \text{C}}}\coloneqq\left|L\left(j\omega_{{\scriptscriptstyle \text{C}}}\right)\right|=1\label{eq:Margine-di-fase}
\end{equation}

\begin{defn}
La distanza angolare dal punto in $\omega_{{\scriptscriptstyle \text{C}}}$
al punto critico si chiama \emph{margine di fase}; se chiamiamo la
fase della funzione di risposta armonica ruotata alla pulsazione critica
$\phi_{{\scriptscriptstyle \text{C}}}=\arg\left(L\left(j\omega_{{\scriptscriptstyle \text{C}}}\right)\right)$,
indichiamo il margine di fase come:
\[
\phi_{{\scriptscriptstyle \text{m}}}=180{^\circ}-\phi_{{\scriptscriptstyle \text{C}}}
\]
Se vale che $\left|L\left(j\omega\right)\right|<1\,\forall\omega\in\mathbb{R}$,
allora il margine di fase è infinito.
\end{defn}
In presenza di un ritardo di tempo, il margine di fase vale $\phi_{{\scriptscriptstyle \text{m}}}=180{^\circ}-\tau\omega_{{\scriptscriptstyle \text{C}}}$,
da cui si ricava che il massimo ritardo tollerabile (in radianti)
vale $\tau_{{\scriptscriptstyle \text{MAX}}}=\phi_{{\scriptscriptstyle \text{m}}}/\omega_{{\scriptscriptstyle \text{C}}}$.
Possiamo allora interpretare il margine di fase anche come il massimo
ritardo ammissibile prima di avere instabilità.

\subsection{Casi particolari}

Possiamo incontrare dei casi nei quali il margine di guadagno o di
fase è molto elevato, mentre l'altro è piccolo; allora è necessario
usare entrambi i criteri per discutere la stabilità di un sistema.
Si noti che esistono anche casi in cui, non ostante entrambi i margini
siano elevati, il sistema sia comunque al limite della stabilità (in
particolare nel caso di poli risonanti per piccole frequenze).

In presenza di più valori per i quali valgono le condizioni (\ref{eq:Margine-di-guadagno})
e/o (\ref{eq:Margine-di-fase}), dobbiamo scegliere il più critico
(quello che sul diagramma di Nyquist sia più prossimo al punto critico).

\section{Criterio di Bode}

Per applicare questo criterio è necessario verificare tre ipotesi
preliminari:
\begin{enumerate}
\item la funzione di trasferimento in anello aperto non abbia poli con parte
reale positiva ($P=0$);
\item il diagramma di Bode del modulo della risposta armonica, attraversi
una sola volta l'asse a $0\,\text{dB}$;
\item la funzione di trasferimento sia strettamente propria (per $\omega\rightarrow+\infty$
il modulo tende a zero).
\end{enumerate}
\begin{thm}
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Criterio di Bode}{\footnotesize{}\index{Criterio di Bode@{\footnotesize{}Criterio di Bode}}}}Una volta verificate le tre ipotesi precedenti, si può dire che un
sistema LTI in retroazione è asintoticamente stabile se e solo se:

\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item il guadagno statico è positivo ($\mu>0$);
\item il margine di fase è positivo ($\phi_{{\scriptscriptstyle \text{m}}}>0$).
\end{itemize}
%
\end{minipage}
\end{thm}
Questo criterio è un'applicazione in un caso semplificato del criterio
di Nyquist che ci solleva dal tracciare il diagramma di Nyquist.
\begin{cor}
Se il sistema è anche a sfasamento minimo (guadagno sempre positivo
e diagramma della fase ottenibile direttamente da quello del modulo,
si veda \secref{Sistemi-a-sfasamento-minimo}), esso è asintoticamente
stabile se la sua pendenza finale è maggiore di $-60\,\text{dB}/\text{dec}$.
\end{cor}

\appendix

\chapter{\label{chap:Richiami-di-Geometria}Richiami di Geometria e Algebra
Lineare}

\section{Matrici}

Richiamiamo le proprietà del prodotto nell'ambito delle matrici; siano
date due matrici quadrate di ordine $n$ chiamate $A,\,B\in\mathbb{R}^{n\times n}$
e uno scalare $\alpha$; siano inoltre $a_{i,\,j}$ e $b_{i,\,j}$
gli elementi alla riga $i$ e colonna $j$ delle rispettive matrici
(indicate con la maiuscola corrispondente).
\begin{defn}
Il \emph{prodotto per uno scalare} di una matrice, indicato con $\alpha\cdot A$,
è pari a
\[
A^{\prime}=\begin{bmatrix}\alpha\cdot a_{1,1} & \cdots & \alpha\cdot a_{1,n}\\
\vdots & \ddots & \vdots\\
\alpha\cdot a_{n,1} & \cdots & \alpha\cdot a_{n,n}
\end{bmatrix}
\]
dove $a'_{i,\,j}=\alpha\cdot a_{i,\,j}$; il prodotto per uno scalare
gode delle stesse proprietà del prodotto tra due scalari.
\end{defn}
%
\begin{defn}
Prese $A\in\mathbb{R}^{m\times n},\,B\in\mathbb{R}^{n\times p},\,C\in\mathbb{R}^{m\times p}$,
chiamiamo \emph{prodotto righe per colonne} la relazione $A\cdot B=C$,
dove gli elementi della matrice $C$ valgono
\[
c_{i,\,j}=a_{i,\,1}\cdot b_{1,\,i}+a_{i,\,2}\cdot b_{2,\,i}+\ldots+a_{i,\,n}\cdot b_{n,\,j}
\]
Si osserva che l'elemento $c_{i,\,j}$ è ottenuto dal prodotto termine
a termine della $i$-esima riga di $A$ con la $j$-esima colonna
di $B$; questa operazione non è commutativa.
\end{defn}
%
\begin{defn}
Si chiama matrice \emph{trasposta} di $A$ e si indica con $A^{{\scriptscriptstyle \text{T}}}$
la matrice ottenuta scambiando ordinatamente le righe con le colonne
di $A$.
\end{defn}
Il prossimo concetto è essenziale per capire la successiva Definizione
\ref{def:Determinante}:
\begin{defn}
\label{def:Complemento-algebrico}Data una matrice quadrata $A$ il
\emph{complemento algebrico} del suo elemento $a_{i,\,j}$ è il determinante
della sotto-matrice che si ottiene eliminando dalla matrice principale
la $i$-esima riga e la $j$-esima colonna, moltiplicato per $(-1)^{i+j}$;
esso è indicato con $\Delta_{i,\,j}$.
\end{defn}
Ora possiamo introdurre il concetto di determinante, utilizzato ricorsivamente
nella precedente Definizione \ref{def:Complemento-algebrico}:
\begin{defn}
\label{def:Determinante}Il \emph{determinante} di una generica matrice
quadrata $A$ di ordine $n>1$ è pari a\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}I teorema di Laplace}{\footnotesize{}\index{Laplace, I teorema@{\footnotesize{}Laplace, I teorema}}}}[0.5cm]
\[
\det\left(A\right)=\serie{i=1}n{\left(a_{i,\,j}\cdot\Delta_{i,\,j}\right)}=\serie{j=1}n{\left(a_{i,\,j}\cdot\Delta_{i,\,j}\right)}
\]
o in altri termini il determinante di $A$ è la somma dei prodotti
degli elementi di una sua linea (riga o colonna) per i rispettivi
complementi algebrici. Se $n=1$ si ha il caso banale in cui la matrice
$A$ ha un solo elemento $a$ e vale $\det\left(a\right)=a$.

Inoltre per una matrice con $n=2$ si ottiene facilmente $\det\left(A\right)=a_{1,\,1}\cdot a_{2,\,2}-a_{2,\,1}\cdot a_{1,\,2}$.
\end{defn}
\begin{center}
\smallskip{}
\par\end{center}
\begin{xca}
Calcolare il determinante della seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: determinante di una matrice
$3\times3$}}

\[
A=\begin{bmatrix}1 & 0 & 2\\
2 & -1 & 3\\
1 & 5 & 2
\end{bmatrix}
\]
\end{xca}
\begin{center}
\rule[0.5ex]{0.9\textwidth}{0.1pt}
\par\end{center}
\begin{sol}
Considero la riga $1$, la quale presenta uno zero (semplificando
un addendo della somma di complementi algebrici): applicando la Definizione
\ref{def:Determinante} si ottiene che:
\end{sol}
\begin{itemize}
\item il primo addendo (relativo all'elemento $a_{1,\,1}=1$) si ottiene
da
\[
\begin{bmatrix}\boxed{1} & \cancel{0} & \cancel{2}\\
\cancel{2} & -1 & 3\\
\cancel{1} & 5 & 2
\end{bmatrix}\rightarrow1\cdot\left(-1\right)^{1+1}\cdot\det\left(\begin{bmatrix}-1 & 3\\
5 & 2
\end{bmatrix}\right)=-2-15=-17;
\]
\item il secondo addendo vale $0$;
\item il terzo addendo (relativo all'elemento $a_{1,\,3}=2$) si ottiene
da
\[
\begin{bmatrix}\cancel{1} & \cancel{0} & \boxed{2}\\
2 & -1 & \cancel{3}\\
1 & 5 & \cancel{2}
\end{bmatrix}\rightarrow2\cdot\left(-1\right)^{1+3}\cdot\det\left(\begin{bmatrix}2 & -1\\
1 & 5
\end{bmatrix}\right)=2\left(10+1\right)=22;
\]
\end{itemize}
Il determinante di $A$ sarà $\det\left(A\right)=22-17=\boxed{5}$.\demo
\begin{center}
\smallskip{}
\par\end{center}

A seguire alcune proprietà e osservazioni sul determinante di una
matrice:
\begin{rem}
Una matrice e la sua trasposta hanno lo stesso determinante: $\det\left(A\right)=\det\left(A^{{\scriptscriptstyle \text{T}}}\right)$.
\end{rem}
%
\begin{rem}
Il determinante di un prodotto matrice per scalare è dato da $\det\left(\alpha\cdot A\right)=\alpha^{n}\det\left(A\right)$.\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Teorema di Binet}{\footnotesize{}\index{Binet, teorema@{\footnotesize{}Binet, teorema}}}}[0.5cm]
\end{rem}
\begin{thm}
Per due matrici quadrate $A$ e $B$ dello stesso ordine vale $\det\left(A\cdot B\right)=\det\left(A\right)\cdot\det\left(B\right)$.
\end{thm}
\begin{defn}
\label{def:Matrice-singolare}Una matrice il cui determinante sia
nullo (zero) si dice \emph{singolare}; una matrice singolare non è
invertibile.
\end{defn}
%
\begin{defn}
\label{def:Rango}Il \emph{rango} di una matrice quadrata è il numero
massimo di vettori \emph{linearmente indipendenti} tra righe e colonne;
presi $n$ vettori, essi si dicono linearmente indipendenti se $\serie{i=1}n{\alpha_{i}v_{i}\neq0}\,\forall\alpha_{i}\in\mathbb{R},\,\alpha\neq0$.

Vice versa si parla di vettori linearmente \emph{dipendenti} se $\exists\alpha_{i},\,i\in1\ldots n\,:\,\serie{i=1}n{\alpha_{i}v_{i}=0}$.
\end{defn}
%
\begin{defn}
\label{def:Matrice-inversa}Data una matrice $A\in\mathbb{R}^{n\times n}$
indichiamo con $A^{-1}$ la sua \emph{inversa}, tale che $A\cdot A^{-1}=I$
(questo è valido solo per matrici non singolari, dalla Definizione
\ref{def:Matrice-singolare}).\marginpar{Attenzione agli indici del complemento algebrico $\Delta$: sono scambiati
rispetto a quelli dell'elemento $b$ corrispondente!}

Tale matrice si calcola come $A^{-1}=B=\begin{bmatrix}b_{1,1} & \cdots & b_{1,n}\\
\vdots & \ddots & \vdots\\
b_{n,1} & \cdots & b_{n,n}
\end{bmatrix}$ dove l'elemento $b_{i,\,j}=\dfrac{\Delta_{j,\,i}}{\det\left(A\right)}$.
\end{defn}
\begin{thm}
Data una matrice quadrata $A$, essa è invertibile se e solo se non
è singolare; se $A$ non è singolare allora la sua inversa vale $A^{-1}=\dfrac{1}{\det\left(A\right)}A^{*}$;
con $A^{*}=\left[a_{i,,j}^{*}\right]$ si indica la \emph{matrice
aggiunta} di $A$, ovvero quella il cui elemento di posto $a_{i,,j}^{*}$
corrisponde al complemento algebrico di $a_{j,,i}$.
\end{thm}
\begin{example}
Si vuole invertire la seguente matrice:
\[
A=\begin{bmatrix}1 & 3\\
5 & 2
\end{bmatrix}
\]
Usando la Definizione \ref{def:Matrice-inversa}, controlliamo che
$A$ sia invertibile: $\det\left(A\right)=1\cdot2-5\cdot3=2-15=-13$
che essendo diverso da zero rende la matrice invertibile; scriviamo
dunque la matrice inversa come il prodotto dell'inverso del determinante
per la matrice dei complementi algebrici di $A$ (dove per $a_{i,\,j}$
si prende $\Delta_{j,\,i}$, si rimanda inoltre alla Definizione \ref{def:Complemento-algebrico}):
\[
A^{-1}=-\dfrac{1}{13}\cdot\begin{bmatrix}2 & -3\\
-5 & 1
\end{bmatrix}
\]
\demo
\end{example}
\begin{center}
\smallskip{}
\par\end{center}
\begin{xca}
Calcolare l'inversa (se esiste) della seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: inversa di una matrice $3\times3$}}
\[
A=\begin{bmatrix}3 & -1 & 2\\
4 & 0 & 1\\
1 & 2 & 3
\end{bmatrix}
\]
\end{xca}
\begin{center}
\rule[0.5ex]{0.9\textwidth}{0.1pt}
\par\end{center}
\begin{sol}
Controlliamo che la matrice sia invertibile; calcoliamo dunque il
determinante utilizzando la seconda riga (contenente uno zero):
\[
\det\left(A\right)=4\cdot\left(-1\right)^{2+1}\cdot\det\left(\begin{bmatrix}-1 & 2\\
2 & 3
\end{bmatrix}\right)+0+1\cdot\left(-1\right)^{2+3}\cdot\det\left(\begin{bmatrix}3 & -1\\
1 & 2
\end{bmatrix}\right)
\]
\[
=-4\cdot(-3-4)-1\cdot\left(6+1\right)=28-7=21
\]
che risulta maggiore di zero e la matrice è invertibile.

Procediamo calcolando l'inversa come il prodotto dell'inverso del
determinante per la matrice dei complementi algebrici degli elementi
speculari ($a_{i,\,j}=\Delta_{j,\,i}$):\marginpar{Per brevità è stata usata la scrittura alternativa $\left|A\right|$
per indicare $\det\left(A\right)$}
\[
A^{-1}=\dfrac{1}{21}\cdot\begin{bmatrix}\Delta_{1,1} & \Delta_{2,1} & \Delta_{3,1}\\
\Delta_{1,2} & \Delta_{2,2} & \Delta_{3,2}\\
\Delta_{1,3} & \Delta_{2,3} & \Delta_{3,3}
\end{bmatrix}
\]

\[
=\dfrac{1}{21}\cdot\begin{bmatrix}\left(-1\right)^{1+1}\cdot\begin{vmatrix}0 & 1\\
2 & 3
\end{vmatrix} & \left(-1\right)^{2+1}\cdot\begin{vmatrix}-1 & 2\\
2 & 3
\end{vmatrix} & \left(-1\right)^{3+1}\cdot\begin{vmatrix}-1 & 2\\
0 & 1
\end{vmatrix}\\
\left(-1\right)^{2+1}\cdot\begin{vmatrix}4 & 1\\
1 & 3
\end{vmatrix} & \left(-1\right)^{2+2}\cdot\begin{vmatrix}3 & 2\\
1 & 3
\end{vmatrix} & \left(-1\right)^{3+2}\cdot\begin{vmatrix}3 & 2\\
4 & 1
\end{vmatrix}\\
\left(-1\right)^{3+1}\cdot\begin{vmatrix}4 & 0\\
1 & 2
\end{vmatrix} & \left(-1\right)^{3+2}\cdot\begin{vmatrix}3 & -1\\
1 & 2
\end{vmatrix} & \left(-1\right)^{3+3}\cdot\begin{vmatrix}3 & -1\\
4 & 0
\end{vmatrix}
\end{bmatrix}
\]

\[
=\dfrac{1}{21}\cdot\begin{bmatrix}-2 & \left(-1\right)-7 & -1\\
\left(-1\right)11 & 7 & \left(-1\right)-5\\
8 & \left(-1\right)7 & 4
\end{bmatrix}=\dfrac{1}{21}\begin{bmatrix}-2 & 7 & -1\\
-11 & 7 & 5\\
8 & -7 & 4
\end{bmatrix}
\]
\demo
\end{sol}
\begin{center}
\smallskip{}
\par\end{center}

Seguono ora alcune osservazioni sulle proprietà delle matrici inverse:
\begin{rem}
Per l'operazione di inverso sulle matrici sono dimostrate le seguenti
proprietà:
\end{rem}
\begin{itemize}
\item l'inversa di una matrice inversa è la matrice non invertita $\left(A^{-1}\right)^{-1}=A$;
\item l'inverso del prodotto di uno scalare per una matrice è il prodotto
del suo inverso per la matrice inversa $\left(\alpha\cdot A\right)^{-1}=\nicefrac{1}{\alpha}\cdot A^{-1}$;
\item l'inverso del prodotto di due matrici è uguale al prodotto delle inverse
scambiate di posto $\left(A\cdot B\right)^{-1}=B^{-1}\cdot A^{-1}$.
\end{itemize}
\begin{rem}
Sia $A$ una matrice diagonale del tipo $\begin{bmatrix}a_{1,1} & 0 & 0\\
0 & \ddots & 0\\
0 & 0 & a_{n,n}
\end{bmatrix}$, allora la sua inversa è ancora una matrice diagonale nella forma
\[
\begin{bmatrix}\dfrac{1}{a_{1,1}} & 0 & 0\\
0 & \ddots & 0\\
0 & 0 & \dfrac{1}{a_{n,n}}
\end{bmatrix}
\]
Si verifica inoltre che, se una matrice è invertibile, risulta che
$\det\left(A^{-1}\right)=\dfrac{1}{\det\left(A\right)}$.
\end{rem}

\section{Autovalori e autovettori}
\begin{defn}
\label{def:Autovalore}Un numero $\lambda\in\mathbb{C}$ è un \emph{autovalore}
per una matrice $A\in\mathbb{C}^{n\times n}$ se vale la seguente:
\[
\exists v\in\mathbb{C}^{n}\,:\,A\cdot v=\lambda\cdot v
\]
che può essere riscritta come $\left(\lambda I-A\right)\cdot v=0$
per $v\neq0$; questo si verifica se e solo se \marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Polinomio caratteristico}{\footnotesize{}\index{Matrice, polinomio caratteristico@{\footnotesize{}Matrice, polinomio caratteristico}}}}[0.2cm]
\begin{equation}
\det\left(\lambda I-A\right)=0\label{eq:Polinomio-caratteristico}
\end{equation}
Il (\ref{eq:Polinomio-caratteristico}), che indichiamo come $\phi\left(\lambda\right)=0$,
ha per soluzioni $\lambda_{i}\in\mathbb{C}$ le quali sono gli autovalori
della matrice $A$.

La molteplicità degli autovalori è minore o uguale all'ordine della
matrice $A$ ($i\in1\ldots n$); chiamiamo il numero di autovalori
distinti $\mu_{n}\in1\ldots n$.
\end{defn}
%
\begin{defn}
\label{def:Molteplicit=0000E0-algebrica}La \emph{molteplicità algebrica}
di un autovalore $\lambda_{i}$ è il numero di volte che esso compare
tra gli autovalori di una matrice, e si indica con $n_{i}$; possiamo
scrivere le soluzioni di (\ref{eq:Polinomio-caratteristico}) rispetto
alla molteplicità algebrica:
\[
\phi\left(\lambda\right)=\overset{{\scriptstyle \mu_{n}}}{\underset{{\scriptstyle i=1}}{\prod}}\left(\lambda-\lambda_{i}\right)^{n_{i}}
\]
Si verifica che il numero $\mu_{n}$ di autovalori distinti deve corrispondere
al rango della matrice.
\end{defn}
%
\begin{defn}
Un \emph{autovettore} $v_{i}$ associato all'autovalore $\lambda_{i}$
è tale per cui (applicando la Definizione \ref{def:Autovalore}) valga
$\left(\lambda_{i}I-A\right)v_{i}=0$ posto che $v_{i}\neq0$. Gli
autovettori associati a un autovalore sono infiniti.
\end{defn}
\begin{center}
\smallskip{}
\par\end{center}
\begin{xca}
Calcolare gli autovalori e un autovettore per ciascuno di essi, per
la seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: autovettori di matrice $2\times2$}}[-0.5cm]
\[
A=\begin{bmatrix}1 & 3\\
-2 & 5
\end{bmatrix}
\]
\end{xca}
\begin{center}
\rule[0.5ex]{0.9\textwidth}{0.1pt}
\par\end{center}
\begin{sol}
Per cominciare calcoliamo (\ref{eq:Polinomio-caratteristico}) in
generale (rispetto a $\lambda$):
\[
\det\left(\lambda I-A\right)=\det\left(\lambda\cdot\begin{bmatrix}1 & 0\\
0 & 1
\end{bmatrix}-\begin{bmatrix}1 & 3\\
-2 & 5
\end{bmatrix}\right)=\begin{vmatrix}\lambda-1 & -3\\
2 & \lambda-5
\end{vmatrix}
\]
\[
=\left(\lambda-1\right)\left(\lambda-5\right)+6=\lambda^{2}-6\lambda+11
\]
Le soluzioni del determinante (polinomio caratteristico) sono le complesse
coniugate $\lambda_{i}=3\pm j\sqrt{2}$ (con $j$ l'unità immaginaria,
tale che $j^{2}=-1$); calcoliamo gli autovettori associati a entrambi
gli autovalori:
\end{sol}
\begin{enumerate}
\item Autovettore $v_{1}$ associato a $\lambda_{1}=3+j\sqrt{2}$:\\
deve valere $\det\left(\lambda_{1}I-A\right)v_{1}=0$ ovvero $\begin{bmatrix}3+j\sqrt{2}-1 & -3\\
2 & 3+j\sqrt{2}-5
\end{bmatrix}\cdot\begin{bmatrix}v_{1,1}\\
v_{2,1}
\end{bmatrix}=0$; dal prodotto righe per colonne si ottiene l'equazione $\left(2-j\sqrt{2}\right)v_{1,1}-3v_{2,1}=0$.
Essa può essere risolta scegliendo una condizione per una delle due
componenti del vettore; imponiamo $v_{1,1}=3$: si ottiene $v_{2,1}=2+j\sqrt{2}$
e quindi il vettore $v_{1}$ avrà le componenti $\boxed{\left(3,\,2+j\sqrt{2}\right)}$
\item Autovettore $v_{2}$ associato a $\lambda_{2}=3-j\sqrt{2}$:\\
essendo gli autovalori complessi coniugati e la matrice di ordine
$2$, possiamo assumere che il secondo autovettore abbia la seconda
componente complessa coniugata rispetto al primo $\boxed{\left(3,\,2-j\sqrt{2}\right)}$\demo
\end{enumerate}
\begin{center}
\smallskip{}
\par\end{center}
\begin{xca}
Calcolare autovalori e autovettori della seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: autovettori di matrice $2\times2$}}
\[
A=\begin{bmatrix}-1 & -1\\
-4 & -1
\end{bmatrix}
\]
\sln{\lambda_{1}=1,\,\lambda_{2}=-3,\,v_{1}=\left(-1,2\right),\,v_{2}=\left(1,2\right)}
\end{xca}
\begin{center}
\smallskip{}
\par\end{center}
\begin{rem}
Se scriviamo il determinante (Definizione \ref{def:Determinante})
in termini di autovalori (Definizione \ref{def:Molteplicit=0000E0-algebrica})
segue che
\[
\det\left(A\right)=\overset{{\scriptstyle \mu_{n}}}{\underset{{\scriptstyle i=1}}{\prod}}\left(\lambda_{i}\right)^{n_{i}}
\]
Per annullare la produttoria deve esistere almeno un $\lambda_{i}=0$,
per cui una matrice con determinante nullo (singolare) ha almeno un
autovalore nullo.
\end{rem}
%
\begin{rem}
Sia $A$ una matrice triangolare (ha solo elementi nulli al di sotto
o al di sopra della diagonale principale); allora gli autovalori di
$A$ sono esattamente gli elementi sulla diagonale principale ($\lambda_{i}=a_{i,\,i}$).
\end{rem}
%
\begin{rem}
Se $\lambda_{i}$ è un autovalore di una matrice $A$ allora $\lambda_{i}^{-1}$
è un autovalore di $A^{-1}$ (posto che $A$ sia invertibile).
\end{rem}
%
\begin{rem}
la \emph{traccia} della matrice $A$ (la somma degli elementi sulla
diagonale principale) è anche pari alla somma dei suoi autovalori
(contati con le rispettive molteplicità algebriche):
\[
\text{tr}\left(A\right)=\serie{i=1}n{a_{i,\,i}}=\serie{i=1}n{n_{i}\lambda_{i}}
\]
\end{rem}
Definiamo ora alcune proprietà degli autovettori.
\begin{defn}
\label{def:Autospazio-molt-geometrica}Un autovettore $v_{i}$ si
chiama \emph{autospazio} per il suo autovalore associato $\lambda_{i}$;
la dimensione di tale autospazio è indicata con $g_{i}\in\left[1,n_{i}\right]$
e si chiama \emph{molteplicità geometrica}, relativa a $\lambda_{i}$.
Essa si calcola come $g_{i}=n-\text{rango}\left(\lambda_{i}I-A\right)$

Per autovalori tutti distinti la loro molteplicità geometrica sarà
in ogni caso $1$.
\end{defn}
\begin{center}
\smallskip{}
\par\end{center}
\begin{xca}
Calcolare la molteplicità geometrica degli autovalori della seguente
matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: molteplicità geometrica di
autovalori di matrice $3\times3$}}[-0.5cm]
\[
A=\begin{bmatrix}0 & 1 & 0\\
1 & 0 & 0\\
0 & 0 & 1
\end{bmatrix}
\]
\end{xca}
\begin{center}
\rule[0.5ex]{0.9\textwidth}{0.1pt}
\par\end{center}
\begin{sol}
Partiamo cercando gli autovalori di $A$ tramite il (\ref{eq:Polinomio-caratteristico}):
\[
\det\left(\lambda I-A\right)=\begin{bmatrix}\lambda & -1 & 0\\
-1 & \lambda & 0\\
0 & 0 & \lambda-1
\end{bmatrix}=\lambda\left(-1\right)^{1+1}\begin{vmatrix}\lambda & 0\\
0 & \lambda-1
\end{vmatrix}-1\left(-1\right)^{1+2}\begin{vmatrix}-1 & 0\\
0 & \lambda-1
\end{vmatrix}
\]
\[
=\lambda\left(\lambda\left(\lambda-1\right)\right)-\left(\lambda-1\right)=\left(\lambda-1\right)\left(\lambda^{2}-1\right)=\left(\lambda-1\right)\left(\lambda+1\right)\left(\lambda-1\right)
\]
Il gli autovalori risultano essere $\lambda_{1}=1$ con $n_{1}=2$
e $\lambda_{2}=-1$ con $n_{2}=1$; calcoliamo quindi la molteplicità
geometrica per entrambi gli autovalori:
\end{sol}
\begin{enumerate}
\item Per il primo autovalore applichiamo la Definizione \ref{def:Autospazio-molt-geometrica}:
\[
g_{1}=3-\text{rango}\left(\begin{bmatrix}1 & -1 & 0\\
-1 & 1 & 0\\
0 & 0 & 0
\end{bmatrix}\right)=3-1=2
\]
ricordando che per la Definizione \ref{def:Rango} il rango è il numero
massimo di righe o colonne linearmente indipendenti; nel caso di $A$
sono al più 1, essendo l'ultima riga e l'ultima colonna costituite
da zeri (quindi combinazione lineare di una delle altre righe o colonne
per 0) mentre le prima due righe e colonne sono l'una l'opposto dell'altra
(quindi combinazione lineare di una delle due per $-1$).
\item Per il secondo autovalore, che ha molteplicità algebrica $1$, la
molteplicità geometrica vale $g_{2}=1$.
\end{enumerate}
In conclusione, abbiamo trovato $g_{1}=1,\,g_{2}=1$\demo\smallskip{}


\section{Similitudine e diagonalizzabilità}

La seguente definizione realizza una relazione di equivalenza (riflessiva,
simmetrica e transitiva) tra due matrici:
\begin{defn}
Siano $A$ e $B$ matrici quadrate dello stesso ordine; $A$ è detta
\emph{simile} a $B$ se esiste una matrice non singolare $T$ tale
che $B=T\cdot A\cdot T^{-1}$.

La matrice di trasformazione $T^{-1}$ ha per colonne autovettori
della matrice $A$: $T^{-1}=\left[v_{1},v_{2},\ldots\,,v_{\mu_{n}}\right]$
con $v_{i}$ associato a $\lambda_{i}$ per $A$; ogni $v_{i}$ inoltre
ha un numero di colonne pari alla molteplicità algebrica $n_{i}$
del $\lambda_{i}$ associato.
\end{defn}
\begin{thm}
Due matrici simili possiedono lo stesso polinomio caratteristico,
quindi gli stessi autovalori.
\end{thm}
\begin{defn}
Una matrice si dice \emph{diagonalizzabile} se è simile a una matrice
diagonale, ovvero $A$ è diagonalizzabile se
\[
\exists T_{{\scriptscriptstyle \text{D}}}\,:\,A_{{\scriptscriptstyle \text{D}}}=T_{{\scriptscriptstyle \text{D}}}AT_{{\scriptscriptstyle \text{D}}}^{-1}
\]
dove $A_{{\scriptscriptstyle \text{D}}}$ è una matrice diagonale
con gli stessi autovalori di $A$.
\end{defn}
\begin{rem}
\label{oss:Condizione-sufficiente-diagonalizzabilit=0000E0}Si osserva
allora che una matrice $A$ è diagonalizzabile se e solo se ha autovalori
tutti distinti (la molteplicità algebrica e geometrica dei suoi autovalori
coincidono) $\forall i\in1\ldots n\left(n_{i}=g_{i}\right)$.
\end{rem}
\smallskip{}

\begin{xca}
Ottenere se la seguente matrice è diagonalizzabile, e in tal caso
ottenere la matrice di trasformazione:\marginpar{$\blacktriangleright$ \emph{Esercizio: diagonalizzabilità di matrice
$3\times3$}}[-0.5cm]
\[
A=\begin{bmatrix}1 & 0 & 1\\
0 & 1 & 0\\
0 & 0 & 2
\end{bmatrix}
\]
\end{xca}
\begin{center}
\rule[0.5ex]{0.9\textwidth}{0.1pt}
\par\end{center}
\begin{sol}
Per sapere se $A$ sia diagonalizzabile dobbiamo riuscire a ottenere
una matrice invertibile $T_{{\scriptscriptstyle \text{D}}}$ che renda
$A$ simile a una matrice diagonale; cominciamo quindi usando l'Osservazione
\ref{oss:Condizione-sufficiente-diagonalizzabilit=0000E0} e cerchiamo
gli autovalori di $A$:
\[
\det\left(\lambda I-A\right)=\begin{vmatrix}\lambda-1 & 0 & -1\\
0 & \lambda-1 & 0\\
0 & 0 & \lambda-2
\end{vmatrix}=\left(\lambda-1\right)^{2}\left(\lambda-2\right)
\]
La precedente è una matrice triangolare, dunque il determinante si
ottiene come prodotto degli elementi sulla diagonale principale; otteniamo
$\lambda_{1}=1$ con $n_{1}=2$ e $\lambda_{2}=2$ con $n_{2}=1$.

Abbiamo che la $n_{2}=1=g_{2}$, rimane da controllare che $g_{1}=n_{1}=2$;
usando la definizione scriviamo
\[
g_{1}=3-\text{rango}\left(\lambda_{1}I-A\right)=3-\text{rango}\left(\begin{bmatrix}0 & 0 & -1\\
0 & 0 & 0\\
0 & 0 & -1
\end{bmatrix}\right)=3-1=\boxed{2}
\]
Possiamo affermare che $A$ è diagonalizzabile, quindi troviamo la
matrice di trasformazione $T_{{\scriptscriptstyle \text{D}}}$ cercando
gli autospazi associati agli autovalori:
\end{sol}
\begin{enumerate}
\item Per $\lambda_{1}=1$ abbiamo $\left(I-A\right)v_{1}=0$:
\[
\begin{bmatrix}0 & 0 & -1\\
0 & 0 & 0\\
0 & 0 & -1
\end{bmatrix}\cdot\begin{bmatrix}v_{1,1} & v_{1,2}\\
v_{2,1} & v_{2,2}\\
v_{3,1} & v_{3,2}
\end{bmatrix}=0
\]
Imponendo $v_{3,1}=0$ possiamo scegliere $v_{1,1}=0$ e $v_{2,1}\neq0$
per ottenere due autovettori linearmente indipendenti:
\[
v_{1}=\left(1,0,0\right),\,\left(0,1,0\right)
\]
\item Per $\lambda_{2}=2$ abbiamo $\left(2I-A\right)v_{2}=0:$
\[
\begin{bmatrix}1 & 0 & -1\\
0 & 1 & 0\\
0 & 0 & 0
\end{bmatrix}\cdot\begin{bmatrix}v_{1,1}\\
v_{2,1}\\
v_{3,1}
\end{bmatrix}=0\rightarrow\begin{cases}
v_{1,1}=v_{3,1} & {\scriptscriptstyle \text{(1°riga\ensuremath{\times v_{2}})}}\\
v_{2,1}=0 & {\scriptscriptstyle \text{(2°riga\ensuremath{\times v_{2}})}}
\end{cases}
\]
Una possibile scelta per il secondo autospazio è $v_{2}=\left(1,0,1\right)$.
\end{enumerate}
Infine, scriviamo la matrice di trasformazione inversa, le cui righe
sono gli autospazi trovati:
\[
T_{{\scriptscriptstyle \text{D}}}^{-1}=\begin{bmatrix}1 & 0 & 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}\rightarrow T_{{\scriptscriptstyle \text{D}}}=1\cdot\begin{bmatrix}1 & 0 & -1\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}
\]
e grazie ad essa otteniamo la matrice diagonale $A_{{\scriptscriptstyle \text{D}}}$
simile ad $A$:
\[
A_{{\scriptscriptstyle \text{D}}}=\begin{bmatrix}1 & 0 & -1\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}\cdot\begin{bmatrix}1 & 0 & 1\\
0 & 1 & 0\\
0 & 0 & 2
\end{bmatrix}\cdot\begin{bmatrix}1 & 0 & 1\\
0 & 1 & 0\\
0 & 0 & 1
\end{bmatrix}=\begin{bmatrix}1 & 0 & 0\\
0 & 1 & 0\\
0 & 0 & 2
\end{bmatrix}
\]

che è proprio la matrice diagonale cercata, con gli autovalori di
$A$ sulla diagonale principale.\demo

\smallskip{}

\begin{xca}
Trova (se esiste) la matrice diagonale simile alla seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: matrice diagonale simile a
matrice $2\times2$}}
\[
A=\begin{bmatrix}1 & 3\\
-2 & 5
\end{bmatrix}
\]
\sln{A_{{\scriptscriptstyle \text{D}}}=[[3+j\sqrt{2},0],\,[0,3-j\sqrt{2}]]}
\end{xca}
\begin{center}
\smallskip{}
\par\end{center}

Anche se una matrice non è diagonalizzabile (non vale la Definizione
\ref{oss:Condizione-sufficiente-diagonalizzabilit=0000E0}), è possibile
metterla comunque in una forma il più simile possibile a una matrice
diagonale:
\begin{defn}
Una matrice $A$ che non sia diagonalizzabile può comunque essere
scritta in una forma diagonale a blocchi, chiamata \emph{forma di
Jordan}.

Si prendono tutti gli autovalori di $A$ tali che $g_{i}<n_{i}$ e
si trovano gli \emph{autovettori generalizzati} associati ai $\lambda_{i}$
nel modo seguente:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Autovettori generalizzati}{\footnotesize{}\index{Autovettori generalizzati@{\footnotesize{}Autovettori generalizzati}}}}[1cm]
\begin{equation}
\begin{array}{c}
v_{i,\,1}\coloneqq\left(\lambda_{i}I-A\right)v_{i,\,1}=0\\
v_{i,\,2}\coloneqq\left(A-\lambda_{i}I\right)v_{i,\,2}=v_{i,\,1}\\
\vdots\\
v_{i,\,\mu_{n}}\coloneqq\left(A-\lambda_{i}I\right)v_{i,\,\mu_{n}}=v_{i,\,\mu_{n}-1}
\end{array}\label{eq:Autovettori-generalizzati}
\end{equation}
La matrice di trasformazione si otterrà come $T_{{\scriptscriptstyle \text{J}}}^{-1}=\left[v_{i,1},\,v_{i,2},\,\ldots v_{i,\,\mu_{n}}\right]$
in cui le colonne sono costituite dagli autovettori generalizzati.

La matrice $A$ in forma di Jordan si scrive come\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Forma di Jordan}{\footnotesize{}\index{Jordan, forma di@{\footnotesize{}Jordan, forma di}}}}[0.5cm]
\begin{equation}
A_{{\scriptscriptstyle \text{J}}}=T_{{\scriptscriptstyle \text{J}}}\cdot A\cdot T_{{\scriptscriptstyle \text{J}}}^{-1}\label{eq:Forma-di-Jordan}
\end{equation}
\end{defn}
La matrice in forma di Jordan ha una struttura diagonale a blocchi,
ognuno dei quali è sulla diagonale principale e sono tanti quanti
gli autovalori distinti; ciascun blocco ha dimensione pari alla molteplicità
algebrica dell'autovalore relativo, e ogni coefficiente sulla diagonale
del blocco è l'autovalore a cui appartiene il blocco.

\begin{wrapfigure}{o}{0.3\textwidth}%
\begin{centering}
$A_{{\scriptscriptstyle \text{J}}}=\begin{bmatrix}\boxed{\begin{array}{cc}
\lambda_{1} & 1\\
0 & \lambda_{1}
\end{array}} & \begin{array}{c}
0\\
0
\end{array}\\
\begin{array}{cc}
0\; & \;0\end{array} & \boxed{\lambda_{2}}
\end{bmatrix}$
\par\end{centering}
\caption{Esempio di matrice in forma di Jordan, per $n_{1}=2,\,g_{1}=1$ e
$n_{2}=g_{2}=1$}
\end{wrapfigure}%
Nei blocchi di ordine maggiore di uno (hanno ordine $n_{i}$, relativi
ad autovalori con $n_{i}>1$) sono presenti gli autovalori $\lambda_{i}$
sulla diagonale principale, e tutti gli elementi della sopra-diagonale
sono pari a 1;

L'esponenziale di una matrice in forma di Jordan è costituito dall'esponenziale
di ogni blocco di Jordan di ordine uno, mentre per i blocchi di ordine
maggiore i coefficienti al di sopra della diagonale (quelli sulla
diagonale sono l'esponenziale dei coefficienti sulla diagonale) sono
pari al termine $t^{h}/h!$ con $h=i-j$ la distanza dell'elemento
$a_{{\scriptscriptstyle \text{J}},\,i,j}^{\prime}$ da quello sulla
diagonale $a_{{\scriptscriptstyle \text{J}},\,i,i}^{\prime}$ all'interno
della stessa riga:
\[
e^{A_{{\scriptscriptstyle \text{J}}}t}=e^{\lambda_{1}}\cdot\begin{bmatrix}1 & t & t^{2}/2\\
0 & 1 & t\\
0 & 0 & 1
\end{bmatrix}=\begin{bmatrix}e^{\lambda_{1}} & te^{\lambda_{1}} & \nicefrac{t^{2}}{2}e^{\lambda_{1}}\\
0 & e^{\lambda_{1}} & te^{\lambda_{1}}\\
0 & 0 & e^{\lambda_{1}}
\end{bmatrix}
\]
dove $A_{{\scriptscriptstyle \text{J}}}$ è una matrice in forma di
Jordan con un unico blocco di Jordan relativo a un autovalore $\lambda_{1}$
con $n_{i}=3$.

\smallskip{}

\begin{xca}
Trova la matrice in forma di Jordan simile alla seguente matrice:\marginpar{$\blacktriangleright$ \emph{Esercizio: matrice $3\times3$ in forma
di Jordan}}
\[
A=\begin{bmatrix}1 & -4 & 3\\
0 & -2 & 0\\
-3 & 8 & 1
\end{bmatrix}
\]
\sln{A_{{\scriptscriptstyle \text{J}}}=[[-2,1,0],\,[0,2,0],\,[0,0,4]]}
\end{xca}
\begin{center}
\smallskip{}
\par\end{center}

\section{Esponenziali di matrici}

Possiamo definire la funzione esponenziale di una matrice $A$ rispetto
a una variabile $t$ come:
\begin{defn}
\label{def:Esponenziale-di-matrice}Un \emph{esponenziale di matrice}
è una funzione del tipo $e^{A\cdot t}=\serie{i=0}{\infty}{\dfrac{1}{i!}\left(A\cdot t\right)^{i}}=I+A\cdot t+\dfrac{1}{2}\left(A\cdot t\right)^{2}+\ldots$

Se abbiamo una matrice diagonale $A=\begin{bmatrix}\lambda_{1} & 0\\
0 & \lambda_{2}
\end{bmatrix}$ allora il suo esponenziale vale $e^{A\cdot t}=\begin{bmatrix}e^{\lambda_{1}t} & 0\\
0 & e^{\lambda_{2}t}
\end{bmatrix}$, dove si ha l'esponenziale scalare $e^{\lambda t}=\serie{i=1}{\infty}{\dfrac{1}{i!}\left(\lambda t\right)^{i}}$.

Se abbiamo una matrice in forma di Jordan, per i blocchi di Jordan
con ordine maggiore di 1 vale $A_{{\scriptscriptstyle \text{J}}}=\begin{bmatrix}\lambda_{1} & 1\\
0 & \lambda_{1}
\end{bmatrix}\rightarrow e^{A_{{\scriptscriptstyle \text{J}}}\cdot t}=\begin{bmatrix}e^{\lambda_{1}t} & te^{\lambda_{1}t}\\
0 & e^{\lambda_{1}t}
\end{bmatrix}$; da un blocco di Jordan $2\times2$ compare un termine lineare, per
dimensione $n$ maggiore compariranno termini di grado $n-1$.
\end{defn}
\begin{rem}
\label{oss:Esponenziali-matrici-simili}Siano $A$ e $B$ due matrici
simili ($B=T\cdot A\cdot T^{-1}$), allora vale $e^{B\cdot t}=T\cdot e^{A\cdot t}\cdot T^{-1}$;
questo si verifica applicando la Definizione \ref{def:Esponenziale-di-matrice}.
\end{rem}
%
\begin{rem}
Sia $A$ una matrice diagonale o in forma di Jordan, allora si ha
che $A\cdot e^{A\cdot t}=e^{A\cdot t}\cdot A$; dato che $A$ è diagonale,
anche la sua esponenziale sarà una matrice diagonale e il prodotto
di due matrici diagonali è commutativo.

Dalla Osservazione \ref{oss:Esponenziali-matrici-simili} otteniamo
che questa uguaglianza vale in generale per una matrice $A$ qualsiasi;
infatti $T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot T_{{\scriptscriptstyle \text{D}}}\cdot T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}\cdot T_{{\scriptscriptstyle \text{D}}}=T_{{\scriptscriptstyle \text{D}}}^{-1}\cdot A_{{\scriptscriptstyle \text{D}}}\cdot e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}\cdot T_{{\scriptscriptstyle \text{D}}}=A$.
\end{rem}
%
\begin{rem}
\label{oss:Derivata-esponenziale-matrice}Sia $A_{{\scriptscriptstyle \text{D}}}$
una matrice diagonale, allora la derivata nel tempo del suo esponenziale
vale $\dfrac{\partial}{\partial t}e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}=A_{{\scriptscriptstyle \text{D}}}\cdot e^{A_{{\scriptscriptstyle \text{D}}}\cdot t}$;
questo risultato proviene dalla derivata degli elementi sulla diagonale
di una matrice esponenziale.

Si ottiene di nuovo che questa uguaglianza vale in generale, per qualsiasi
matrice $A$.
\end{rem}

\section{Numeri nel campo complesso}
\begin{defn}
Un numero complesso nella forma algebrica è scritto come $s=a+jb$,
dove $a=\Re\left(s\right)$ è la parte reale e $b=\Im\left(s\right)$
la parte immaginaria; $j$ è l'unità immaginaria tale che $j^{2}=-1$.

Ogni numero complesso possiede un complesso coniugato, che ha la stessa
parte reale e la parte immaginaria cambiata di segno ($\overline{s}=a-jb$).

I numero complessi ammettono anche la rappresentazione in forma trigonometrica
(modulo e fase) sul piano di Gauss: $s=\rho\left(\cos\left(\phi\right)+j\sin\left(\phi\right)\right)$,
dove $\rho$ è la distanza del numero dall'origine e $\phi$ è l'angolo
che questa distanza forma con l'asse orizzontale.
\end{defn}
\begin{rem}
Per passare da una rappresentazione algebrica a una trigonometrica
si usano le seguenti considerazioni:
\[
\rho=\sqrt{a^{2}+b^{2}}
\]
\[
\phi=\text{arg}\left(s\right)\coloneqq\begin{cases}
\arctan\left(\dfrac{b}{a}\right) & a>0\\
\arctan\left(\dfrac{b}{a}\right)+\pi & a<0\\
\dfrac{\pi}{2} & a=0\land b>0\\
-\dfrac{\pi}{2} & a=0\land b<0
\end{cases}
\]
\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Formula di Eulero}{\footnotesize{}\index{Eulero, formula di@{\footnotesize{}Eulero, formula di}}}}[1.4cm]
\end{rem}
\begin{thm}
Consideriamo l'esponenziale di un numero complesso; scriveremo: $e^{a+jb}=e^{a}\cdot e^{jb}$.
La formula di Eulero afferma che
\begin{equation}
e^{jb}=\cos\left(b\right)+j\sin\left(b\right)\label{eq:Formula-di-Eulero}
\end{equation}
\end{thm}
La (\ref{eq:Formula-di-Eulero}) è molto utile per eseguire il prodotto
di numeri complessi, riconducendolo alle proprietà delle potenze.

\chapter{Trasformata di Laplace}

\section{Definizione}
\begin{defn}
Sia data una funzione $f\,:\,\mathbb{R}\rightarrow\mathbb{C}$ e definiamo
una variabile complessa $s=\sigma+j\omega\in\mathbb{C}$; se la funzione\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Trasformata di Laplace}{\footnotesize{}\index{Laplace, trasformata continua@{\footnotesize{}Laplace, trasformata continua}}}}[0.7cm]
\begin{equation}
F\left(s\right)=\somme 0{+\infty}{f\left(t\right)e^{-st}}t\label{eq:Trasformata-Laplace}
\end{equation}
esiste per qualche valore di $s$, essa si dice \emph{trasformata
di Laplace} di $f\left(t\right)$ e si indice come $\mathscr{L}\left[f\left(t\right)\right]=F\left(s\right)$.
\end{defn}
La definizione appena enunciata implica che $f\left(t\right)$ sia
almeno definita per $t\geq0$; i contributi della funzione per $t<0$
saranno nulli. Per questo motivo useremo moltiplicare i segnali di
cui calcoleremo (\ref{eq:Trasformata-Laplace}) per l'ingresso canonico
$\text{sca}\left(t\right)$, che si annulla proprio per $t<0$ mentre
è costante e unitario per gli altri valori di $t$.

Inoltre il primo estremo di integrazione di (\ref{eq:Trasformata-Laplace})
va inteso come $0^{-}$ (avvicinamento da sinistra), ovvero esso comprende
i contributi impulsivi della funzione applicati nell'istante $t=0$.
\begin{defn}
Sia $\overline{\sigma}>-\infty$ l'estremo inferiore delle parti reali
$\Re\left(s\right)$ dei valori $s$ per cui l'integrale (\ref{eq:Trasformata-Laplace})
converge; allora la trasformata di Laplace esiste in un semipiano
delimitato dalla condizione $\Re\left(s\right)>\overline{\sigma}$,
per questo motivo $\overline{\sigma}$ si chiama ascissa di convergenza.
\end{defn}
%
\begin{defn}
Sia $F\left(s\right)$ la trasformata di Laplace di una funzione $f\left(t\right)$;
se è possibile scrivere
\begin{equation}
F\left(s\right)=\dfrac{N\left(s\right)}{D\left(s\right)}\label{eq:Trasformata-razionale}
\end{equation}
con $N\left(s\right)$ e $D\left(s\right)$ polinomi primi tra loro,
si ha una trasformata razionale.

Per questa categoria di trasformate, le radici dei polinomi al numeratore
e denominatore si chiamano \emph{singolarità} e si classificano in
\begin{equation}
\begin{cases}
N\left(s\right)=0 & \text{zeri}\\
D\left(s\right)=0 & \text{poli}
\end{cases}\label{eq:Singolarit=0000E0}
\end{equation}
Quando $f\left(t\right)\in\mathbb{R}$ i coefficienti di $N\left(s\right)$
e $D\left(s\right)$ sono reali e l'ascissa di convergenza è pari
alla massima tra le parti reali dei coefficienti dei poli.
\end{defn}
%
\begin{defn}
Chiamiamo \emph{formula di antitrasformazione} la funzione inversa
della trasformata di Laplace, definita come\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Antitrasformata di Laplace}{\footnotesize{}\index{Laplace, antitrasformata continua@{\footnotesize{}Laplace, antitrasformata continua}}}}[0.7cm]
\begin{equation}
\mathscr{L}^{-1}\left[F\left(s\right)\right]=f\left(t\right)=\dfrac{1}{2\pi j}\somme{\sigma-j\infty}{\sigma+j\infty}{F\left(s\right)e^{st}}s\label{eq:Antitrasformata-Laplace}
\end{equation}
dove agli estremi di integrazione si ha $\sigma>\overline{\sigma},\,\sigma\in\mathbb{R}$
qualsiasi. La corrispondenza tra trasformata e antitrasformata di
Laplace è biunivoca nel caso di funzioni nulle per $t<0$.
\end{defn}

\section{Proprietà\label{sec:Propriet=0000E0-della-trasformata}}
\begin{lyxlist}{00.00.0000}
\item [{$\mathrm{\left(I\right)}\,\text{\textsc{Linearità}}$\noun{:}}] Prendiamo
due funzioni $f\left(t\right)$ e $g\left(t\right)$, allora $\forall\alpha\in\mathbb{C},\,\forall\beta\in\mathbb{C}$
vale
\[
\mathscr{L}\left[\alpha f\left(t\right)+\beta g\left(t\right)\right]=\alpha F\left(s\right)+\beta G\left(s\right)
\]
ovvero la (\ref{eq:Trasformata-razionale}) è una operazione lineare.\bigskip{}
\item [{$\mathrm{\left(II\right)}\,\text{\textsc{Traslazione nel dominio del Tempo}}$\noun{:}}] Comunque
preso un ritardo $\tau>0$, si consideri la funzione traslata $f\left(t-\tau\right)$;
la sua trasformata di Laplace vale
\[
\mathscr{L}\left[f\left(t-\tau\right)\right]=\somme 0{+\infty}{f\left(t-\tau\right)e^{-st}}t=e^{-s\tau}\somme 0{+\infty}{f\left(t-\tau\right)e^{-st}\cdot e^{s\tau}}t
\]
\[
=e^{-s\tau}\somme 0{+\infty}{f\left(t-\tau\right)e^{-s\left(t-\tau\right)}}{\left(t-\tau\right)}=\boxed{e^{-s\tau}F\left(s\right)}
\]
dove abbiamo moltiplicato e diviso per $e^{-s\tau}$ e infine abbiamo
aggiustato il differenziale $dt$ considerando anche il ritardo (costante).\bigskip{}
\item [{$\mathrm{\left(III\right)}\,\text{\textsc{Traslazione nel dominio di Laplace}}$\noun{:}}] Comunque
preso un valore $\alpha\in\mathbb{C}$, la trasformata della funzione
$e^{\alpha t}f\left(t\right)$ vale:
\[
\mathscr{L}\left[e^{\alpha t}f\left(t\right)\right]=\somme 0{+\infty}{e^{\alpha t}f\left(t\right)e^{-st}}t=\somme 0{+\infty}{f\left(t\right)e^{-t\left(s-\alpha\right)}}t=\boxed{F\left(s-\alpha\right)}.
\]
\item [{$\mathrm{\left(IV\right)}\,\text{\textsc{Derivazione nel dominio del Tempo}}$\noun{:}}] La
trasformata di Laplace della derivata prima di una funzione $f\left(t\right)$
rispetto a $t$, vale:
\[
\mathscr{L}\left[\dot{f}\left(t\right)\right]=\somme 0{+\infty}{\dot{f}\left(t\right)e^{-st}}t=sF\left(s\right)-f\left(0\right)
\]
Questo risultato si ottiene a partire dalla seguente uguaglianza sull'integranda:
\[
\dfrac{\partial}{\partial t}\left(f\left(t\right)e^{-st}\right)=\dot{f}\left(t\right)e^{-st}-sf\left(t\right)e^{-st}\implies
\]
\[
\dot{f}\left(t\right)e^{-st}=\dfrac{\partial}{\partial t}\left(f\left(t\right)e^{-st}\right)+sf\left(t\right)e^{-st}
\]
da cui otteniamo
\[
\somme 0{+\infty}{\left(\dfrac{\partial}{\partial t}\left(f\left(t\right)e^{-st}\right)+sf\left(t\right)e^{-st}\right)}t=\somme 0{+\infty}{\dfrac{\partial}{\partial t}\left(f\left(t\right)e^{-st}\right)}t+s\somme 0{+\infty}{f\left(t\right)e^{-st}}t
\]
\[
=\left[f\left(0\right)e^{-st}\right]_{0}^{+\infty}+sF\left(s\right)=\boxed{sF\left(s\right)-f\left(0\right)}
\]
Questa proprietà può essere usata in catena per ottenere la seguente
formula, valida per qualsiasi derivata multipla:
\begin{equation}
\mathscr{L}\left[\dfrac{\partial^{n}}{\partial t}f\left(t\right)\right]=s^{n}F\left(s\right)-\serie{i=1}n{s^{n-i}\left.\dfrac{\partial^{i-1}}{\partial t}f\left(t\right)\right|_{t=0}}\label{eq:Derivazione-multipla-tempo-Laplace}
\end{equation}
\bigskip{}
\item [{$\mathrm{\left(V\right)}\,\text{\textsc{Derivazione nel dominio di Laplace}}$\noun{:}}] Supponendo
che la trasformata $F\left(s\right)$ sia derivabile per ogni $s$
eccetto un numero finito di valori, vale:
\[
\mathscr{L}\left[t\cdot f\left(t\right)\right]=\boxed{-\dfrac{\partial}{\partial s}F\left(s\right)}
\]
Questo risultato si ottiene dalla seguente considerazione:
\[
\dfrac{\partial}{\partial s}F\left(s\right)=\dfrac{\partial}{\partial s}\left(\somme 0{+\infty}{f\left(t\right)e^{-st}}t\right)=\somme 0{+\infty}{\dfrac{\partial}{\partial s}\left(f\left(t\right)e^{-st}\right)}t
\]
\[
=-t\somme 0{+\infty}{f\left(t\right)e^{-st}}t=-\mathscr{L}\left[t\cdot f\left(t\right)\right]
\]
\bigskip{}
\item [{$\mathrm{\left(VI\right)}\,\text{\textsc{Integrazione nel dominio del Tempo}}$\noun{:}}] Con
l'intuizione che l'integrazione è l'operazione inversa della derivazione,
si dimostra che ciò vale anche per le trasformate; presa $f\left(t\right)$
integrabile tra 0 e $+\infty$, vale:
\[
\mathscr{L}\left[\somme 0{+\infty}{f\left(t\right)}t\right]=\boxed{\dfrac{1}{s}\cdot F\left(s\right)}
\]
dal fatto che l'operazione di derivazione nel dominio del tempo $\left(\mathrm{IV}\right)$
si effettua moltiplicando per $s$ (a meno della condizione iniziale).\bigskip{}
\item [{$\mathrm{\left(VII\right)}\,\text{\textsc{Convoluzione nel dominio del Tempo}}$\noun{:}}] \marginpar{Questa proprietà è fondamentale nell'analisi in frequenza dei movimenti
dei sistemi LTI}Prendiamo due segnali $f_{1}\left(t\right)$ e $f_{2}\left(t\right)$
e facciamone il \emph{prodotto di convoluzione} come
\begin{equation}
f_{1}\left(t\right)\varhexstar f_{2}\left(t\right)=\somme{-\infty}{+\infty}{f_{1}\left(\tau\right)f_{2}\left(t-\tau\right)}{\tau}=\somme{-\infty}{+\infty}{f_{1}\left(t-\eta\right)f_{2}\left(\eta\right)}{\eta}=f_{2}\left(t\right)\varhexstar f_{1}\left(t\right)\label{eq:Prodotto-di-convoluzione}
\end{equation}
Si dimostra che la trasformata di (\ref{eq:Prodotto-di-convoluzione})
vale:
\[
\mathscr{L}\left[f_{1}\left(t\right)\varhexstar f_{2}\left(t\right)\right]=\boxed{F_{1}\left(s\right)\cdot F_{2}\left(s\right)}
\]
\bigskip{}
\item [{$\mathrm{\left(VIII\right)}\,\text{\textsc{Teorema del valore iniziale}}$\noun{:}}] Se
la trasformata è razionale nella forma (\ref{eq:Trasformata-razionale})
e vale $n\left(N\left(s\right)\right)<n\left(D\left(s\right)\right)$
(con $n\left(P\left(x\right)\right)$ il grado del polinomio $P$
nella variabile $x$), allora vale:
\begin{equation}
f\left(0\right)=\lm s{+\infty}{s\cdot F\left(s\right)}.\label{eq:Teorema-valore-iniziale}
\end{equation}
\bigskip{}
\item [{$\mathrm{\left(IX\right)}\,\text{\textsc{Teorema del valore finale}}$\noun{:}}] Se
la trasformata è razionale nella forma (\ref{eq:Trasformata-razionale})
e vale $n\left(N\left(s\right)\right)<n\left(D\left(s\right)\right)$,
e inoltre per ogni suo polo $p_{i}$ vale $\Re\left(p_{1}\right)<0$,
allora vale:
\begin{equation}
\lm t{+\infty}{f\left(t\right)}=\lm s0{\,s\cdot F\left(s\right)}.\label{eq:Teorema-valore-finale}
\end{equation}
\bigskip{}
\end{lyxlist}

\section{Trasformate notevoli}

L'\textbf{impulso} è un ingresso canonico il cui integrale è non nullo
solo nell'istante $t=0$; la sua trasformata di Laplace vale
\[
\mathscr{L}\left[\text{imp}\left(t\right)\right]=\somme 0{+\infty}{e^{-st}\text{imp}\left(t\right)}t=e^{-s\cdot0}\somme 0{+\infty}{\text{imp}\left(0\right)}t=1
\]

Lo \textbf{scalino} è un ingresso canonico il cui integrale è nullo
per istanti di tempo negativi e costante unitario altrimenti; la sua
trasformata di Laplace vale:
\[
\mathscr{L}\left[\text{sca}\left(t\right)\right]=\somme 0{+\infty}{e^{-st}\text{sca}\left(t\right)}t=\somme 0{+\infty}{e^{-st}\cdot1}t=\left[-\dfrac{1}{s}e^{-st}\right]_{0}^{\infty}=\dfrac{1}{s}
\]

L'\textbf{esponenziale} è una funzione ricorrente nei modi dei sistemi
LTI, definita strettamente monotona; la sua trasformata di Laplace
vale:
\[
\mathscr{L}\left[e^{\alpha t}\cdot\text{sca}\left(t\right)\right]=\dfrac{1}{s-\alpha}
\]
per la proprietà $\left(\mathrm{III}\right)$ e per il risultato ottenuto
sulla trasformata dello scalino.

La \textbf{cosinusoide} è una funzione limitata, tipica dei movimenti
associati a modi complessi coniugati; la sua trasformata di Laplace
vale:
\[
\mathscr{L}\left[\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)\right]\overset{{\scriptscriptstyle \text{Eulero}}}{=}\mathscr{L}\biggl[\overset{{\scriptstyle 2\cos\left(\omega t\right)}}{\overbrace{\dfrac{e^{j\omega t}+e^{-j\omega t}}{2}}}\text{sca}\left(t\right)\biggr]\overset{{\scriptscriptstyle \left(\mathrm{I}\right)}}{=}\mathscr{L}\left[\dfrac{e^{j\omega t}}{2}\text{sca}\left(t\right)\right]+\mathscr{L}\left[\dfrac{e^{-j\omega t}}{2}\text{sca}\left(t\right)\right]
\]
\[
\overset{{\scriptscriptstyle \left(\mathrm{II}\right)}}{=}\dfrac{1}{2}\cdot\left(\dfrac{1}{s+j\omega}+\dfrac{1}{s-j\omega}\right)=\dfrac{s}{s^{2}+\omega^{2}}
\]

\marginpar{La trasformata della sinusoide può essere ottenuta usando la (\ref{eq:Formula-di-Eulero}),
come per la cosinusoide}La \textbf{sinusoide}, come la cosinusoide, è una funzione limitata
tipica dei movimenti associati a modi complessi coniugati; facciamo
le seguenti considerazioni per calcolare la sua trasformata di Laplace:
\[
\dfrac{\partial}{\partial t}\text{sca}\left(t\right)=\text{imp}\left(t\right)\implies\dfrac{\partial}{\partial t}\left(\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)\right)=-\omega\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)+\cos\left(wt\right)\cdot\text{imp}\left(t\right)
\]
Dalle precedenti scriviamo (esplicitando la sinusoide) che:
\[
\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)=-\dfrac{1}{\omega}\dfrac{\partial}{\partial t}\left(\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)\right)+\dfrac{1}{\omega}\cos\left(\omega t\right)\cdot\text{imp}\left(t\right)
\]
da cui la trasformata della sinusoide vale:
\[
\mathscr{L}\left[\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)\right]\overset{{\scriptscriptstyle \left(\mathrm{I}\right)}}{=}\dfrac{1}{\omega}\left(\mathscr{L}\left[-\dfrac{\partial}{\partial t}\left(\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)\right)\right]+\mathscr{L}\left[\cos\left(\omega t\right)\cdot\text{imp}\left(t\right)\right]\right)
\]
\[
\overset{{\scriptscriptstyle \left(\mathrm{IV}\right)}}{=}-\dfrac{1}{\omega}\left(\dfrac{s^{2}}{s^{2}+\omega^{2}}-1\right)=\dfrac{\omega}{s^{2}+\omega^{2}}
\]
dai risultati sulla trasformata della cosinusoide e dell'\uline{impulso}.
Si noti che, anche se la trasformata di una derivata contiene le condizioni
iniziali ($f\left(0\right)$), la trasformata della cosinusoide è
una funzione discontinua di prima specie nell'origine (a causa dello
scalino): in questo caso la condizione iniziale $f\left(0\right)\rightarrow f\left(0^{-}\right)=0$
col contributo dello scalino, che vale 0 per $t<0$.

La \textbf{rampa} è un ingresso canonico definito a partire dallo
scalino come $\text{ram}\left(t\right)=t\cdot\text{sca}\left(t\right)$;
la sua trasformata di Laplace vale:
\[
\mathscr{L}\left[\text{ram}\left(t\right)\right]=\mathscr{L}\left[t\cdot\text{sca}\left(t\right)\right]\overset{{\scriptscriptstyle \left(\mathrm{V}\right)}}{=}-\dfrac{\partial}{\partial s}\mathscr{L}\left[\text{sca}\left(t\right)\right]=-\dfrac{\partial}{\partial s}\cdot\dfrac{1}{s}=\dfrac{1}{s^{2}}
\]
Un'alternativa per ottenere questo risultato consiste nel vedere la
rampa come integrale dello scalino (moltiplicando quindi per $\nicefrac{1}{s}$
la trasformata dello scalino).

La \textbf{parabola} è un ingresso canonico monotono che si annulla
nell'istante iniziale, definita a partire dallo scalino come $\text{par}\left(t\right)=\nicefrac{1}{2}\,t^{2}\text{sca}\left(t\right)$;
la sua trasformata di Laplace vale:
\[
\mathscr{L}\left[\text{par}\left(t\right)\right]=\mathscr{L}\left[\somme 0{\infty}{\text{ram}\left(t\right)}t\right]\overset{{\scriptscriptstyle \left(\mathrm{VI}\right)}}{=}\dfrac{1}{s}\mathscr{L}\left[\text{ram}\left(t\right)\right]=\dfrac{1}{s^{3}}
\]

\begin{example}
\emph{Sia dato il seguente movimento forzato di un sistema dinamico
del I ordine, con coefficiente di stato $\alpha$:
\[
f\left(t\right)=e^{\alpha t}\cdot\text{sca}\left(t\right)\varhexstar\text{sca}\left(t\right)
\]
$\checkmark$Calcolare la trasformata di Laplace di tale movimento.}

Utilizziamo le proprietà di traslazione e di convoluzione per ottenere
il seguente risultato:
\[
\mathscr{L}\left[f\left(t\right)\right]=\dfrac{1}{s-\alpha}\cdot\dfrac{1}{s}=\dfrac{1}{s\left(s-\alpha\right)}
\]

\emph{$\checkmark$Calcolare valore iniziale e finale del movimento
$f\left(t\right)$.}

Essendo $f\left(t\right)$ razionale e con più poli che zeri, possiamo
applicare il Teorema \ref{eq:Teorema-valore-iniziale} e il Teorema
\ref{eq:Teorema-valore-finale}:
\[
f\left(0\right)\overset{{\scriptscriptstyle \left(\mathrm{VIII}\right)}}{=}\lm s{+\infty}{\dfrac{s}{s\left(s-\alpha\right)}}=\lm s{+\infty}{\dfrac{1}{s-\alpha}}\rightarrow1
\]
\[
\lm t{+\infty}{f\left(t\right)}\overset{{\scriptscriptstyle \left(IX\right)}}{=}\lm s0{\dfrac{s}{s\left(s-\alpha\right)}}=\lm s0{\dfrac{1}{s-\alpha}}\rightarrow\dfrac{1}{\alpha}
\]
dove nella seconda uguaglianza si è posto $\alpha<0$ come da ipotesi
del Teorema \ref{eq:Teorema-valore-finale}.\demo
\end{example}
\begin{xca}
\marginpar{$\blacktriangleright$ \emph{Esercizio: trasformata di Laplace}}\emph{$\checkmark$Trovare
la trasformata di Laplace dei seguenti segnali:}
\[
t\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{2\omega s/\left(s^{2}+\omega^{2}\right)^{2}}
\[
t\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{s^{2}-\omega^{2}/\left(s^{2}+\omega^{2}\right)^{2}}
\[
e^{\alpha t}\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{\left(s-\sigma\right)/\left(\left(s-\sigma\right)^{2}+\omega^{2}\right)}
\[
e^{\alpha t}\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{\omega/\left(\left(s-\alpha\right)^{2}+\omega^{2}\right)}
\[
te^{\alpha t}\cos\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{\left(\left(s-\alpha\right)^{2}-\omega^{2}\right)/\left(\left(s-\alpha\right)^{2}-\omega^{2}\right)^{2}}
\[
te^{\alpha t}\sin\left(\omega t\right)\cdot\text{sca}\left(t\right)
\]
\sln{2\omega\left(s-\alpha\right)/\left(\left(s-\alpha\right)^{2}+\omega^{2}\right)^{2}}
\end{xca}

\section{Antitrasformata}

Poniamoci nel caso di trasformate razionali (\ref{eq:Trasformata-razionale}),
con coefficienti reali; scegliamo $N\left(s\right)$ e $D\left(s\right)$
per cui $n\left(N\left(s\right)\right)<n\left(D\left(s\right)\right)$.
Nei sistemi LTI, è sempre possibile ricondurre i movimenti a forme
razionali come quella in esame; in particolare, utilizzando l'algoritmo
per la divisione dei polinomi, è sempre possibile la seguente riscrittura:
\[
F\left(s\right)=\dfrac{N\left(s\right)}{D\left(s\right)}=\dfrac{\beta_{0}s^{n}+\beta_{1}s^{n-1}+\ldots+\beta_{n}}{\alpha_{0}s^{n}+\alpha_{1}s^{n-1}+\ldots+\alpha_{n}}
\]
\[
=\dfrac{\beta_{0}}{\alpha_{0}}+\dfrac{\left(\beta_{1}-\beta_{0}\alpha_{1}\right)s^{n}+\left(\beta_{2}-\beta_{1}\alpha_{2}\right)s^{n-1}+\ldots+\left(\beta_{n}-\beta_{n-1}\alpha_{n}\right)}{\alpha_{0}s^{n}+\alpha_{1}s^{n-1}+\ldots+\alpha_{n}}
\]
Vale in generale che una funzione razionale può essere scritta come
somma di una costante e di una frazione strettamente propria, e grazie
alla proprietà $\left(\mathrm{I}\right)$ essa è ancora una antitrasformata
di Laplace.

L'antitrasformata della precedente riscrittura vale
\[
\mathscr{L}^{-1}\left[F\left(s\right)\right]=\dfrac{\beta_{0}}{\alpha_{0}}\cdot\text{imp}\left(t\right)
\]
dato che l'antitrasformata di una costante è un impulso di ampiezza
la costante.\bigskip{}

Analizziamo come antitrasformare una funzione che abbia \textbf{poli
distinti}; si procede scomponendo $F\left(s\right)$ in una sommatoria
di termini semplici (con denominatore al più di secondo grado) di
cui conosciamo l'antitrasformata e dai quali otterremo l'antitrasformata
complessiva per linearità.

Si scrive il polinomio al denominatore nel modo seguente:
\[
D\left(s\right)=\overset{{\scriptstyle n}}{\underset{{\scriptstyle i=1}}{\prod}}\left(s+p_{i}\right)
\]
con $p_{i}\in\mathbb{C}$, e la trasformata diventa sviluppabile come
\[
F\left(s\right)=\dfrac{N\left(s\right)}{\prod_{i=1}^{n}\left(s+p_{i}\right)}=\serie{i=1}n{\dfrac{P_{i}}{s+p_{i}}}
\]
dove $P_{i}$ sono i \emph{residui} che vogliamo calcolare, mentre
$p_{i}$ sono le radici di $D\left(s\right)$ (i \emph{poli}).

D'ora in avanti si procede applicando il \emph{metodo di Heaviside},
nel quale si moltiplica per uno dei termini $\left(s+p_{i}\right)$
la funzione sviluppata e la si valuta per $s=-p_{i}$:\marginpar{\rule[0.5ex]{3cm}{1pt}\textbf{\footnotesize{}}\protect \\
\textbf{\footnotesize{}Metodo di Heaviside}{\footnotesize{}\index{Heaviside, metodo di@{\footnotesize{}Heaviside, metodo di}}}}[2.25cm]
\[
\left(s+p_{i}\right)F\left(s\right)=\left[\left(s+p_{i}\right)\serie{j=1,\,j\neq i}n{\dfrac{P_{j}}{s+p_{j}}}\right]+P_{i}
\]
\begin{equation}
P_{i}=\dfrac{N\left(-p_{i}\right)}{\prod_{j=1,\,j\neq i}^{n}\left(p_{i}-p_{j}\right)}=\dfrac{N\left(-p_{i}\right)}{\nicefrac{\partial}{\partial s}\left.D\left(s\right)\right|_{s=-p_{i}}}=\left.\left[\left(s+p_{i}\right)F\left(s\right)\right]\right|_{s=-p_{i}}\label{eq:Metodo-di-Heaviside}
\end{equation}
Una volta ricavati i residui con (\ref{eq:Metodo-di-Heaviside}) in
corrispondenza di ciascun polo, otteniamo l'antitrasformata come:
\begin{equation}
f\left(t\right)=\mathscr{L}^{-1}\left[F\left(s\right)\right]=\mathscr{L}^{-1}\left[\serie{i=1}n{\dfrac{P_{i}}{s+p_{i}}}\right]=\left(\serie{i=1}n{P_{i}\cdot e^{-p_{i}t}}\right)\cdot\text{sca}\left(t\right)\label{eq:Antitrasformata-Laplace-poli-distinti}
\end{equation}
\bigskip{}

\begin{example}
\emph{Sia data la seguente trasformata di Laplace di un segnale:}
\[
F\left(s\right)=\dfrac{s-10}{\left(s+2\right)\left(s+5\right)}
\]
\emph{$\checkmark$Trovare la sua antitrasformata.}

Possiamo riscrivere con (\ref{eq:Metodo-di-Heaviside}) la funzione
come
\[
F\left(s\right)=\dfrac{P_{1}}{s+2}+\dfrac{P_{2}}{s+5}
\]
da cui ricaviamo i residui $P_{1,2}$ nel modo seguente:

\begin{minipage}[t]{1\columnwidth}%
\begin{enumerate}
\item $\left[\left(s+2\right)F\left(s\right)\right]|_{s=-2}=\left.\dfrac{\cancel{\left(s+2\right)}\left(s-10\right)}{\cancel{\left(s+2\right)}\left(s+5\right)}\right|_{s=-2}=\dfrac{-12}{3}=-4=P_{1}$\bigskip{}
\item $\left[\left(s+5\right)F\left(s\right)\right]|_{s=-5}=\left.\dfrac{\cancel{\left(s+5\right)}\left(s-10\right)}{\left(s+2\right)\cancel{\left(s+5\right)}}\right|_{s=-5}=\dfrac{-15}{-3}=5=P_{2}$
\end{enumerate}
%
\end{minipage}

Usando (\ref{eq:Antitrasformata-Laplace-poli-distinti}) scriviamo
l'antitrasformata come:
\[
\mathscr{L}^{-1}\left[F\left(s\right)\right]=\left(-4e^{-2t}+5e^{-5t}\right)\cdot\text{sca}\left(t\right)
\]
\demo
\end{example}
Nel caso di \textbf{poli complessi coniugati}, abbiamo comunque poli
distinti, con residui complessi coniugati; prendiamo due poli tali
che $s_{i}=-p_{i}$ e $s_{j}=-p_{i}^{*}$, allora il residuo $P_{j}=P_{i}^{*}$.
Scriviamo la funzione trasformata come combinazione lineare di termini
del tipo:
\[
F\left(s\right)=\dfrac{P_{i}}{\left(s+p_{i}\right)}+\dfrac{P_{i}^{*}}{\left(s+p_{i}^{*}\right)}
\]
Quando questa somma viene antitrasformata, si ottiene con (\ref{eq:Formula-di-Eulero})
dalla (\ref{eq:Antitrasformata-Laplace-poli-distinti}):
\[
P_{i}e^{-p_{i}t}+P_{i}^{*}e^{-p_{i}^{*}t}
\]
Se esprimiamo i poli $p_{i}=\sigma_{i}+j\omega_{i}$ e i residui $P_{i}=\left|P_{i}\right|e^{j\arg\left(P_{i}\right)}$,
con calcoli analoghi al caso di poli distinti, otteniamo la scrittura:
\begin{equation}
\mathscr{L}^{-1}\left[F\left(s\right)\right]=2\left|P_{i}\right|e^{-\sigma_{i}t}\cos\left(\omega_{i}t+\arg\left(P_{i}\right)\right)\label{eq:Antitrasformata-Laplace-poli-complessi-coniugati}
\end{equation}

\begin{example}
\emph{\label{exa:Anitrasformata-poli-complessi-coniugati}Sia data
la seguente trasformata di Laplace:
\[
F\left(s\right)=\dfrac{100}{\left(s+1\right)\left(s^{2}+4s+13\right)}
\]
$\checkmark$Calcolare la sua antitrasformata.}

Cominciamo calcolando i poli, ricavandoli da $D\left(s\right)=0$;
essi valgono rispettivamente $p_{1}=-1,\,p_{2}=-2+j3,\,p_{3}=-2-j3$,
con il secondo e il terzo polo le radici complesse coniugate del polinomio
$s^{2}+4s+13$. Ricaviamo ora i residuo con il (\ref{eq:Metodo-di-Heaviside}),
tenendo conto dei poli complessi coniugati:
\[
F\left(s\right)=\dfrac{P_{1}}{s-p_{1}}+\dfrac{P_{2}}{s-p_{2}}+\dfrac{P_{2}^{*}}{s-p_{2}^{*}}=\dfrac{P_{1}}{s+1}+\dfrac{P_{2}}{s+2-j3}+\dfrac{P_{2}^{*}}{s+2-j3}
\]
Da questa scrittura applichiamo il metodo di Heaviside e otteniamo
i residui $P_{1,2,3}$, moltiplicando a turno la trasformata per ciascun
denominatore $s-p_{i}$:

\begin{minipage}[t]{1\columnwidth}%
\begin{enumerate}
\item $\left.\dfrac{\cancel{\left(s+1\right)}\cdot100}{\cancel{\left(s+1\right)}\left(s+2-j3\right)\left(s+2+j3\right)}\right|_{s=-1}=\dfrac{100}{10}=10$;\bigskip{}
\item $\left.\dfrac{\cancel{\left(s+2-j3\right)}\cdot100}{\left(s+1\right)\cancel{\left(s+2-j3\right)}\left(s+2+j3\right)}\right|_{s=-2+j3}=\dfrac{100}{2\left(-9-j3\right)}=\dfrac{5}{3}\left(-3+j\right)\rightarrow\dfrac{5}{3}\sqrt{10}e^{j\left(\arctan\left(-\nicefrac{1}{3}\right)+\pi\right)}$;\bigskip{}
\item $P_{3}=P_{2}^{*}=\dfrac{5}{3}\left(-3-j\right)\rightarrow\dfrac{5}{3}\sqrt{10}e^{j\arctan\left(\nicefrac{1}{3}\right)}$.
\end{enumerate}
%
\end{minipage}

Possiamo usare le considerazioni fatte per i poli complessi coniugati
per affermare $\left(3\right)$; sostituendo i residui nella scrittura
della trasformata, otteniamo
\[
F\left(s\right)=\dfrac{10}{s+1}+\dfrac{\nicefrac{5}{3}\sqrt{10}e^{j\left(\arctan\left(-\nicefrac{1}{3}\right)+\pi\right)}}{s+2-j3}+\dfrac{\nicefrac{5}{3}\sqrt{10}e^{j\arctan\left(\nicefrac{1}{3}\right)}}{s+2+j3}
\]
dalla quale, usando (\ref{eq:Antitrasformata-Laplace-poli-distinti}),
si ottiene direttamente
\[
\mathscr{L}^{-1}\left[F\left(s\right)\right]=\left(10e^{-t}+\nicefrac{5}{3}\sqrt{10}e^{j\left(\arctan\left(-\nicefrac{1}{3}\right)+\pi\right)+\left(-2+j3\right)t}+\nicefrac{5}{3}\sqrt{10}e^{j\arctan\left(\nicefrac{1}{3}\right)+\left(-2-j3\right)t}\right)\cdot\text{sca}\left(t\right)
\]
e sfruttando la formula (\ref{eq:Antitrasformata-Laplace-poli-complessi-coniugati})
possiamo infine scrivere
\[
f\left(t\right)=\left[10e^{-t}+\nicefrac{5}{3}\sqrt{10}e^{-2t}\cdot2\cos\left(3t+\arctan\left(-\nicefrac{1}{3}\right)+\pi\right)\right]\cdot\text{sca}\left(t\right)
\]
\demo
\end{example}
Nel caso di \textbf{poli multipli} (radici di grado superiore al primo),
il metodo di Heaviside risulta inefficace, poiché esso perde dell'informazione
sui residui associati ai poli con molteplicità maggiore di 1; esprimiamo
la trasformata con poli multipli nella seguente scrittura:
\[
F\left(s\right)=\dfrac{N\left(s\right)}{\prod_{i=1}^{\mu}\left(s+p_{i}\right)^{n_{i}}}
\]
con $\mu<n$ rispettivamente il numero di poli distinti minore stretto
del grado del denominatore, $\exists i\in1\ldots\mu\,:\,n_{i}>1$
la molteplicità del $i$-esimo polo sia per qualche $i$ maggiore
di 1, e valga $\serie{i=1}{\mu}{n_{i}=n}$ (la somma di tutte le molteplicità
sia pari al grado del denominatore).

Introduciamo il metodo di \emph{cancellazione del denominatore}, che
in questa situazione permette di ottenere comunque ciascun residuo
a prescindere dalla molteplicità del suo polo; esso consiste nel moltiplicare
per $D\left(s\right)$ la trasformata, in forma di somma di residui
pesati sui poli, per ottenere la seguente scrittura:
\begin{equation}
N\left(s\right)=\serie{i=1}{\mu}{\serie{h=1}{n_{i}}{\left(P_{i,h}\cdot\overset{{\scriptstyle \mu}}{\underset{{\scriptstyle i=1}}{\prod}}\left[\left(s+p_{i}\right)^{n_{i}}\cdot\dfrac{1}{\left(s+p_{i}\right)^{h}}\right]\right)}}\label{eq:Metodo-cancellazione-denominatore}
\end{equation}
Da questa uguaglianza si ricavano $n$ equazioni che, risolte in un
sistema, forniscono tutti i residui anche in caso di molteplicità
($h>1$).
\begin{example}
\emph{Sia data la seguente trasformata di Laplace:
\[
F\left(s\right)=\dfrac{s+18}{s\left(s+3\right)^{2}}
\]
$\checkmark$Calcolarne l'antitrasformata.}

I poli della trasformata valgono rispettivamente $p_{1}=0$ con $n_{1}=1$
e $p_{2}=-3$ con $n_{2}=2$; riscriviamo la trasformata nella combinazione
di residui pesati sui poli:
\[
F\left(s\right)=\dfrac{P_{1,1}}{s-0}+\dfrac{P_{2,1}}{s+3}+\dfrac{P_{2,2}}{\left(s+3\right)^{2}}
\]
Otteniamo quindi i residui nei modi seguenti:

\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item $P_{1,1}$ può essere di nuovo ottenuto con (\ref{eq:Metodo-di-Heaviside}),
dato che ha molteplicità unitaria; in tal caso scriviamo:
\[
P_{1,1}=\left.\dfrac{\cancel{s}\left(s+18\right)}{\cancel{s}\left(s+3\right)^{2}}\right|_{s=0}=\dfrac{18}{9}=2
\]
\item $P_{2,2}$ può anch'esso essere ottenuto con (\ref{eq:Metodo-di-Heaviside}),
dato che moltiplicando per il suo denominatore rimane un polo di primo
grado:
\[
P_{2,2}=\left.\dfrac{\cancel{\left(s+3\right)^{2}}\left(s+18\right)}{s\cancel{\left(s+3\right)^{2}}}\right|_{s=-3}=\dfrac{15}{-3}=-5
\]
\item $P_{2,1}$ deve essere calcolato con (\ref{eq:Metodo-cancellazione-denominatore}),
vale a dire:
\[
F\left(s\right)\doteq\dfrac{s+18}{s\left(s+3\right)^{2}}=\dfrac{P_{1,1}}{s}+\dfrac{P_{2,1}}{s+3}+\dfrac{P_{2,2}}{\left(s+3\right)^{2}}
\]
\[
s+18=P_{1,1}\left(s+3\right)^{2}+P_{2,1}s\left(s+3\right)+P_{2,2}s
\]
A questo punto si raccolgono le $s$ per imporre delle condizioni
rispetto ai residui e ai valori già noti dal numeratore, a sinistra
dell'uguale:
\[
s+18=s^{2}\left(P_{1,1}+P_{2,1}\right)+s\left(6P_{1,1}+3P_{2,1}+P_{2,2}\right)+9P_{1}
\]
da cui si nota che $s^{2}=0$ dunque $P_{1,1}+P_{2,1}=0\rightarrow P_{1,1}=-P_{2,2}$
e, avendo già calcolato il valore di $P_{1.1}$, segue che $P_{2,1}=-2$.
\end{itemize}
%
\end{minipage}

L'espressione generale della trasformata sarà quindi:
\[
F\left(s\right)=\dfrac{2}{s}+\dfrac{-2}{s+3}+\dfrac{-5}{\left(s+3\right)^{2}}
\]
da cui ricaviamo l'antitrasformata
\[
\mathscr{L}^{-1}\left[F\left(s\right)\right]=\left(2-2e^{-3t}-5te^{-3t}\right)\cdot\text{sca}\left(t\right)=f\left(t\right)
\]
dove il terzo addendo ($-5te^{-3t}$) è ottenuto come prodotto di
un esponenziale per una rampa; infatti $\mathscr{L}\left[e^{\alpha t}\cdot\text{ram}\left(t\right)\right]=\dfrac{1}{\left(s-\alpha\right)^{2}}$.\demo
\end{example}
%
\begin{example}
Riprendiamo il testo dell'Esempio \ref{exa:Anitrasformata-poli-complessi-coniugati};
la trasformata assegnata era
\[
F\left(s\right)=\dfrac{100}{\left(s+1\right)\left(s^{2}+4s+13\right)}
\]
Riscriviamola nel modo seguente, per poter sfruttare (\ref{eq:Metodo-cancellazione-denominatore}):\marginpar{Si ricorda che il denominatore della trasformata di una sinusoide
è del tipo $1/\left(\left(s+\alpha\right)^{2}+\omega^{2}\right)$,
come in questo caso per il secondo e terzo residuo}
\[
F\left(s\right)=\dfrac{100}{\left(s+1\right)\left(\left(s+2\right)^{2}+9\right)}=\dfrac{P_{1}}{s+1}+\dfrac{P_{2}s+P_{3}}{\left(s+2\right)^{2}+9}
\]
Nel secondo addendo abbiamo posto il denominatore pari a una combinazione
lineare di residui con grado inferiore di uno rispetto al polo associato;
otteniamo dunque i seguenti valori dei residui:

\begin{minipage}[t]{1\columnwidth}%
\begin{itemize}
\item $P_{1}$ si ottiene usando il metodo di Heaviside; come nell'Esempio
\ref{exa:Anitrasformata-poli-complessi-coniugati} (per quanto riguardava
$P_{1,1}$), esso vale 10;
\item Applicando (\ref{eq:Metodo-cancellazione-denominatore}) otteniamo
le condizioni necessarie a calcolare $P_{2}$ e $P_{3}$:
\[
100=P_{1}\left(s^{2}+4s+13\right)+P_{2}s\left(s+1\right)+P_{3}\left(s+1\right)
\]
\[
=s^{2}\left(P_{1}+P_{2}\right)+s\left(4P_{1}+P_{2}+P_{3}\right)+13P_{1}+P_{3}
\]
Osservando che nel numeratore non compare la variabile $s$, imponiamo
che $100=13P_{1}+P_{3}$ da cui, con la conoscenza di $P_{1}=10$,
otteniamo sostituendo nella precedente che $P_{2}=-30$.\\
Infine usiamo il coefficiente di $s^{2}$ per imporre che $P_{1}+P_{2}=0\rightarrow P_{2}=-P_{1}=-10$.
\end{itemize}
%
\end{minipage}

La forma generale della trasformata risulta:
\[
F\left(s\right)=\dfrac{10}{s+1}+\dfrac{-10s-30}{\left(s+2\right)^{2}+9}\overset{{\scriptscriptstyle *}}{=}\dfrac{10}{s+1}-10\left(\dfrac{s+2}{\left(s+2\right)^{2}+9}+\nicefrac{1}{3}\dfrac{3}{\left(s+2\right)^{2}+9}\right)
\]
dove nell'uguaglianza ${\scriptstyle *}$ abbiamo raccolto e separato
per ottenere dei termini simili alla trasformata di funzioni trigonometriche;
grazie a questo raffinamento possiamo scrivere direttamente l'antitrasformata
come:
\[
\mathscr{L}^{-1}\left[F\left(s\right)\right]=\left(10e^{-t}-10e^{-2t}\cos\left(3t\right)-\dfrac{10}{3}e^{-2t}\sin\left(3t\right)\right)\cdot\text{sca}\left(t\right)
\]
\demo
\end{example}
\renewcommand{\chaptername}{}\printindex
\end{document}
